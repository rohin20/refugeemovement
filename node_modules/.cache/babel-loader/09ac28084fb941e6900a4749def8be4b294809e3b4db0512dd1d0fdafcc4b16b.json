{"ast":null,"code":"// Copyright (c) 2022 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.processCsvData = processCsvData;\nexports.parseRowsByFields = parseRowsByFields;\nexports.parseCsvRowsByFieldType = parseCsvRowsByFieldType;\nexports.processRowObject = processRowObject;\nexports.processGeojson = processGeojson;\nexports.processKeplerglJSON = processKeplerglJSON;\nexports.processKeplerglDataset = processKeplerglDataset;\nexports.Processors = exports.DATASET_HANDLERS = exports.PARSE_FIELD_VALUE_FROM_STRING = exports.CSV_NULLS = void 0;\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _d3Dsv = require(\"d3-dsv\");\nvar _geojsonNormalize = _interopRequireDefault(require(\"@mapbox/geojson-normalize\"));\nvar _constants = require(\"@kepler.gl/constants\");\nvar _utils = require(\"@kepler.gl/utils\");\nvar _schemas = require(\"@kepler.gl/schemas\");\nvar _PARSE_FIELD_VALUE_FR, _DATASET_HANDLERS;\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        (0, _defineProperty2[\"default\"])(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n  return target;\n}\n\n// if any of these value occurs in csv, parse it to null;\n// const CSV_NULLS = ['', 'null', 'NULL', 'Null', 'NaN', '/N'];\n// matches empty string\nvar CSV_NULLS = /^(null|NULL|Null|NaN|\\/N||)$/;\nexports.CSV_NULLS = CSV_NULLS;\nvar PARSE_FIELD_VALUE_FROM_STRING = (_PARSE_FIELD_VALUE_FR = {}, (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _constants.ALL_FIELD_TYPES[\"boolean\"], {\n  valid: function valid(d) {\n    return typeof d === 'boolean';\n  },\n  parse: function parse(d) {\n    return d === 'true' || d === 'True' || d === 'TRUE' || d === '1';\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _constants.ALL_FIELD_TYPES.integer, {\n  // @ts-ignore\n  valid: function valid(d) {\n    return parseInt(d, 10) === d;\n  },\n  // @ts-ignore\n  parse: function parse(d) {\n    return parseInt(d, 10);\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _constants.ALL_FIELD_TYPES.timestamp, {\n  valid: function valid(d, field) {\n    return ['x', 'X'].includes(field.format) ? typeof d === 'number' : typeof d === 'string';\n  },\n  parse: function parse(d, field) {\n    return ['x', 'X'].includes(field.format) ? Number(d) : d;\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _constants.ALL_FIELD_TYPES.real, {\n  // @ts-ignore\n  valid: function valid(d) {\n    return parseFloat(d) === d;\n  },\n  // Note this will result in NaN for some string\n  parse: parseFloat\n}), _PARSE_FIELD_VALUE_FR);\n/**\n * Process csv data, output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and pass to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * @param rawData raw csv string\n * @returns data object `{fields: [], rows: []}` can be passed to addDataToMaps\n * @public\n * @example\n * import {processCsvData} from 'kepler.gl/processors';\n *\n * const testData = `gps_data.utc_timestamp,gps_data.lat,gps_data.lng,gps_data.types,epoch,has_result,id,time,begintrip_ts_utc,begintrip_ts_local,date\n * 2016-09-17 00:09:55,29.9900937,31.2590542,driver_analytics,1472688000000,False,1,2016-09-23T00:00:00.000Z,2016-10-01 09:41:39+00:00,2016-10-01 09:41:39+00:00,2016-09-23\n * 2016-09-17 00:10:56,29.9927699,31.2461142,driver_analytics,1472688000000,False,2,2016-09-23T00:00:00.000Z,2016-10-01 09:46:37+00:00,2016-10-01 16:46:37+00:00,2016-09-23\n * 2016-09-17 00:11:56,29.9907261,31.2312742,driver_analytics,1472688000000,False,3,2016-09-23T00:00:00.000Z,,,2016-09-23\n * 2016-09-17 00:12:58,29.9870074,31.2175827,driver_analytics,1472688000000,False,4,2016-09-23T00:00:00.000Z,,,2016-09-23`\n *\n * const dataset = {\n *  info: {id: 'test_data', label: 'My Csv'},\n *  data: processCsvData(testData)\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: [dataset],\n *  options: {centerMap: true, readOnly: true}\n * }));\n */\n\nexports.PARSE_FIELD_VALUE_FROM_STRING = PARSE_FIELD_VALUE_FROM_STRING;\nfunction processCsvData(rawData, header) {\n  var rows;\n  var headerRow;\n  if (typeof rawData === 'string') {\n    var _parsedRows = (0, _d3Dsv.csvParseRows)(rawData);\n    if (!Array.isArray(_parsedRows) || _parsedRows.length < 2) {\n      // looks like an empty file, throw error to be catch\n      throw new Error('process Csv Data Failed: CSV is empty');\n    }\n    headerRow = _parsedRows[0];\n    rows = _parsedRows.slice(1);\n  } else if (Array.isArray(rawData) && rawData.length) {\n    rows = rawData;\n    headerRow = header;\n    if (!Array.isArray(headerRow)) {\n      // if data is passed in as array of rows and missing header\n      // assume first row is header\n      // @ts-ignore\n      headerRow = rawData[0];\n      rows = rawData.slice(1);\n    }\n  }\n  if (!rows || !headerRow) {\n    throw new Error('invalid input passed to processCsvData');\n  } // here we assume the csv file that people uploaded will have first row\n  // as name of the column\n\n  cleanUpFalsyCsvValue(rows); // No need to run type detection on every data point\n  // here we get a list of none null values to run analyze on\n\n  var sample = (0, _utils.getSampleForTypeAnalyze)({\n    fields: headerRow,\n    rows: rows\n  });\n  var fields = (0, _utils.getFieldsFromData)(sample, headerRow);\n  var parsedRows = parseRowsByFields(rows, fields);\n  return {\n    fields: fields,\n    rows: parsedRows\n  };\n}\n/**\n * Parse rows of csv by analyzed field types. So that `'1'` -> `1`, `'True'` -> `true`\n * @param rows\n * @param fields\n */\n\nfunction parseRowsByFields(rows, fields) {\n  // Edit rows in place\n  var geojsonFieldIdx = fields.findIndex(function (f) {\n    return f.name === '_geojson';\n  });\n  fields.forEach(parseCsvRowsByFieldType.bind(null, rows, geojsonFieldIdx));\n  return rows;\n}\n/**\n * Convert falsy value in csv including `'', 'null', 'NULL', 'Null', 'NaN'` to `null`,\n * so that type-analyzer won't detect it as string\n *\n * @param rows\n */\n\nfunction cleanUpFalsyCsvValue(rows) {\n  var re = new RegExp(CSV_NULLS, 'g');\n  for (var i = 0; i < rows.length; i++) {\n    for (var j = 0; j < rows[i].length; j++) {\n      // analyzer will set any fields to 'string' if there are empty values\n      // which will be parsed as '' by d3.csv\n      // here we parse empty data as null\n      // TODO: create warning when deltect `CSV_NULLS` in the data\n      if (typeof rows[i][j] === 'string' && rows[i][j].match(re)) {\n        rows[i][j] = null;\n      }\n    }\n  }\n}\n/**\n * Process uploaded csv file to parse value by field type\n *\n * @param rows\n * @param geoFieldIdx field index\n * @param field\n * @param i\n */\n\nfunction parseCsvRowsByFieldType(rows, geoFieldIdx, field, i) {\n  var parser = PARSE_FIELD_VALUE_FROM_STRING[field.type];\n  if (parser) {\n    // check first not null value of it's already parsed\n    var first = rows.find(function (r) {\n      return (0, _utils.notNullorUndefined)(r[i]);\n    });\n    if (!first || parser.valid(first[i], field)) {\n      return;\n    }\n    rows.forEach(function (row) {\n      // parse string value based on field type\n      if (row[i] !== null) {\n        row[i] = parser.parse(row[i], field);\n        if (geoFieldIdx > -1 && (0, _utils.isPlainObject)(row[geoFieldIdx]) &&\n        // @ts-ignore\n        (0, _utils.hasOwnProperty)(row[geoFieldIdx], 'properties')) {\n          // @ts-ignore\n          row[geoFieldIdx].properties[field.name] = row[i];\n        }\n      }\n    });\n  }\n}\n/* eslint-enable complexity */\n\n/**\n * Process data where each row is an object, output can be passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n * @param rawData an array of row object, each object should have the same number of keys\n * @returns dataset containing `fields` and `rows`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processRowObject} from 'kepler.gl/processors';\n *\n * const data = [\n *  {lat: 31.27, lng: 127.56, value: 3},\n *  {lat: 31.22, lng: 126.26, value: 1}\n * ];\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {label: 'My Data', id: 'my_data'},\n *    data: processRowObject(data)\n *  }\n * }));\n */\n\nfunction processRowObject(rawData) {\n  if (!Array.isArray(rawData)) {\n    return null;\n  } else if (!rawData.length) {\n    // data is empty\n    return {\n      fields: [],\n      rows: []\n    };\n  }\n  var keys = Object.keys(rawData[0]); // [lat, lng, value]\n\n  var rows = rawData.map(function (d) {\n    return keys.map(function (key) {\n      return d[key];\n    });\n  }); // [[31.27, 127.56, 3]]\n  // row object an still contain values like `Null` or `N/A`\n\n  cleanUpFalsyCsvValue(rows);\n  return processCsvData(rows, keys);\n}\n/**\n * Process GeoJSON [`FeatureCollection`](http://wiki.geojson.org/GeoJSON_draft_version_6#FeatureCollection),\n * output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n *\n * @param rawData raw geojson feature collection\n * @returns dataset containing `fields` and `rows`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processGeojson} from 'kepler.gl/processors';\n *\n * const geojson = {\n * \t\"type\" : \"FeatureCollection\",\n * \t\"features\" : [{\n * \t\t\"type\" : \"Feature\",\n * \t\t\"properties\" : {\n * \t\t\t\"capacity\" : \"10\",\n * \t\t\t\"type\" : \"U-Rack\"\n * \t\t},\n * \t\t\"geometry\" : {\n * \t\t\t\"type\" : \"Point\",\n * \t\t\t\"coordinates\" : [ -71.073283, 42.417500 ]\n * \t\t}\n * \t}]\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {\n *      label: 'Sample Taxi Trips in New York City',\n *      id: 'test_trip_data'\n *    },\n *    data: processGeojson(geojson)\n *  }\n * }));\n */\n\nfunction processGeojson(rawData) {\n  var normalizedGeojson = (0, _geojsonNormalize[\"default\"])(rawData);\n  if (!normalizedGeojson || !Array.isArray(normalizedGeojson.features)) {\n    var error = new Error(\"Read File Failed: File is not a valid GeoJSON. Read more about [supported file format](\".concat(_constants.GUIDES_FILE_FORMAT_DOC, \")\"));\n    throw error; // fail to normalize geojson\n  } // getting all feature fields\n\n  var allDataRows = [];\n  for (var i = 0; i < normalizedGeojson.features.length; i++) {\n    var f = normalizedGeojson.features[i];\n    if (f.geometry) {\n      allDataRows.push(_objectSpread({\n        // add feature to _geojson field\n        _geojson: f\n      }, f.properties || {}));\n    }\n  } // get all the field\n\n  var fields = allDataRows.reduce(function (accu, curr) {\n    Object.keys(curr).forEach(function (key) {\n      if (!accu.includes(key)) {\n        accu.push(key);\n      }\n    });\n    return accu;\n  }, []); // make sure each feature has exact same fields\n\n  allDataRows.forEach(function (d) {\n    fields.forEach(function (f) {\n      if (!(f in d)) {\n        d[f] = null;\n        d._geojson.properties[f] = null;\n      }\n    });\n  });\n  return processRowObject(allDataRows);\n}\n/**\n * Process saved kepler.gl json to be pass to [`addDataToMap`](../actions/actions.md#adddatatomap).\n * The json object should contain `datasets` and `config`.\n * @param rawData\n * @param schema\n * @returns datasets and config `{datasets: {}, config: {}}`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processKeplerglJSON} from 'kepler.gl/processors';\n *\n * dispatch(addDataToMap(processKeplerglJSON(keplerGlJson)));\n */\n\nfunction processKeplerglJSON(rawData) {\n  var schema = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : _schemas.KeplerGlSchema;\n  return rawData ? schema.load(rawData.datasets, rawData.config) : null;\n}\n/**\n * Parse a single or an array of datasets saved using kepler.gl schema\n * @param rawData\n * @param schema\n */\n\nfunction processKeplerglDataset(rawData) {\n  var schema = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : _schemas.KeplerGlSchema;\n  if (!rawData) {\n    return null;\n  }\n  var results = schema.parseSavedData((0, _utils.toArray)(rawData));\n  if (!results) {\n    return null;\n  }\n  return Array.isArray(rawData) ? results : results[0];\n}\nvar DATASET_HANDLERS = (_DATASET_HANDLERS = {}, (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _constants.DATASET_FORMATS.row, processRowObject), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _constants.DATASET_FORMATS.geojson, processGeojson), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _constants.DATASET_FORMATS.csv, processCsvData), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _constants.DATASET_FORMATS.keplergl, processKeplerglDataset), _DATASET_HANDLERS);\nexports.DATASET_HANDLERS = DATASET_HANDLERS;\nvar Processors = {\n  processGeojson: processGeojson,\n  processCsvData: processCsvData,\n  processRowObject: processRowObject,\n  processKeplerglJSON: processKeplerglJSON,\n  processKeplerglDataset: processKeplerglDataset,\n  analyzerTypeToFieldType: _utils.analyzerTypeToFieldType,\n  getFieldsFromData: _utils.getFieldsFromData,\n  parseCsvRowsByFieldType: parseCsvRowsByFieldType\n};\nexports.Processors = Processors;","map":{"version":3,"names":["_interopRequireDefault","require","Object","defineProperty","exports","Processors","DATASET_HANDLERS","PARSE_FIELD_VALUE_FROM_STRING","CSV_NULLS","_defineProperty2","_geojsonNormalize","_constants","_utils","_schemas","_PARSE_FIELD_VALUE_FR","_DATASET_HANDLERS","ownKeys","object","enumerableOnly","keys","getOwnPropertySymbols","symbols","filter","sym","getOwnPropertyDescriptor","enumerable","push","apply","_objectSpread","target","i","arguments","length","source","forEach","key","getOwnPropertyDescriptors","defineProperties","ALL_FIELD_TYPES","valid","d","parse","integer","parseInt","timestamp","field","includes","format","Number","real","parseFloat","processCsvData","rawData","header","rows","headerRow","_parsedRows","_d3Dsv","csvParseRows","Array","isArray","Error","slice","sample","getSampleForTypeAnalyze","fields","getFieldsFromData","parsedRows","parseRowsByFields","geojsonFieldIdx","findIndex","f","name","parseCsvRowsByFieldType","bind","cleanUpFalsyCsvValue","re","RegExp","j","match","geoFieldIdx","parser","type","first","find","r","notNullorUndefined","row","isPlainObject","hasOwnProperty","properties","processRowObject","map","processGeojson","normalizedGeojson","features","error","concat","GUIDES_FILE_FORMAT_DOC","allDataRows","geometry","_geojson","reduce","accu","curr","processKeplerglJSON","results","schema","undefined","KeplerGlSchema","load","datasets","config","processKeplerglDataset","parseSavedData","toArray"],"sources":["/Users/rohinphukan/Desktop/RefugeeWebsite/node_modules/@kepler.gl/processors/src/data-processor.ts"],"sourcesContent":["// Copyright (c) 2022 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\nimport {csvParseRows} from 'd3-dsv';\nimport normalize from '@mapbox/geojson-normalize';\nimport {ALL_FIELD_TYPES, DATASET_FORMATS, GUIDES_FILE_FORMAT_DOC} from '@kepler.gl/constants';\nimport {ProcessorResult, Field} from '@kepler.gl/types';\nimport {\n  notNullorUndefined,\n  hasOwnProperty,\n  isPlainObject,\n  analyzerTypeToFieldType,\n  getSampleForTypeAnalyze,\n  getFieldsFromData,\n  toArray\n} from '@kepler.gl/utils';\nimport {KeplerGlSchema, ParsedDataset, SavedMap, LoadedMap} from '@kepler.gl/schemas';\nimport {Feature} from '@nebula.gl/edit-modes';\n\n// if any of these value occurs in csv, parse it to null;\n// const CSV_NULLS = ['', 'null', 'NULL', 'Null', 'NaN', '/N'];\n// matches empty string\nexport const CSV_NULLS = /^(null|NULL|Null|NaN|\\/N||)$/;\n\nexport const PARSE_FIELD_VALUE_FROM_STRING = {\n  [ALL_FIELD_TYPES.boolean]: {\n    valid: (d: unknown): boolean => typeof d === 'boolean',\n    parse: (d: unknown): boolean => d === 'true' || d === 'True' || d === 'TRUE' || d === '1'\n  },\n  [ALL_FIELD_TYPES.integer]: {\n    // @ts-ignore\n    valid: (d: unknown): boolean => parseInt(d, 10) === d,\n    // @ts-ignore\n    parse: (d: unknown): number => parseInt(d, 10)\n  },\n  [ALL_FIELD_TYPES.timestamp]: {\n    valid: (d: unknown, field: Field): boolean =>\n      ['x', 'X'].includes(field.format) ? typeof d === 'number' : typeof d === 'string',\n    parse: (d: any, field: Field) => (['x', 'X'].includes(field.format) ? Number(d) : d)\n  },\n  [ALL_FIELD_TYPES.real]: {\n    // @ts-ignore\n    valid: (d: unknown): boolean => parseFloat(d) === d,\n    // Note this will result in NaN for some string\n    parse: parseFloat\n  }\n};\n\n/**\n * Process csv data, output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and pass to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * @param rawData raw csv string\n * @returns data object `{fields: [], rows: []}` can be passed to addDataToMaps\n * @public\n * @example\n * import {processCsvData} from 'kepler.gl/processors';\n *\n * const testData = `gps_data.utc_timestamp,gps_data.lat,gps_data.lng,gps_data.types,epoch,has_result,id,time,begintrip_ts_utc,begintrip_ts_local,date\n * 2016-09-17 00:09:55,29.9900937,31.2590542,driver_analytics,1472688000000,False,1,2016-09-23T00:00:00.000Z,2016-10-01 09:41:39+00:00,2016-10-01 09:41:39+00:00,2016-09-23\n * 2016-09-17 00:10:56,29.9927699,31.2461142,driver_analytics,1472688000000,False,2,2016-09-23T00:00:00.000Z,2016-10-01 09:46:37+00:00,2016-10-01 16:46:37+00:00,2016-09-23\n * 2016-09-17 00:11:56,29.9907261,31.2312742,driver_analytics,1472688000000,False,3,2016-09-23T00:00:00.000Z,,,2016-09-23\n * 2016-09-17 00:12:58,29.9870074,31.2175827,driver_analytics,1472688000000,False,4,2016-09-23T00:00:00.000Z,,,2016-09-23`\n *\n * const dataset = {\n *  info: {id: 'test_data', label: 'My Csv'},\n *  data: processCsvData(testData)\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: [dataset],\n *  options: {centerMap: true, readOnly: true}\n * }));\n */\nexport function processCsvData(rawData: unknown[][], header?: string[]): ProcessorResult {\n  let rows: unknown[][] | undefined;\n  let headerRow: string[] | undefined;\n\n  if (typeof rawData === 'string') {\n    const parsedRows: string[][] = csvParseRows(rawData);\n\n    if (!Array.isArray(parsedRows) || parsedRows.length < 2) {\n      // looks like an empty file, throw error to be catch\n      throw new Error('process Csv Data Failed: CSV is empty');\n    }\n    headerRow = parsedRows[0];\n    rows = parsedRows.slice(1);\n  } else if (Array.isArray(rawData) && rawData.length) {\n    rows = rawData;\n    headerRow = header;\n\n    if (!Array.isArray(headerRow)) {\n      // if data is passed in as array of rows and missing header\n      // assume first row is header\n      // @ts-ignore\n      headerRow = rawData[0];\n      rows = rawData.slice(1);\n    }\n  }\n\n  if (!rows || !headerRow) {\n    throw new Error('invalid input passed to processCsvData');\n  }\n\n  // here we assume the csv file that people uploaded will have first row\n  // as name of the column\n\n  cleanUpFalsyCsvValue(rows);\n  // No need to run type detection on every data point\n  // here we get a list of none null values to run analyze on\n  const sample = getSampleForTypeAnalyze({fields: headerRow, rows});\n  const fields = getFieldsFromData(sample, headerRow);\n  const parsedRows = parseRowsByFields(rows, fields);\n\n  return {fields, rows: parsedRows};\n}\n\n/**\n * Parse rows of csv by analyzed field types. So that `'1'` -> `1`, `'True'` -> `true`\n * @param rows\n * @param fields\n */\nexport function parseRowsByFields(rows: any[][], fields: Field[]) {\n  // Edit rows in place\n  const geojsonFieldIdx = fields.findIndex(f => f.name === '_geojson');\n  fields.forEach(parseCsvRowsByFieldType.bind(null, rows, geojsonFieldIdx));\n\n  return rows;\n}\n\n/**\n * Convert falsy value in csv including `'', 'null', 'NULL', 'Null', 'NaN'` to `null`,\n * so that type-analyzer won't detect it as string\n *\n * @param rows\n */\nfunction cleanUpFalsyCsvValue(rows: unknown[][]): void {\n  const re = new RegExp(CSV_NULLS, 'g');\n  for (let i = 0; i < rows.length; i++) {\n    for (let j = 0; j < rows[i].length; j++) {\n      // analyzer will set any fields to 'string' if there are empty values\n      // which will be parsed as '' by d3.csv\n      // here we parse empty data as null\n      // TODO: create warning when deltect `CSV_NULLS` in the data\n      if (typeof rows[i][j] === 'string' && (rows[i][j] as string).match(re)) {\n        rows[i][j] = null;\n      }\n    }\n  }\n}\n\n/**\n * Process uploaded csv file to parse value by field type\n *\n * @param rows\n * @param geoFieldIdx field index\n * @param field\n * @param i\n */\nexport function parseCsvRowsByFieldType(\n  rows: unknown[][],\n  geoFieldIdx: number,\n  field: Field,\n  i: number\n): void {\n  const parser = PARSE_FIELD_VALUE_FROM_STRING[field.type];\n  if (parser) {\n    // check first not null value of it's already parsed\n    const first = rows.find(r => notNullorUndefined(r[i]));\n    if (!first || parser.valid(first[i], field)) {\n      return;\n    }\n    rows.forEach(row => {\n      // parse string value based on field type\n      if (row[i] !== null) {\n        row[i] = parser.parse(row[i], field);\n        if (\n          geoFieldIdx > -1 &&\n          isPlainObject(row[geoFieldIdx]) &&\n          // @ts-ignore\n          hasOwnProperty(row[geoFieldIdx], 'properties')\n        ) {\n          // @ts-ignore\n          row[geoFieldIdx].properties[field.name] = row[i];\n        }\n      }\n    });\n  }\n}\n\n/* eslint-enable complexity */\n\n/**\n * Process data where each row is an object, output can be passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n * @param rawData an array of row object, each object should have the same number of keys\n * @returns dataset containing `fields` and `rows`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processRowObject} from 'kepler.gl/processors';\n *\n * const data = [\n *  {lat: 31.27, lng: 127.56, value: 3},\n *  {lat: 31.22, lng: 126.26, value: 1}\n * ];\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {label: 'My Data', id: 'my_data'},\n *    data: processRowObject(data)\n *  }\n * }));\n */\nexport function processRowObject(rawData: unknown[]): ProcessorResult {\n  if (!Array.isArray(rawData)) {\n    return null;\n  } else if (!rawData.length) {\n    // data is empty\n    return {\n      fields: [],\n      rows: []\n    };\n  }\n\n  const keys = Object.keys(rawData[0]); // [lat, lng, value]\n  const rows = rawData.map(d => keys.map(key => d[key])); // [[31.27, 127.56, 3]]\n\n  // row object an still contain values like `Null` or `N/A`\n  cleanUpFalsyCsvValue(rows);\n\n  return processCsvData(rows, keys);\n}\n\n/**\n * Process GeoJSON [`FeatureCollection`](http://wiki.geojson.org/GeoJSON_draft_version_6#FeatureCollection),\n * output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n *\n * @param rawData raw geojson feature collection\n * @returns dataset containing `fields` and `rows`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processGeojson} from 'kepler.gl/processors';\n *\n * const geojson = {\n * \t\"type\" : \"FeatureCollection\",\n * \t\"features\" : [{\n * \t\t\"type\" : \"Feature\",\n * \t\t\"properties\" : {\n * \t\t\t\"capacity\" : \"10\",\n * \t\t\t\"type\" : \"U-Rack\"\n * \t\t},\n * \t\t\"geometry\" : {\n * \t\t\t\"type\" : \"Point\",\n * \t\t\t\"coordinates\" : [ -71.073283, 42.417500 ]\n * \t\t}\n * \t}]\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {\n *      label: 'Sample Taxi Trips in New York City',\n *      id: 'test_trip_data'\n *    },\n *    data: processGeojson(geojson)\n *  }\n * }));\n */\nexport function processGeojson(rawData: unknown): ProcessorResult {\n  const normalizedGeojson = normalize(rawData);\n\n  if (!normalizedGeojson || !Array.isArray(normalizedGeojson.features)) {\n    const error = new Error(\n      `Read File Failed: File is not a valid GeoJSON. Read more about [supported file format](${GUIDES_FILE_FORMAT_DOC})`\n    );\n    throw error;\n    // fail to normalize geojson\n  }\n\n  // getting all feature fields\n  const allDataRows: Array<{_geojson: Feature} & keyof Feature> = [];\n  for (let i = 0; i < normalizedGeojson.features.length; i++) {\n    const f = normalizedGeojson.features[i];\n    if (f.geometry) {\n      allDataRows.push({\n        // add feature to _geojson field\n        _geojson: f,\n        ...(f.properties || {})\n      });\n    }\n  }\n  // get all the field\n  const fields = allDataRows.reduce<string[]>((accu, curr) => {\n    Object.keys(curr).forEach(key => {\n      if (!accu.includes(key)) {\n        accu.push(key);\n      }\n    });\n    return accu;\n  }, []);\n\n  // make sure each feature has exact same fields\n  allDataRows.forEach(d => {\n    fields.forEach(f => {\n      if (!(f in d)) {\n        d[f] = null;\n        d._geojson.properties[f] = null;\n      }\n    });\n  });\n\n  return processRowObject(allDataRows);\n}\n\n/**\n * Process saved kepler.gl json to be pass to [`addDataToMap`](../actions/actions.md#adddatatomap).\n * The json object should contain `datasets` and `config`.\n * @param rawData\n * @param schema\n * @returns datasets and config `{datasets: {}, config: {}}`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processKeplerglJSON} from 'kepler.gl/processors';\n *\n * dispatch(addDataToMap(processKeplerglJSON(keplerGlJson)));\n */\nexport function processKeplerglJSON(rawData: SavedMap, schema = KeplerGlSchema): LoadedMap | null {\n  return rawData ? schema.load(rawData.datasets, rawData.config) : null;\n}\n\n/**\n * Parse a single or an array of datasets saved using kepler.gl schema\n * @param rawData\n * @param schema\n */\nexport function processKeplerglDataset(\n  rawData: object | object[],\n  schema = KeplerGlSchema\n): ParsedDataset | ParsedDataset[] | null {\n  if (!rawData) {\n    return null;\n  }\n\n  const results = schema.parseSavedData(toArray(rawData));\n  if (!results) {\n    return null;\n  }\n  return Array.isArray(rawData) ? results : results[0];\n}\n\nexport const DATASET_HANDLERS: {\n  row: typeof processRowObject;\n  geojson: typeof processGeojson;\n  csv: typeof processCsvData;\n  keplergl: typeof processKeplerglDataset;\n} = {\n  [DATASET_FORMATS.row]: processRowObject,\n  [DATASET_FORMATS.geojson]: processGeojson,\n  [DATASET_FORMATS.csv]: processCsvData,\n  [DATASET_FORMATS.keplergl]: processKeplerglDataset\n};\n\nexport const Processors: {\n  processGeojson: typeof processGeojson;\n  processCsvData: typeof processCsvData;\n  processRowObject: typeof processRowObject;\n  processKeplerglJSON: typeof processKeplerglJSON;\n  processKeplerglDataset: typeof processKeplerglDataset;\n  analyzerTypeToFieldType: typeof analyzerTypeToFieldType;\n  getFieldsFromData: typeof getFieldsFromData;\n  parseCsvRowsByFieldType: typeof parseCsvRowsByFieldType;\n} = {\n  processGeojson,\n  processCsvData,\n  processRowObject,\n  processKeplerglJSON,\n  processKeplerglDataset,\n  analyzerTypeToFieldType,\n  getFieldsFromData,\n  parseCsvRowsByFieldType\n};\n"],"mappings":";;;;;;;;;;;;;;;;;;AAoBA;;AACA;;AACA,IAAAA,sBAAA,GAAAC,OAAA;AAEAC,MAAA,CAAAC,cAAA,CAAAC,OAAA;;AASA;;;;;;;;AAGAA,OAAA,CAAAC,UAAA,GAAAD,OAAA,CAAAE,gBAAA,GAAAF,OAAA,CAAAG,6BAAA,GAAAH,OAAA,CAAAI,SAAA;AAEA,IAAAC,gBAAA,GAAAT,sBAAA,CAAAC,OAAA;;AAKI,IAAAS,iBAAO,GAACV,sBAAD,CAAAC,OAAA;AAAA,IADkBU,UAAA,GAAAV,OAAA;AAElB,IAAAW,MAAA,GAA0BX,OAAK,mBAAN;AAFP,IADaY,QAAA,GAAAZ,OAAA;AAOtC,IAAAa,qBAAO,EAAAC,iBAAA;AAAA,SAFkBC,QAAAC,MAAA,EAAAC,cAAA;EAAA,IAAAC,IAAA,GAAAjB,MAAA,CAAAiB,IAAA,CAAAF,MAAA;EAAA,IAAAf,MAAA,CAAAkB,qBAAA;IAAA,IAAAC,OAAA,GAAAnB,MAAA,CAAAkB,qBAAA,CAAAH,MAAA;IAAA,IAAAC,cAAA,EAAAG,OAAA,GAAAA,OAAA,CAAAC,MAAA,WAAAC,GAAA;MAAA,OAAArB,MAAA,CAAAsB,wBAAA,CAAAP,MAAA,EAAAM,GAAA,EAAAE,UAAA;IAAA;IAAAN,IAAA,CAAAO,IAAA,CAAAC,KAAA,CAAAR,IAAA,EAAAE,OAAA;EAAA;EAAA,OAAAF,IAAA;AAAA;AAIzB,SAAOS,cAAAC,MAAA;EAAA,SAAAC,CAAA,MAAAA,CAAA,GAAAC,SAAA,CAAAC,MAAA,EAAAF,CAAA;IAAA,IAAAG,MAAA,GAAAF,SAAA,CAAAD,CAAA,YAAAC,SAAA,CAAAD,CAAA;IAAA,IAAAA,CAAA;MAAAd,OAAA,CAAAd,MAAA,CAAA+B,MAAA,SAAAC,OAAA,WAAAC,GAAA;QAAA,IAAA1B,gBAAA,aAAAoB,MAAA,EAAAM,GAAA,EAAAF,MAAA,CAAAE,GAAA;MAAA;IAAA,WAAAjC,MAAA,CAAAkC,yBAAA;MAAAlC,MAAA,CAAAmC,gBAAA,CAAAR,MAAA,EAAA3B,MAAA,CAAAkC,yBAAA,CAAAH,MAAA;IAAA;MAAAjB,OAAA,CAAAd,MAAA,CAAA+B,MAAA,GAAAC,OAAA,WAAAC,GAAA;QAAAjC,MAAA,CAAAC,cAAA,CAAA0B,MAAA,EAAAM,GAAA,EAAAjC,MAAA,CAAAsB,wBAAA,CAAAS,MAAA,EAAAE,GAAA;MAAA;IAAA;EAAA;EAAA,OAAAN,MAAA;AAAA;;AAAA;AAJkB;AAOzB;AAAO,IAAArB,SACJ,GAAD;AADKJ,OADoB,CAAAI,SAAA,GAAAA,SAAA;AAG3B,IAAAD,6BAAO,IAAAO,qBAAA,WAAAL,gBAAA,aAAAK,qBAAA,EAAAH,UAAA,CAAA2B,eAAA;EAAAC,KAAA,WAAiCA,KAAKA,CAAAC,CAAA;IAAtC,cAAAA,CAAA;EAd+B;EAiBtCC,KAAA,WAAAA,MAAAD,CAAA;IACA,OAAOA,CAAA,eAAAA,CAAA,eAAAA,CAAA,eAAAA,CAAA;EAAA;AAAA,IAFe,IAAA/B,gBAAA,aAAAK,qBAAA,EAAAH,UAAA,CAAA2B,eAAA,CAAAI,OAAA;EAGtB;EACAH,KAAK,EAAE,SAAAA,MAAAC,CAAA;IApB+B,OAAAG,QAAA,CAAAH,CAAA,KAAnC,KAAAA,CAAA;EAwBP;EACA;EACAC,KAAA,WAAAA,MAAAD,CAAA;IACA,OAAAG,QAAA,CAAAH,CAAA;EACA;AACA,QAAA/B,gBAAA,aAAAK,qBAAA,EAAAH,UAAA,CAAA2B,eAAA,CAAAM,SAAA;EACAL,KAAA,WAAAA,MAAAC,CAAA,EAAAK,KAAA;IACA,kBAAAC,QAAA,CAAAD,KAAA,CAAAE,MAAA,WAAAP,CAAA,uBAAAA,CAAA;EACA;EACAC,KAAA,WAAAA,MAAAD,CAAA,EAAAK,KAAA;IACA,kBAAAC,QAAA,CAAAD,KAAA,CAAAE,MAAA,IAAAC,MAAA,CAAAR,CAAA,IAAAA,CAAA;EACA;AACA,QAAA/B,gBAAA,aAAAK,qBAAA,EAAAH,UAAA,CAAA2B,eAAA,CAAAW,IAAA;EACA;EACAV,KAAA,WAAAA,MAAAC,CAAA;IACA,OAAAU,UAAA,CAAAV,CAAA,MAAAA,CAAA;EACA;EACA;EACAC,KAAA,EAAAS;AACA,IAAApC,qBAAA;AACA;AACA;AACA;AACA;AACA;;;;AACO;AACL;AACA;;AAEA;AACE;;AAEA;AACE;AACA;AACD;;AACD;AACA;AACD;AACC;AACA;;AAEAV,OAAA,CAAIG,6BAA2B,GAAAA,6BAAA;AAE7B,SAAA4C,eAAAC,OAAA,EAAAC,MAAA;EACA,IAAAC,IAAA;EACA,IAAAC,SAAS;EAEV,WAAAH,OAAA;IACF,IAAAI,WAAA,OAAAC,MAAA,CAAAC,YAAA,EAAAN,OAAA;IAED,IAAK,CAAAO,KAAD,CAASC,OAAC,CAAAJ,WAAW,KAAAA,WAAA,CAAAxB,MAAA;MACvB;MAGF,UAAA6B,KAAA;IACA;;IAEAP,IAAA,GAAAE,WAAoB,CAACM,KAArB,CAjCuF,CAkCvF;EACA,WAAAH,KAAA,CAAAC,OAAA,CAAAR,OAAA,KAAAA,OAAA,CAAApB,MAAA;;IACAuB,SAAY,GAAGF,MAAA;IAA4C,IAAI,CAAAM,KAAJ,CAAAC,OAAA,CAAAL,SAAA;MAA3D;MACM;MACA;MAENA,SAAO,GAAAH,OAAA;MAACE,IAAM,GAANF,OAAD,CAAAU,KAAA;IAAS;EAAT;EAGT,KAAAR,IAAA,KAAAC,SAAA;IACA,UAAAM,KAAA;EACA;EACA;;;EAEO;;EAEL,IAAME,MAAA,OAAAnD,MAAkB,CAAAoD,uBAAiB;IAACC,MAAA,EAAKV,SAAD;IAA9CD,IAAA,EAAAA;EACA;EAEA,IAAAW,MAAO,GAAP,IAAArD,MAAA,CAAAsD,iBAAA,EAAAH,MAAA,EAAAR,SAAA;EACD,IAAAY,UAAA,GAAAC,iBAAA,CAAAd,IAAA,EAAAW,MAAA;EAED;IACAA,MAAA,EAAAA,MAAA;IACAX,IAAA,EAAAa;EACA;AACA;AACA;;;AACA;AACE;;AAEE,SAAKC,iBAAeA,CAAAd,IAAA,EAAQW,MAA5B,EAAqC;EACnC;EACA,IAAAI,eAAA,GAAAJ,MAAA,CAAAK,SAAA,WAAAC,CAAA;IACA,OAAAA,CAAA,CAAAC,IAAA;EACA;EACAP,MAAA,CAAA/B,OAAI,CAAOuC,uBAAP,CAAAC,IAAmC,KAAI,EAAIpB,IAAc,EAAAe,eAAW;EACtE,OAAAf,IAAK;AACN;AACF;AACF;AACF;AAED;AACA;AACA;;AAGA,SAAAqB,qBAAArB,IAAA;EACA,IAAAsB,EAAA,OAAAC,MAAA,CAAArE,SAAA;;;MAEO;MAMC;;MACF;MACF,WAAA8C,IAAA,CAAAxB,CAAA,EAAAgD,CAAA,kBAAAxB,IAAA,CAAAxB,CAAA,EAAAgD,CAAA,EAAAC,KAAA,CAAAH,EAAA;QACMtB,IAAA,CAAKxB,CAAA,EAAGgD,CAAA,IAAK,IAAL;MAAW;IAAA;;AACzB;AACE;AACD;;AACD;AACE;AACA;AACE;;;AAOE,SAAAL,wBAAAnB,IAAA,EAAA0B,WAAA,EAAAnC,KAAA,EAAAf,CAAA;EACA,IAAAmD,MAAA,GAAI1E,6BAA8B,CAAAsC,KAAlC,CAAAqC,IAA6C,CAAC;EAEjD,IAAAD,MAAA;IACF;IACF,IAAAE,KAAA,GAAA7B,IAAA,CAAA8B,IAAA,WAAAC,CAAA;MACF,WAAAzE,MAAA,CAAA0E,kBAAA,EAAAD,CAAA,CAAAvD,CAAA;IAED;IAEA,KAAAqD,KAAA,IAAAF,MAAA,CAAA1C,KAAA,CAAA4C,KAAA,CAAArD,CAAA,GAAAe,KAAA;MACA;IACA;IAEAS,IAAA,CAAApB,OAAA,WAAAqD,GAAA;MACA;MACA,IAAAA,GAAA,CAAAzD,CAAA;QACAyD,GAAA,CAAAzD,CAAA,IAAAmD,MAAA,CAAAxC,KAAA,CAAA8C,GAAA,CAAAzD,CAAA,GAAAe,KAAA;QAEA,IAAAmC,WAAA,aAAApE,MAAA,CAAA4E,aAAA,EAAAD,GAAA,CAAAP,WAAA;QAAA;QACA,IAAApE,MAAA,CAAA6E,cAAA,EAAAF,GAAA,CAAAP,WAAA;UACA;UACAO,GAAA,CAAAP,WAAA,EAAAU,UAAA,CAAA7C,KAAA,CAAA2B,IAAA,IAAAe,GAAA,CAAAzD,CAAA;QACA;MACA;IACA;EACA;AACA;AACA;;AAEA;AACA;;;AACO;AACL;AACE;AACD;AACC;AACA;AACE;AACA;AAFK;AAIR;;AAED;;AACA;AAA0B;AAAgB;AAAA;AAAhB;;AAG1B,SAAA6D,gBAAqBA,CAAAvC,OAArB;EAEA,KAAAO,KAAO,CAAAC,OAAA,CAAAR,OAAc,GAAO;IAC7B;EAED,YAAAA,OAAA,CAAApB,MAAA;IACA;IACA;MACAiC,MAAA;MACAX,IAAA;IACA;EACA;EAEA,IAAAnC,IAAA,GAAAjB,MAAA,CAAAiB,IAAA,CAAAiC,OAAA;;EAEA,IAAAE,IAAA,GAAAF,OAAA,CAAAwC,GAAA,WAAApD,CAAA;IACA,OAAArB,IAAA,CAAAyE,GAAA,WAAAzD,GAAA;MACA,OAAAK,CAAA,CAAAL,GAAA;IACA;EACA;EACA;;EAEAwC,oBAAA,CAAArB,IAAA;EACA,OAAAH,cAAA,CAAAG,IAAA,EAAAnC,IAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACO;AACL;;AAEA;AACE;AAGA;AAED;;;AAGD;;AACA;AACE;;AACA;AACE;AACE;AACA;;AAIL,SACD0E,eAAAzC,OAAA;;EACA,IAAM,CAAA0C,iBAAS,IAAY,CAAAnC,KAAiB,CAAAC,OAAA,CAAAkC,iBAAgB,CAAAC,QAAA;IAC1D,IAAAC,KAAO,GAAK,IAAZnC,KAAkB,0FAAe,CAAAoC,MAAA,CAAAtF,UAAA,CAAAuF,sBAAA;IAC/B,MAAIF,KAAK,CAAC;EACR;;EAGJ,IAAAG,WAAA;;IAIF,IAAA5B,CAAA,GAAAuB,iBAAoB,CAAAC,QAAK,CAAAjE,CAAA;IAErB,IAAAyC,CAAA,CAAI6B,QAAA,EAAJ;MACED,WAAO,CAAAzE,IAAP,CAAAE,aAAA;QACA;QACDyE,QAAA,EAAA9B;MAJH,GAAAA,CAAA,CAAAmB,UAAA;IADF;EASA;;EAIF,IAAAzB,MAAA,GAAAkC,WAAA,CAAAG,MAAA,WAAAC,IAAA,EAAAC,IAAA;IACAtG,MAAA,CAAAiB,IAAA,CAAAqF,IAAA,EAAAtE,OAAA,WAAAC,GAAA;MACA,KAAAoE,IAAA,CAAAzD,QAAA,CAAAX,GAAA;QACAoE,IAAA,CAAA7E,IAAA,CAAAS,GAAA;MACA;IACA;IACA,OAAAoE,IAAA;EACA;;EAEAJ,WAAA,CAAAjE,OAAA,WAAAM,CAAA;IACAyB,MAAA,CAAA/B,OAAA,WAAAqC,CAAA;MACA,MAAAA,CAAA,IAAA/B,CAAA;;;MACO;IAA2F,EAA3C;EACrD;EACD,OAAAmD,gBAAA,CAAAQ,WAAA;AAED;AACA;AACA;AACA;AACA;;;AACO;AAGmC;;AACxC;AACE;AACD;;;AAGD,SAAKM,mBAASC,CAAAtD,OAAA;EACZ,IAAAuD,MAAO,GAAP5E,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAA6E,SAAA,GAAA7E,SAAA,MAAAlB,QAAA,CAAAgG,cAAA;EACD,OAAAzD,OAAA,GAAAuD,MAAA,CAAAG,IAAA,CAAA1D,OAAA,CAAA2D,QAAA,EAAA3D,OAAA,CAAA4D,MAAA;;AACD;AACD;;AAEM;;;AAuBL,SAAAC,uBAFE7D,OAAA;EAGF,IAAAuD,MAAA,GAAA5E,SAAA,CAAAC,MAAA,QAHED,SAAA,QAAA6E,SAAA,GAAA7E,SAAA,MAAAlB,QAAA,CAAAgG,cAAA;EAKF,KAAAzD,OAAA;IACA;EACA;EAhBK,IAAAsD,OAAA,GAAAC,MAAA,CAAAO,cAAA,KAAAtG,MAAA,CAAAuG,OAAA,EAAA/D,OAAA"},"metadata":{},"sourceType":"script","externalDependencies":[]}