{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.processCsvData = processCsvData;\nexports.parseRowsByFields = parseRowsByFields;\nexports.getSampleForTypeAnalyze = getSampleForTypeAnalyze;\nexports.parseCsvRowsByFieldType = parseCsvRowsByFieldType;\nexports.getFieldsFromData = getFieldsFromData;\nexports.renameDuplicateFields = renameDuplicateFields;\nexports.analyzerTypeToFieldType = analyzerTypeToFieldType;\nexports.processRowObject = processRowObject;\nexports.processGeojson = processGeojson;\nexports.formatCsv = formatCsv;\nexports.validateInputData = validateInputData;\nexports.processKeplerglJSON = processKeplerglJSON;\nexports.processKeplerglDataset = processKeplerglDataset;\nexports.Processors = exports.DATASET_HANDLERS = exports.PARSE_FIELD_VALUE_FROM_STRING = exports.CSV_NULLS = exports.ACCEPTED_ANALYZER_TYPES = void 0;\nvar _typeof2 = _interopRequireDefault(require(\"@babel/runtime/helpers/typeof\"));\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _d3Dsv = require(\"d3-dsv\");\nvar _d3Array = require(\"d3-array\");\nvar _window = require(\"global/window\");\nvar _assert = _interopRequireDefault(require(\"assert\"));\nvar _typeAnalyzer = require(\"type-analyzer\");\nvar _geojsonNormalize = _interopRequireDefault(require(\"@mapbox/geojson-normalize\"));\nvar _defaultSettings = require(\"../constants/default-settings\");\nvar _dataUtils = require(\"../utils/data-utils\");\nvar _schemas = _interopRequireDefault(require(\"../schemas\"));\nvar _userGuides = require(\"../constants/user-guides\");\nvar _utils = require(\"../utils/utils\");\nvar _PARSE_FIELD_VALUE_FR, _DATASET_HANDLERS;\nfunction _createForOfIteratorHelper(o, allowArrayLike) {\n  var it;\n  if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) {\n    if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") {\n      if (it) o = it;\n      var i = 0;\n      var F = function F() {};\n      return {\n        s: F,\n        n: function n() {\n          if (i >= o.length) return {\n            done: true\n          };\n          return {\n            done: false,\n            value: o[i++]\n          };\n        },\n        e: function e(_e) {\n          throw _e;\n        },\n        f: F\n      };\n    }\n    throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n  }\n  var normalCompletion = true,\n    didErr = false,\n    err;\n  return {\n    s: function s() {\n      it = o[Symbol.iterator]();\n    },\n    n: function n() {\n      var step = it.next();\n      normalCompletion = step.done;\n      return step;\n    },\n    e: function e(_e2) {\n      didErr = true;\n      err = _e2;\n    },\n    f: function f() {\n      try {\n        if (!normalCompletion && it[\"return\"] != null) it[\"return\"]();\n      } finally {\n        if (didErr) throw err;\n      }\n    }\n  };\n}\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n  return arr2;\n}\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        (0, _defineProperty2[\"default\"])(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n  return target;\n}\nvar ACCEPTED_ANALYZER_TYPES = [_typeAnalyzer.DATA_TYPES.DATE, _typeAnalyzer.DATA_TYPES.TIME, _typeAnalyzer.DATA_TYPES.DATETIME, _typeAnalyzer.DATA_TYPES.NUMBER, _typeAnalyzer.DATA_TYPES.INT, _typeAnalyzer.DATA_TYPES.FLOAT, _typeAnalyzer.DATA_TYPES.BOOLEAN, _typeAnalyzer.DATA_TYPES.STRING, _typeAnalyzer.DATA_TYPES.GEOMETRY, _typeAnalyzer.DATA_TYPES.GEOMETRY_FROM_STRING, _typeAnalyzer.DATA_TYPES.PAIR_GEOMETRY_FROM_STRING, _typeAnalyzer.DATA_TYPES.ZIPCODE, _typeAnalyzer.DATA_TYPES.ARRAY, _typeAnalyzer.DATA_TYPES.OBJECT]; // if any of these value occurs in csv, parse it to null;\n// const CSV_NULLS = ['', 'null', 'NULL', 'Null', 'NaN', '/N'];\n// matches empty string\n\nexports.ACCEPTED_ANALYZER_TYPES = ACCEPTED_ANALYZER_TYPES;\nvar CSV_NULLS = /^(null|NULL|Null|NaN|\\/N||)$/;\nexports.CSV_NULLS = CSV_NULLS;\nvar IGNORE_DATA_TYPES = Object.keys(_typeAnalyzer.DATA_TYPES).filter(function (type) {\n  return !ACCEPTED_ANALYZER_TYPES.includes(type);\n});\nvar PARSE_FIELD_VALUE_FROM_STRING = (_PARSE_FIELD_VALUE_FR = {}, (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES[\"boolean\"], {\n  valid: function valid(d) {\n    return typeof d === 'boolean';\n  },\n  parse: function parse(d) {\n    return d === 'true' || d === 'True' || d === 'TRUE' || d === '1';\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES.integer, {\n  valid: function valid(d) {\n    return parseInt(d, 10) === d;\n  },\n  parse: function parse(d) {\n    return parseInt(d, 10);\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES.timestamp, {\n  valid: function valid(d, field) {\n    return ['x', 'X'].includes(field.format) ? typeof d === 'number' : typeof d === 'string';\n  },\n  parse: function parse(d, field) {\n    return ['x', 'X'].includes(field.format) ? Number(d) : d;\n  }\n}), (0, _defineProperty2[\"default\"])(_PARSE_FIELD_VALUE_FR, _defaultSettings.ALL_FIELD_TYPES.real, {\n  valid: function valid(d) {\n    return parseFloat(d) === d;\n  },\n  // Note this will result in NaN for some string\n  parse: parseFloat\n}), _PARSE_FIELD_VALUE_FR);\n/**\n * Process csv data, output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and pass to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * @param rawData raw csv string\n * @returns  data object `{fields: [], rows: []}` can be passed to addDataToMaps\n * @type {typeof import('./data-processor').processCsvData}\n * @public\n * @example\n * import {processCsvData} from 'kepler.gl/processors';\n *\n * const testData = `gps_data.utc_timestamp,gps_data.lat,gps_data.lng,gps_data.types,epoch,has_result,id,time,begintrip_ts_utc,begintrip_ts_local,date\n * 2016-09-17 00:09:55,29.9900937,31.2590542,driver_analytics,1472688000000,False,1,2016-09-23T00:00:00.000Z,2016-10-01 09:41:39+00:00,2016-10-01 09:41:39+00:00,2016-09-23\n * 2016-09-17 00:10:56,29.9927699,31.2461142,driver_analytics,1472688000000,False,2,2016-09-23T00:00:00.000Z,2016-10-01 09:46:37+00:00,2016-10-01 16:46:37+00:00,2016-09-23\n * 2016-09-17 00:11:56,29.9907261,31.2312742,driver_analytics,1472688000000,False,3,2016-09-23T00:00:00.000Z,,,2016-09-23\n * 2016-09-17 00:12:58,29.9870074,31.2175827,driver_analytics,1472688000000,False,4,2016-09-23T00:00:00.000Z,,,2016-09-23`\n *\n * const dataset = {\n *  info: {id: 'test_data', label: 'My Csv'},\n *  data: processCsvData(testData)\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: [dataset],\n *  options: {centerMap: true, readOnly: true}\n * }));\n */\n\nexports.PARSE_FIELD_VALUE_FROM_STRING = PARSE_FIELD_VALUE_FROM_STRING;\nfunction processCsvData(rawData, header) {\n  var rows;\n  var headerRow;\n  if (typeof rawData === 'string') {\n    var _parsedRows = (0, _d3Dsv.csvParseRows)(rawData);\n    if (!Array.isArray(_parsedRows) || _parsedRows.length < 2) {\n      // looks like an empty file, throw error to be catch\n      throw new Error('process Csv Data Failed: CSV is empty');\n    }\n    headerRow = _parsedRows[0];\n    rows = _parsedRows.slice(1);\n  } else if (Array.isArray(rawData) && rawData.length) {\n    rows = rawData;\n    headerRow = header;\n    if (!Array.isArray(headerRow)) {\n      // if data is passed in as array of rows and missing header\n      // assume first row is header\n      headerRow = rawData[0];\n      rows = rawData.slice(1);\n    }\n  }\n  if (!rows || !headerRow) {\n    throw new Error('invalid input passed to processCsvData');\n  } // here we assume the csv file that people uploaded will have first row\n  // as name of the column\n\n  cleanUpFalsyCsvValue(rows); // No need to run type detection on every data point\n  // here we get a list of none null values to run analyze on\n\n  var sample = getSampleForTypeAnalyze({\n    fields: headerRow,\n    rows: rows\n  });\n  var fields = getFieldsFromData(sample, headerRow);\n  var parsedRows = parseRowsByFields(rows, fields);\n  return {\n    fields: fields,\n    rows: parsedRows\n  };\n}\n/**\n * Parse rows of csv by analyzed field types. So that `'1'` -> `1`, `'True'` -> `true`\n * @param {Array<Array>} rows\n * @param {Array<Object>} fields\n */\n\nfunction parseRowsByFields(rows, fields) {\n  // Edit rows in place\n  var geojsonFieldIdx = fields.findIndex(function (f) {\n    return f.name === '_geojson';\n  });\n  fields.forEach(parseCsvRowsByFieldType.bind(null, rows, geojsonFieldIdx));\n  return rows;\n}\n/**\n * Getting sample data for analyzing field type.\n *\n * @type {typeof import('./data-processor').getSampleForTypeAnalyze}\n */\n\nfunction getSampleForTypeAnalyze(_ref) {\n  var fields = _ref.fields,\n    rows = _ref.rows,\n    _ref$sampleCount = _ref.sampleCount,\n    sampleCount = _ref$sampleCount === void 0 ? 50 : _ref$sampleCount;\n  var total = Math.min(sampleCount, rows.length); // const fieldOrder = fields.map(f => f.name);\n\n  var sample = (0, _d3Array.range)(0, total, 1).map(function (d) {\n    return {};\n  }); // collect sample data for each field\n\n  fields.forEach(function (field, fieldIdx) {\n    // data counter\n    var i = 0; // sample counter\n\n    var j = 0;\n    while (j < total) {\n      if (i >= rows.length) {\n        // if depleted data pool\n        sample[j][field] = null;\n        j++;\n      } else if ((0, _dataUtils.notNullorUndefined)(rows[i][fieldIdx])) {\n        var value = rows[i][fieldIdx];\n        sample[j][field] = typeof value === 'string' ? value.trim() : value;\n        j++;\n        i++;\n      } else {\n        i++;\n      }\n    }\n  });\n  return sample;\n}\n/**\n * Convert falsy value in csv including `'', 'null', 'NULL', 'Null', 'NaN'` to `null`,\n * so that type-analyzer won't detect it as string\n *\n * @param {Array<Array>} rows\n */\n\nfunction cleanUpFalsyCsvValue(rows) {\n  var re = new RegExp(CSV_NULLS, 'g');\n  for (var i = 0; i < rows.length; i++) {\n    for (var j = 0; j < rows[i].length; j++) {\n      // analyzer will set any fields to 'string' if there are empty values\n      // which will be parsed as '' by d3.csv\n      // here we parse empty data as null\n      // TODO: create warning when deltect `CSV_NULLS` in the data\n      if (typeof rows[i][j] === 'string' && rows[i][j].match(re)) {\n        rows[i][j] = null;\n      }\n    }\n  }\n}\n/**\n * Process uploaded csv file to parse value by field type\n *\n * @param rows\n * @param geoFieldIdx field index\n * @param field\n * @param i\n * @type {typeof import('./data-processor').parseCsvRowsByFieldType}\n */\n\nfunction parseCsvRowsByFieldType(rows, geoFieldIdx, field, i) {\n  var parser = PARSE_FIELD_VALUE_FROM_STRING[field.type];\n  if (parser) {\n    // check first not null value of it's already parsed\n    var first = rows.find(function (r) {\n      return (0, _dataUtils.notNullorUndefined)(r[i]);\n    });\n    if (!first || parser.valid(first[i], field)) {\n      return;\n    }\n    rows.forEach(function (row) {\n      // parse string value based on field type\n      if (row[i] !== null) {\n        row[i] = parser.parse(row[i], field);\n        if (geoFieldIdx > -1 && row[geoFieldIdx] && row[geoFieldIdx].properties) {\n          row[geoFieldIdx].properties[field.name] = row[i];\n        }\n      }\n    });\n  }\n}\n/**\n * Analyze field types from data in `string` format, e.g. uploaded csv.\n * Assign `type`, `fieldIdx` and `format` (timestamp only) to each field\n *\n * @param data array of row object\n * @param fieldOrder array of field names as string\n * @returns formatted fields\n * @type {typeof import('./data-processor').getFieldsFromData}\n * @public\n * @example\n *\n * import {getFieldsFromData} from 'kepler.gl/processors';\n * const data = [{\n *   time: '2016-09-17 00:09:55',\n *   value: '4',\n *   surge: '1.2',\n *   isTrip: 'true',\n *   zeroOnes: '0'\n * }, {\n *   time: '2016-09-17 00:30:08',\n *   value: '3',\n *   surge: null,\n *   isTrip: 'false',\n *   zeroOnes: '1'\n * }, {\n *   time: null,\n *   value: '2',\n *   surge: '1.3',\n *   isTrip: null,\n *   zeroOnes: '1'\n * }];\n *\n * const fieldOrder = ['time', 'value', 'surge', 'isTrip', 'zeroOnes'];\n * const fields = getFieldsFromData(data, fieldOrder);\n * // fields = [\n * // {name: 'time', format: 'YYYY-M-D H:m:s', fieldIdx: 1, type: 'timestamp'},\n * // {name: 'value', format: '', fieldIdx: 4, type: 'integer'},\n * // {name: 'surge', format: '', fieldIdx: 5, type: 'real'},\n * // {name: 'isTrip', format: '', fieldIdx: 6, type: 'boolean'},\n * // {name: 'zeroOnes', format: '', fieldIdx: 7, type: 'integer'}];\n *\n */\n\nfunction getFieldsFromData(data, fieldOrder) {\n  // add a check for epoch timestamp\n  var metadata = _typeAnalyzer.Analyzer.computeColMeta(data, [{\n    regex: /.*geojson|all_points/g,\n    dataType: 'GEOMETRY'\n  }, {\n    regex: /.*census/g,\n    dataType: 'STRING'\n  }], {\n    ignoredDataTypes: IGNORE_DATA_TYPES\n  });\n  var _renameDuplicateField = renameDuplicateFields(fieldOrder),\n    fieldByIndex = _renameDuplicateField.fieldByIndex;\n  var result = fieldOrder.map(function (field, index) {\n    var name = fieldByIndex[index];\n    var fieldMeta = metadata.find(function (m) {\n      return m.key === field;\n    });\n    var _ref2 = fieldMeta || {},\n      type = _ref2.type,\n      format = _ref2.format;\n    return {\n      name: name,\n      id: name,\n      displayName: name,\n      format: format,\n      fieldIdx: index,\n      type: analyzerTypeToFieldType(type),\n      analyzerType: type,\n      valueAccessor: function valueAccessor(dc) {\n        return function (d) {\n          return dc.valueAt(d.index, index);\n        };\n      }\n    };\n  }); // @ts-ignore\n\n  return result;\n}\n/**\n * pass in an array of field names, rename duplicated one\n * and return a map from old field index to new name\n *\n * @param {Array} fieldOrder\n * @returns {Object} new field name by index\n */\n\nfunction renameDuplicateFields(fieldOrder) {\n  return fieldOrder.reduce(function (accu, field, i) {\n    var allNames = accu.allNames;\n    var fieldName = field; // add a counter to duplicated names\n\n    if (allNames.includes(field)) {\n      var counter = 0;\n      while (allNames.includes(\"\".concat(field, \"-\").concat(counter))) {\n        counter++;\n      }\n      fieldName = \"\".concat(field, \"-\").concat(counter);\n    }\n    accu.fieldByIndex[i] = fieldName;\n    accu.allNames.push(fieldName);\n    return accu;\n  }, {\n    allNames: [],\n    fieldByIndex: {}\n  });\n}\n/**\n * Convert type-analyzer output to kepler.gl field types\n *\n * @param aType\n * @returns corresponding type in `ALL_FIELD_TYPES`\n * @type {typeof import('./data-processor').analyzerTypeToFieldType}}\n */\n\n/* eslint-disable complexity */\n\nfunction analyzerTypeToFieldType(aType) {\n  var DATE = _typeAnalyzer.DATA_TYPES.DATE,\n    TIME = _typeAnalyzer.DATA_TYPES.TIME,\n    DATETIME = _typeAnalyzer.DATA_TYPES.DATETIME,\n    NUMBER = _typeAnalyzer.DATA_TYPES.NUMBER,\n    INT = _typeAnalyzer.DATA_TYPES.INT,\n    FLOAT = _typeAnalyzer.DATA_TYPES.FLOAT,\n    BOOLEAN = _typeAnalyzer.DATA_TYPES.BOOLEAN,\n    STRING = _typeAnalyzer.DATA_TYPES.STRING,\n    GEOMETRY = _typeAnalyzer.DATA_TYPES.GEOMETRY,\n    GEOMETRY_FROM_STRING = _typeAnalyzer.DATA_TYPES.GEOMETRY_FROM_STRING,\n    PAIR_GEOMETRY_FROM_STRING = _typeAnalyzer.DATA_TYPES.PAIR_GEOMETRY_FROM_STRING,\n    ZIPCODE = _typeAnalyzer.DATA_TYPES.ZIPCODE,\n    ARRAY = _typeAnalyzer.DATA_TYPES.ARRAY,\n    OBJECT = _typeAnalyzer.DATA_TYPES.OBJECT; // TODO: un recognized types\n  // CURRENCY PERCENT NONE\n\n  switch (aType) {\n    case DATE:\n      return _defaultSettings.ALL_FIELD_TYPES.date;\n    case TIME:\n    case DATETIME:\n      return _defaultSettings.ALL_FIELD_TYPES.timestamp;\n    case FLOAT:\n      return _defaultSettings.ALL_FIELD_TYPES.real;\n    case INT:\n      return _defaultSettings.ALL_FIELD_TYPES.integer;\n    case BOOLEAN:\n      return _defaultSettings.ALL_FIELD_TYPES[\"boolean\"];\n    case GEOMETRY:\n    case GEOMETRY_FROM_STRING:\n    case PAIR_GEOMETRY_FROM_STRING:\n    case ARRAY:\n    case OBJECT:\n      // TODO: create a new data type for objects and arrays\n      return _defaultSettings.ALL_FIELD_TYPES.geojson;\n    case NUMBER:\n    case STRING:\n    case ZIPCODE:\n      return _defaultSettings.ALL_FIELD_TYPES.string;\n    default:\n      _window.console.warn(\"Unsupported analyzer type: \".concat(aType));\n      return _defaultSettings.ALL_FIELD_TYPES.string;\n  }\n}\n/* eslint-enable complexity */\n\n/**\n * Process data where each row is an object, output can be passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n * @param rawData an array of row object, each object should have the same number of keys\n * @returns dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processRowObject}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processRowObject} from 'kepler.gl/processors';\n *\n * const data = [\n *  {lat: 31.27, lng: 127.56, value: 3},\n *  {lat: 31.22, lng: 126.26, value: 1}\n * ];\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {label: 'My Data', id: 'my_data'},\n *    data: processRowObject(data)\n *  }\n * }));\n */\n\nfunction processRowObject(rawData) {\n  if (!Array.isArray(rawData) || !rawData.length) {\n    return null;\n  }\n  var keys = Object.keys(rawData[0]);\n  var rows = rawData.map(function (d) {\n    return keys.map(function (key) {\n      return d[key];\n    });\n  }); // row object an still contain values like `Null` or `N/A`\n\n  cleanUpFalsyCsvValue(rows);\n  return processCsvData(rows, keys);\n}\n/**\n * Process GeoJSON [`FeatureCollection`](http://wiki.geojson.org/GeoJSON_draft_version_6#FeatureCollection),\n * output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n *\n * @param  rawData raw geojson feature collection\n * @returns  dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processGeojson}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processGeojson} from 'kepler.gl/processors';\n *\n * const geojson = {\n * \t\"type\" : \"FeatureCollection\",\n * \t\"features\" : [{\n * \t\t\"type\" : \"Feature\",\n * \t\t\"properties\" : {\n * \t\t\t\"capacity\" : \"10\",\n * \t\t\t\"type\" : \"U-Rack\"\n * \t\t},\n * \t\t\"geometry\" : {\n * \t\t\t\"type\" : \"Point\",\n * \t\t\t\"coordinates\" : [ -71.073283, 42.417500 ]\n * \t\t}\n * \t}]\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {\n *      label: 'Sample Taxi Trips in New York City',\n *      id: 'test_trip_data'\n *    },\n *    data: processGeojson(geojson)\n *  }\n * }));\n */\n\nfunction processGeojson(rawData) {\n  var normalizedGeojson = (0, _geojsonNormalize[\"default\"])(rawData);\n  if (!normalizedGeojson || !Array.isArray(normalizedGeojson.features)) {\n    var error = new Error(\"Read File Failed: File is not a valid GeoJSON. Read more about [supported file format](\".concat(_userGuides.GUIDES_FILE_FORMAT_DOC, \")\"));\n    throw error; // fail to normalize geojson\n  } // getting all feature fields\n\n  var allDataRows = [];\n  for (var i = 0; i < normalizedGeojson.features.length; i++) {\n    var f = normalizedGeojson.features[i];\n    if (f.geometry) {\n      allDataRows.push(_objectSpread({\n        // add feature to _geojson field\n        _geojson: f\n      }, f.properties || {}));\n    }\n  } // get all the field\n\n  var fields = allDataRows.reduce(function (prev, curr) {\n    Object.keys(curr).forEach(function (key) {\n      if (!prev.includes(key)) {\n        prev.push(key);\n      }\n    });\n    return prev;\n  }, []); // make sure each feature has exact same fields\n\n  allDataRows.forEach(function (d) {\n    fields.forEach(function (f) {\n      if (!(f in d)) {\n        d[f] = null;\n        d._geojson.properties[f] = null;\n      }\n    });\n  });\n  return processRowObject(allDataRows);\n}\n/**\n * On export data to csv\n * @param {import('utils/table-utils/data-container-interface').DataContainerInterface} dataContainer\n * @param {Array<Object>} fields `dataset.fields`\n * @returns {string} csv string\n */\n\nfunction formatCsv(dataContainer, fields) {\n  var columns = fields.map(function (f) {\n    return f.displayName || f.name;\n  });\n  var formattedData = [columns]; // parse geojson object as string\n\n  var _iterator = _createForOfIteratorHelper(dataContainer.rows(true)),\n    _step;\n  try {\n    for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var row = _step.value;\n      formattedData.push(row.map(function (d, i) {\n        return (0, _dataUtils.parseFieldValue)(d, fields[i].type);\n      }));\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n  return (0, _d3Dsv.csvFormatRows)(formattedData);\n}\n/**\n * Validate input data, adding missing field types, rename duplicate columns\n * @type {typeof import('./data-processor').validateInputData}\n */\n\nfunction validateInputData(data) {\n  if (!(0, _utils.isPlainObject)(data)) {\n    (0, _assert[\"default\"])('addDataToMap Error: dataset.data cannot be null');\n    return null;\n  } else if (!Array.isArray(data.fields)) {\n    (0, _assert[\"default\"])('addDataToMap Error: expect dataset.data.fields to be an array');\n    return null;\n  } else if (!Array.isArray(data.rows)) {\n    (0, _assert[\"default\"])('addDataToMap Error: expect dataset.data.rows to be an array');\n    return null;\n  }\n  var fields = data.fields,\n    rows = data.rows; // check if all fields has name, format and type\n\n  var allValid = fields.every(function (f, i) {\n    if (!(0, _utils.isPlainObject)(f)) {\n      (0, _assert[\"default\"])(\"fields needs to be an array of object, but find \".concat((0, _typeof2[\"default\"])(f)));\n      fields[i] = {};\n    }\n    if (!f.name) {\n      (0, _assert[\"default\"])(\"field.name is required but missing in \".concat(JSON.stringify(f))); // assign a name\n\n      fields[i].name = \"column_\".concat(i);\n    }\n    if (!_defaultSettings.ALL_FIELD_TYPES[f.type]) {\n      (0, _assert[\"default\"])(\"unknown field type \".concat(f.type));\n      return false;\n    }\n    if (!fields.every(function (field) {\n      return field.analyzerType;\n    })) {\n      (0, _assert[\"default\"])('field missing analyzerType');\n      return false;\n    } // check time format is correct based on first 10 not empty element\n\n    if (f.type === _defaultSettings.ALL_FIELD_TYPES.timestamp) {\n      var sample = findNonEmptyRowsAtField(rows, i, 10).map(function (r) {\n        return {\n          ts: r[i]\n        };\n      });\n      var analyzedType = _typeAnalyzer.Analyzer.computeColMeta(sample)[0];\n      return analyzedType && analyzedType.category === 'TIME' && analyzedType.format === f.format;\n    }\n    return true;\n  });\n  if (allValid) {\n    return {\n      rows: rows,\n      fields: fields\n    };\n  } // if any field has missing type, recalculate it for everyone\n  // because we simply lost faith in humanity\n\n  var sampleData = getSampleForTypeAnalyze({\n    fields: fields.map(function (f) {\n      return f.name;\n    }),\n    rows: rows\n  });\n  var fieldOrder = fields.map(function (f) {\n    return f.name;\n  });\n  var meta = getFieldsFromData(sampleData, fieldOrder);\n  var updatedFields = fields.map(function (f, i) {\n    return _objectSpread(_objectSpread({}, f), {}, {\n      type: meta[i].type,\n      format: meta[i].format,\n      analyzerType: meta[i].analyzerType\n    });\n  });\n  return {\n    fields: updatedFields,\n    rows: rows\n  };\n}\nfunction findNonEmptyRowsAtField(rows, fieldIdx, total) {\n  var sample = [];\n  var i = 0;\n  while (sample.length < total && i < rows.length) {\n    if ((0, _dataUtils.notNullorUndefined)(rows[i][fieldIdx])) {\n      sample.push(rows[i]);\n    }\n    i++;\n  }\n  return sample;\n}\n/**\n * Process saved kepler.gl json to be pass to [`addDataToMap`](../actions/actions.md#adddatatomap).\n * The json object should contain `datasets` and `config`.\n * @param {Object} rawData\n * @param {Array} rawData.datasets\n * @param {Object} rawData.config\n * @returns {Object} datasets and config `{datasets: {}, config: {}}`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processKeplerglJSON} from 'kepler.gl/processors';\n *\n * dispatch(addDataToMap(processKeplerglJSON(keplerGlJson)));\n */\n\nfunction processKeplerglJSON(rawData) {\n  return rawData ? _schemas[\"default\"].load(rawData.datasets, rawData.config) : null;\n}\n/**\n * Parse a single or an array of datasets saved using kepler.gl schema\n * @param {Array | Array<Object>} rawData\n */\n\nfunction processKeplerglDataset(rawData) {\n  if (!rawData) {\n    return null;\n  }\n  var results = _schemas[\"default\"].parseSavedData((0, _utils.toArray)(rawData));\n  if (!results) {\n    return null;\n  }\n  return Array.isArray(rawData) ? results : results[0];\n}\nvar DATASET_HANDLERS = (_DATASET_HANDLERS = {}, (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.row, processRowObject), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.geojson, processGeojson), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.csv, processCsvData), (0, _defineProperty2[\"default\"])(_DATASET_HANDLERS, _defaultSettings.DATASET_FORMATS.keplergl, processKeplerglDataset), _DATASET_HANDLERS);\nexports.DATASET_HANDLERS = DATASET_HANDLERS;\nvar Processors = {\n  processGeojson: processGeojson,\n  processCsvData: processCsvData,\n  processRowObject: processRowObject,\n  processKeplerglJSON: processKeplerglJSON,\n  processKeplerglDataset: processKeplerglDataset,\n  analyzerTypeToFieldType: analyzerTypeToFieldType,\n  getFieldsFromData: getFieldsFromData,\n  parseCsvRowsByFieldType: parseCsvRowsByFieldType,\n  formatCsv: formatCsv\n};\nexports.Processors = Processors;","map":{"version":3,"names":["_d3Dsv","require","_d3Array","_window","_assert","_interopRequireDefault","_typeAnalyzer","_geojsonNormalize","_defaultSettings","_dataUtils","_schemas","_userGuides","_utils","ACCEPTED_ANALYZER_TYPES","DATA_TYPES","DATE","TIME","DATETIME","NUMBER","INT","FLOAT","BOOLEAN","STRING","GEOMETRY","GEOMETRY_FROM_STRING","PAIR_GEOMETRY_FROM_STRING","ZIPCODE","ARRAY","OBJECT","CSV_NULLS","IGNORE_DATA_TYPES","Object","keys","filter","type","includes","PARSE_FIELD_VALUE_FROM_STRING","_PARSE_FIELD_VALUE_FR","_defineProperty2","ALL_FIELD_TYPES","valid","d","parse","integer","parseInt","timestamp","field","format","Number","real","parseFloat","processCsvData","rawData","header","rows","headerRow","_parsedRows","csvParseRows","Array","isArray","length","Error","slice","cleanUpFalsyCsvValue","sample","getSampleForTypeAnalyze","fields","getFieldsFromData","parsedRows","parseRowsByFields","geojsonFieldIdx","findIndex","f","name","forEach","parseCsvRowsByFieldType","bind","_ref","_ref$sampleCount","sampleCount","total","Math","min","range","map","fieldIdx","i","j","notNullorUndefined","value","trim","re","RegExp","match","geoFieldIdx","parser","first","find","r","row","properties","data","fieldOrder","metadata","Analyzer","computeColMeta","regex","dataType","ignoredDataTypes","_renameDuplicateField","renameDuplicateFields","fieldByIndex","result","index","fieldMeta","m","key","_ref2","id","displayName","analyzerTypeToFieldType","analyzerType","valueAccessor","dc","valueAt","reduce","accu","allNames","fieldName","counter","concat","push","aType","date","geojson","string","console","warn","processRowObject","processGeojson","normalizedGeojson","features","error","GUIDES_FILE_FORMAT_DOC","allDataRows","geometry","_objectSpread","_geojson","prev","curr","formatCsv","dataContainer","columns","formattedData","_iterator","_createForOfIteratorHelper","_step","s","n","done","parseFieldValue","err","e","csvFormatRows","validateInputData","isPlainObject","allValid","every","_typeof2","JSON","stringify","findNonEmptyRowsAtField","ts","analyzedType","category","sampleData","meta","updatedFields","processKeplerglJSON","load","datasets","config","processKeplerglDataset","results","parseSavedData","toArray","DATASET_HANDLERS","_DATASET_HANDLERS","DATASET_FORMATS","csv","keplergl","Processors"],"sources":["/Users/rohinphukan/Desktop/RefugeeWebsite/node_modules/kepler.gl/src/processors/data-processor.js"],"sourcesContent":["// Copyright (c) 2021 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\nimport {csvParseRows, csvFormatRows} from 'd3-dsv';\nimport {range} from 'd3-array';\nimport {console as globalConsole} from 'global/window';\nimport assert from 'assert';\nimport {Analyzer, DATA_TYPES as AnalyzerDATA_TYPES} from 'type-analyzer';\nimport normalize from '@mapbox/geojson-normalize';\nimport {ALL_FIELD_TYPES, DATASET_FORMATS} from 'constants/default-settings';\nimport {notNullorUndefined, parseFieldValue} from 'utils/data-utils';\nimport KeplerGlSchema from 'schemas';\nimport {GUIDES_FILE_FORMAT_DOC} from 'constants/user-guides';\nimport {isPlainObject, toArray} from 'utils/utils';\n\nexport const ACCEPTED_ANALYZER_TYPES = [\n  AnalyzerDATA_TYPES.DATE,\n  AnalyzerDATA_TYPES.TIME,\n  AnalyzerDATA_TYPES.DATETIME,\n  AnalyzerDATA_TYPES.NUMBER,\n  AnalyzerDATA_TYPES.INT,\n  AnalyzerDATA_TYPES.FLOAT,\n  AnalyzerDATA_TYPES.BOOLEAN,\n  AnalyzerDATA_TYPES.STRING,\n  AnalyzerDATA_TYPES.GEOMETRY,\n  AnalyzerDATA_TYPES.GEOMETRY_FROM_STRING,\n  AnalyzerDATA_TYPES.PAIR_GEOMETRY_FROM_STRING,\n  AnalyzerDATA_TYPES.ZIPCODE,\n  AnalyzerDATA_TYPES.ARRAY,\n  AnalyzerDATA_TYPES.OBJECT\n];\n\n// if any of these value occurs in csv, parse it to null;\n// const CSV_NULLS = ['', 'null', 'NULL', 'Null', 'NaN', '/N'];\n// matches empty string\nexport const CSV_NULLS = /^(null|NULL|Null|NaN|\\/N||)$/;\n\nconst IGNORE_DATA_TYPES = Object.keys(AnalyzerDATA_TYPES).filter(\n  type => !ACCEPTED_ANALYZER_TYPES.includes(type)\n);\n\nexport const PARSE_FIELD_VALUE_FROM_STRING = {\n  [ALL_FIELD_TYPES.boolean]: {\n    valid: d => typeof d === 'boolean',\n    parse: d => d === 'true' || d === 'True' || d === 'TRUE' || d === '1'\n  },\n  [ALL_FIELD_TYPES.integer]: {\n    valid: d => parseInt(d, 10) === d,\n    parse: d => parseInt(d, 10)\n  },\n  [ALL_FIELD_TYPES.timestamp]: {\n    valid: (d, field) =>\n      ['x', 'X'].includes(field.format) ? typeof d === 'number' : typeof d === 'string',\n    parse: (d, field) => (['x', 'X'].includes(field.format) ? Number(d) : d)\n  },\n  [ALL_FIELD_TYPES.real]: {\n    valid: d => parseFloat(d) === d,\n    // Note this will result in NaN for some string\n    parse: parseFloat\n  }\n};\n\n/**\n * Process csv data, output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and pass to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * @param rawData raw csv string\n * @returns  data object `{fields: [], rows: []}` can be passed to addDataToMaps\n * @type {typeof import('./data-processor').processCsvData}\n * @public\n * @example\n * import {processCsvData} from 'kepler.gl/processors';\n *\n * const testData = `gps_data.utc_timestamp,gps_data.lat,gps_data.lng,gps_data.types,epoch,has_result,id,time,begintrip_ts_utc,begintrip_ts_local,date\n * 2016-09-17 00:09:55,29.9900937,31.2590542,driver_analytics,1472688000000,False,1,2016-09-23T00:00:00.000Z,2016-10-01 09:41:39+00:00,2016-10-01 09:41:39+00:00,2016-09-23\n * 2016-09-17 00:10:56,29.9927699,31.2461142,driver_analytics,1472688000000,False,2,2016-09-23T00:00:00.000Z,2016-10-01 09:46:37+00:00,2016-10-01 16:46:37+00:00,2016-09-23\n * 2016-09-17 00:11:56,29.9907261,31.2312742,driver_analytics,1472688000000,False,3,2016-09-23T00:00:00.000Z,,,2016-09-23\n * 2016-09-17 00:12:58,29.9870074,31.2175827,driver_analytics,1472688000000,False,4,2016-09-23T00:00:00.000Z,,,2016-09-23`\n *\n * const dataset = {\n *  info: {id: 'test_data', label: 'My Csv'},\n *  data: processCsvData(testData)\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: [dataset],\n *  options: {centerMap: true, readOnly: true}\n * }));\n */\nexport function processCsvData(rawData, header) {\n  let rows;\n  let headerRow;\n\n  if (typeof rawData === 'string') {\n    const parsedRows = csvParseRows(rawData);\n\n    if (!Array.isArray(parsedRows) || parsedRows.length < 2) {\n      // looks like an empty file, throw error to be catch\n      throw new Error('process Csv Data Failed: CSV is empty');\n    }\n    headerRow = parsedRows[0];\n    rows = parsedRows.slice(1);\n  } else if (Array.isArray(rawData) && rawData.length) {\n    rows = rawData;\n    headerRow = header;\n\n    if (!Array.isArray(headerRow)) {\n      // if data is passed in as array of rows and missing header\n      // assume first row is header\n      headerRow = rawData[0];\n      rows = rawData.slice(1);\n    }\n  }\n\n  if (!rows || !headerRow) {\n    throw new Error('invalid input passed to processCsvData');\n  }\n\n  // here we assume the csv file that people uploaded will have first row\n  // as name of the column\n\n  cleanUpFalsyCsvValue(rows);\n  // No need to run type detection on every data point\n  // here we get a list of none null values to run analyze on\n  const sample = getSampleForTypeAnalyze({fields: headerRow, rows});\n  const fields = getFieldsFromData(sample, headerRow);\n  const parsedRows = parseRowsByFields(rows, fields);\n\n  return {fields, rows: parsedRows};\n}\n\n/**\n * Parse rows of csv by analyzed field types. So that `'1'` -> `1`, `'True'` -> `true`\n * @param {Array<Array>} rows\n * @param {Array<Object>} fields\n */\nexport function parseRowsByFields(rows, fields) {\n  // Edit rows in place\n  const geojsonFieldIdx = fields.findIndex(f => f.name === '_geojson');\n  fields.forEach(parseCsvRowsByFieldType.bind(null, rows, geojsonFieldIdx));\n\n  return rows;\n}\n/**\n * Getting sample data for analyzing field type.\n *\n * @type {typeof import('./data-processor').getSampleForTypeAnalyze}\n */\nexport function getSampleForTypeAnalyze({fields, rows, sampleCount = 50}) {\n  const total = Math.min(sampleCount, rows.length);\n  // const fieldOrder = fields.map(f => f.name);\n  const sample = range(0, total, 1).map(d => ({}));\n\n  // collect sample data for each field\n  fields.forEach((field, fieldIdx) => {\n    // data counter\n    let i = 0;\n    // sample counter\n    let j = 0;\n\n    while (j < total) {\n      if (i >= rows.length) {\n        // if depleted data pool\n        sample[j][field] = null;\n        j++;\n      } else if (notNullorUndefined(rows[i][fieldIdx])) {\n        const value = rows[i][fieldIdx];\n        sample[j][field] = typeof value === 'string' ? value.trim() : value;\n        j++;\n        i++;\n      } else {\n        i++;\n      }\n    }\n  });\n\n  return sample;\n}\n\n/**\n * Convert falsy value in csv including `'', 'null', 'NULL', 'Null', 'NaN'` to `null`,\n * so that type-analyzer won't detect it as string\n *\n * @param {Array<Array>} rows\n */\nfunction cleanUpFalsyCsvValue(rows) {\n  const re = new RegExp(CSV_NULLS, 'g');\n  for (let i = 0; i < rows.length; i++) {\n    for (let j = 0; j < rows[i].length; j++) {\n      // analyzer will set any fields to 'string' if there are empty values\n      // which will be parsed as '' by d3.csv\n      // here we parse empty data as null\n      // TODO: create warning when deltect `CSV_NULLS` in the data\n      if (typeof rows[i][j] === 'string' && rows[i][j].match(re)) {\n        rows[i][j] = null;\n      }\n    }\n  }\n}\n\n/**\n * Process uploaded csv file to parse value by field type\n *\n * @param rows\n * @param geoFieldIdx field index\n * @param field\n * @param i\n * @type {typeof import('./data-processor').parseCsvRowsByFieldType}\n */\nexport function parseCsvRowsByFieldType(rows, geoFieldIdx, field, i) {\n  const parser = PARSE_FIELD_VALUE_FROM_STRING[field.type];\n  if (parser) {\n    // check first not null value of it's already parsed\n    const first = rows.find(r => notNullorUndefined(r[i]));\n    if (!first || parser.valid(first[i], field)) {\n      return;\n    }\n    rows.forEach(row => {\n      // parse string value based on field type\n      if (row[i] !== null) {\n        row[i] = parser.parse(row[i], field);\n        if (geoFieldIdx > -1 && row[geoFieldIdx] && row[geoFieldIdx].properties) {\n          row[geoFieldIdx].properties[field.name] = row[i];\n        }\n      }\n    });\n  }\n}\n\n/**\n * Analyze field types from data in `string` format, e.g. uploaded csv.\n * Assign `type`, `fieldIdx` and `format` (timestamp only) to each field\n *\n * @param data array of row object\n * @param fieldOrder array of field names as string\n * @returns formatted fields\n * @type {typeof import('./data-processor').getFieldsFromData}\n * @public\n * @example\n *\n * import {getFieldsFromData} from 'kepler.gl/processors';\n * const data = [{\n *   time: '2016-09-17 00:09:55',\n *   value: '4',\n *   surge: '1.2',\n *   isTrip: 'true',\n *   zeroOnes: '0'\n * }, {\n *   time: '2016-09-17 00:30:08',\n *   value: '3',\n *   surge: null,\n *   isTrip: 'false',\n *   zeroOnes: '1'\n * }, {\n *   time: null,\n *   value: '2',\n *   surge: '1.3',\n *   isTrip: null,\n *   zeroOnes: '1'\n * }];\n *\n * const fieldOrder = ['time', 'value', 'surge', 'isTrip', 'zeroOnes'];\n * const fields = getFieldsFromData(data, fieldOrder);\n * // fields = [\n * // {name: 'time', format: 'YYYY-M-D H:m:s', fieldIdx: 1, type: 'timestamp'},\n * // {name: 'value', format: '', fieldIdx: 4, type: 'integer'},\n * // {name: 'surge', format: '', fieldIdx: 5, type: 'real'},\n * // {name: 'isTrip', format: '', fieldIdx: 6, type: 'boolean'},\n * // {name: 'zeroOnes', format: '', fieldIdx: 7, type: 'integer'}];\n *\n */\nexport function getFieldsFromData(data, fieldOrder) {\n  // add a check for epoch timestamp\n  const metadata = Analyzer.computeColMeta(\n    data,\n    [\n      {regex: /.*geojson|all_points/g, dataType: 'GEOMETRY'},\n      {regex: /.*census/g, dataType: 'STRING'}\n    ],\n    {ignoredDataTypes: IGNORE_DATA_TYPES}\n  );\n\n  const {fieldByIndex} = renameDuplicateFields(fieldOrder);\n\n  const result = fieldOrder.map((field, index) => {\n    const name = fieldByIndex[index];\n\n    const fieldMeta = metadata.find(m => m.key === field);\n    const {type, format} = fieldMeta || {};\n\n    return {\n      name,\n      id: name,\n      displayName: name,\n      format,\n      fieldIdx: index,\n      type: analyzerTypeToFieldType(type),\n      analyzerType: type,\n      valueAccessor: dc => d => {\n        return dc.valueAt(d.index, index);\n      }\n    };\n  });\n\n  // @ts-ignore\n  return result;\n}\n\n/**\n * pass in an array of field names, rename duplicated one\n * and return a map from old field index to new name\n *\n * @param {Array} fieldOrder\n * @returns {Object} new field name by index\n */\nexport function renameDuplicateFields(fieldOrder) {\n  return fieldOrder.reduce(\n    (accu, field, i) => {\n      const {allNames} = accu;\n      let fieldName = field;\n\n      // add a counter to duplicated names\n      if (allNames.includes(field)) {\n        let counter = 0;\n        while (allNames.includes(`${field}-${counter}`)) {\n          counter++;\n        }\n        fieldName = `${field}-${counter}`;\n      }\n\n      accu.fieldByIndex[i] = fieldName;\n      accu.allNames.push(fieldName);\n\n      return accu;\n    },\n    {allNames: [], fieldByIndex: {}}\n  );\n}\n\n/**\n * Convert type-analyzer output to kepler.gl field types\n *\n * @param aType\n * @returns corresponding type in `ALL_FIELD_TYPES`\n * @type {typeof import('./data-processor').analyzerTypeToFieldType}}\n */\n/* eslint-disable complexity */\nexport function analyzerTypeToFieldType(aType) {\n  const {\n    DATE,\n    TIME,\n    DATETIME,\n    NUMBER,\n    INT,\n    FLOAT,\n    BOOLEAN,\n    STRING,\n    GEOMETRY,\n    GEOMETRY_FROM_STRING,\n    PAIR_GEOMETRY_FROM_STRING,\n    ZIPCODE,\n    ARRAY,\n    OBJECT\n  } = AnalyzerDATA_TYPES;\n\n  // TODO: un recognized types\n  // CURRENCY PERCENT NONE\n  switch (aType) {\n    case DATE:\n      return ALL_FIELD_TYPES.date;\n    case TIME:\n    case DATETIME:\n      return ALL_FIELD_TYPES.timestamp;\n    case FLOAT:\n      return ALL_FIELD_TYPES.real;\n    case INT:\n      return ALL_FIELD_TYPES.integer;\n    case BOOLEAN:\n      return ALL_FIELD_TYPES.boolean;\n    case GEOMETRY:\n    case GEOMETRY_FROM_STRING:\n    case PAIR_GEOMETRY_FROM_STRING:\n    case ARRAY:\n    case OBJECT:\n      // TODO: create a new data type for objects and arrays\n      return ALL_FIELD_TYPES.geojson;\n    case NUMBER:\n    case STRING:\n    case ZIPCODE:\n      return ALL_FIELD_TYPES.string;\n    default:\n      globalConsole.warn(`Unsupported analyzer type: ${aType}`);\n      return ALL_FIELD_TYPES.string;\n  }\n}\n/* eslint-enable complexity */\n\n/**\n * Process data where each row is an object, output can be passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n * @param rawData an array of row object, each object should have the same number of keys\n * @returns dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processRowObject}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processRowObject} from 'kepler.gl/processors';\n *\n * const data = [\n *  {lat: 31.27, lng: 127.56, value: 3},\n *  {lat: 31.22, lng: 126.26, value: 1}\n * ];\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {label: 'My Data', id: 'my_data'},\n *    data: processRowObject(data)\n *  }\n * }));\n */\nexport function processRowObject(rawData) {\n  if (!Array.isArray(rawData) || !rawData.length) {\n    return null;\n  }\n\n  const keys = Object.keys(rawData[0]);\n  const rows = rawData.map(d => keys.map(key => d[key]));\n\n  // row object an still contain values like `Null` or `N/A`\n  cleanUpFalsyCsvValue(rows);\n\n  return processCsvData(rows, keys);\n}\n\n/**\n * Process GeoJSON [`FeatureCollection`](http://wiki.geojson.org/GeoJSON_draft_version_6#FeatureCollection),\n * output a data object with `{fields: [], rows: []}`.\n * The data object can be wrapped in a `dataset` and passed to [`addDataToMap`](../actions/actions.md#adddatatomap)\n * NOTE: This function may mutate input.\n *\n * @param  rawData raw geojson feature collection\n * @returns  dataset containing `fields` and `rows`\n * @type {typeof import('./data-processor').processGeojson}\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processGeojson} from 'kepler.gl/processors';\n *\n * const geojson = {\n * \t\"type\" : \"FeatureCollection\",\n * \t\"features\" : [{\n * \t\t\"type\" : \"Feature\",\n * \t\t\"properties\" : {\n * \t\t\t\"capacity\" : \"10\",\n * \t\t\t\"type\" : \"U-Rack\"\n * \t\t},\n * \t\t\"geometry\" : {\n * \t\t\t\"type\" : \"Point\",\n * \t\t\t\"coordinates\" : [ -71.073283, 42.417500 ]\n * \t\t}\n * \t}]\n * };\n *\n * dispatch(addDataToMap({\n *  datasets: {\n *    info: {\n *      label: 'Sample Taxi Trips in New York City',\n *      id: 'test_trip_data'\n *    },\n *    data: processGeojson(geojson)\n *  }\n * }));\n */\nexport function processGeojson(rawData) {\n  const normalizedGeojson = normalize(rawData);\n\n  if (!normalizedGeojson || !Array.isArray(normalizedGeojson.features)) {\n    const error = new Error(\n      `Read File Failed: File is not a valid GeoJSON. Read more about [supported file format](${GUIDES_FILE_FORMAT_DOC})`\n    );\n    throw error;\n    // fail to normalize geojson\n  }\n\n  // getting all feature fields\n  const allDataRows = [];\n  for (let i = 0; i < normalizedGeojson.features.length; i++) {\n    const f = normalizedGeojson.features[i];\n    if (f.geometry) {\n      allDataRows.push({\n        // add feature to _geojson field\n        _geojson: f,\n        ...(f.properties || {})\n      });\n    }\n  }\n  // get all the field\n  const fields = allDataRows.reduce((prev, curr) => {\n    Object.keys(curr).forEach(key => {\n      if (!prev.includes(key)) {\n        prev.push(key);\n      }\n    });\n    return prev;\n  }, []);\n\n  // make sure each feature has exact same fields\n  allDataRows.forEach(d => {\n    fields.forEach(f => {\n      if (!(f in d)) {\n        d[f] = null;\n        d._geojson.properties[f] = null;\n      }\n    });\n  });\n\n  return processRowObject(allDataRows);\n}\n\n/**\n * On export data to csv\n * @param {import('utils/table-utils/data-container-interface').DataContainerInterface} dataContainer\n * @param {Array<Object>} fields `dataset.fields`\n * @returns {string} csv string\n */\nexport function formatCsv(dataContainer, fields) {\n  const columns = fields.map(f => f.displayName || f.name);\n  const formattedData = [columns];\n\n  // parse geojson object as string\n  for (const row of dataContainer.rows(true)) {\n    formattedData.push(row.map((d, i) => parseFieldValue(d, fields[i].type)));\n  }\n\n  return csvFormatRows(formattedData);\n}\n\n/**\n * Validate input data, adding missing field types, rename duplicate columns\n * @type {typeof import('./data-processor').validateInputData}\n */\nexport function validateInputData(data) {\n  if (!isPlainObject(data)) {\n    assert('addDataToMap Error: dataset.data cannot be null');\n    return null;\n  } else if (!Array.isArray(data.fields)) {\n    assert('addDataToMap Error: expect dataset.data.fields to be an array');\n    return null;\n  } else if (!Array.isArray(data.rows)) {\n    assert('addDataToMap Error: expect dataset.data.rows to be an array');\n    return null;\n  }\n\n  const {fields, rows} = data;\n\n  // check if all fields has name, format and type\n  const allValid = fields.every((f, i) => {\n    if (!isPlainObject(f)) {\n      assert(`fields needs to be an array of object, but find ${typeof f}`);\n      fields[i] = {};\n    }\n\n    if (!f.name) {\n      assert(`field.name is required but missing in ${JSON.stringify(f)}`);\n      // assign a name\n      fields[i].name = `column_${i}`;\n    }\n\n    if (!ALL_FIELD_TYPES[f.type]) {\n      assert(`unknown field type ${f.type}`);\n      return false;\n    }\n\n    if (!fields.every(field => field.analyzerType)) {\n      assert('field missing analyzerType');\n      return false;\n    }\n\n    // check time format is correct based on first 10 not empty element\n    if (f.type === ALL_FIELD_TYPES.timestamp) {\n      const sample = findNonEmptyRowsAtField(rows, i, 10).map(r => ({ts: r[i]}));\n      const analyzedType = Analyzer.computeColMeta(sample)[0];\n      return analyzedType && analyzedType.category === 'TIME' && analyzedType.format === f.format;\n    }\n\n    return true;\n  });\n\n  if (allValid) {\n    return {rows, fields};\n  }\n\n  // if any field has missing type, recalculate it for everyone\n  // because we simply lost faith in humanity\n  const sampleData = getSampleForTypeAnalyze({\n    fields: fields.map(f => f.name),\n    rows\n  });\n  const fieldOrder = fields.map(f => f.name);\n  const meta = getFieldsFromData(sampleData, fieldOrder);\n  const updatedFields = fields.map((f, i) => ({\n    ...f,\n    type: meta[i].type,\n    format: meta[i].format,\n    analyzerType: meta[i].analyzerType\n  }));\n\n  return {fields: updatedFields, rows};\n}\n\nfunction findNonEmptyRowsAtField(rows, fieldIdx, total) {\n  const sample = [];\n  let i = 0;\n  while (sample.length < total && i < rows.length) {\n    if (notNullorUndefined(rows[i][fieldIdx])) {\n      sample.push(rows[i]);\n    }\n    i++;\n  }\n  return sample;\n}\n\n/**\n * Process saved kepler.gl json to be pass to [`addDataToMap`](../actions/actions.md#adddatatomap).\n * The json object should contain `datasets` and `config`.\n * @param {Object} rawData\n * @param {Array} rawData.datasets\n * @param {Object} rawData.config\n * @returns {Object} datasets and config `{datasets: {}, config: {}}`\n * @public\n * @example\n * import {addDataToMap} from 'kepler.gl/actions';\n * import {processKeplerglJSON} from 'kepler.gl/processors';\n *\n * dispatch(addDataToMap(processKeplerglJSON(keplerGlJson)));\n */\nexport function processKeplerglJSON(rawData) {\n  return rawData ? KeplerGlSchema.load(rawData.datasets, rawData.config) : null;\n}\n\n/**\n * Parse a single or an array of datasets saved using kepler.gl schema\n * @param {Array | Array<Object>} rawData\n */\nexport function processKeplerglDataset(rawData) {\n  if (!rawData) {\n    return null;\n  }\n\n  const results = KeplerGlSchema.parseSavedData(toArray(rawData));\n  if (!results) {\n    return null;\n  }\n  return Array.isArray(rawData) ? results : results[0];\n}\n\nexport const DATASET_HANDLERS = {\n  [DATASET_FORMATS.row]: processRowObject,\n  [DATASET_FORMATS.geojson]: processGeojson,\n  [DATASET_FORMATS.csv]: processCsvData,\n  [DATASET_FORMATS.keplergl]: processKeplerglDataset\n};\n\nexport const Processors = {\n  processGeojson,\n  processCsvData,\n  processRowObject,\n  processKeplerglJSON,\n  processKeplerglDataset,\n  analyzerTypeToFieldType,\n  getFieldsFromData,\n  parseCsvRowsByFieldType,\n  formatCsv\n};\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;AAoBA,IAAAA,MAAA,GAAAC,OAAA;AACA,IAAAC,QAAA,GAAAD,OAAA;AACA,IAAAE,OAAA,GAAAF,OAAA;AACA,IAAAG,OAAA,GAAAC,sBAAA,CAAAJ,OAAA;AACA,IAAAK,aAAA,GAAAL,OAAA;AACA,IAAAM,iBAAA,GAAAF,sBAAA,CAAAJ,OAAA;AACA,IAAAO,gBAAA,GAAAP,OAAA;AACA,IAAAQ,UAAA,GAAAR,OAAA;AACA,IAAAS,QAAA,GAAAL,sBAAA,CAAAJ,OAAA;AACA,IAAAU,WAAA,GAAAV,OAAA;AACA,IAAAW,MAAA,GAAAX,OAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEO,IAAMY,uBAAuB,GAAG,CACrCP,aAAA,CAAAQ,UAAA,CAAmBC,IADkB,EAErCT,aAAA,CAAAQ,UAAA,CAAmBE,IAFkB,EAGrCV,aAAA,CAAAQ,UAAA,CAAmBG,QAHkB,EAIrCX,aAAA,CAAAQ,UAAA,CAAmBI,MAJkB,EAKrCZ,aAAA,CAAAQ,UAAA,CAAmBK,GALkB,EAMrCb,aAAA,CAAAQ,UAAA,CAAmBM,KANkB,EAOrCd,aAAA,CAAAQ,UAAA,CAAmBO,OAPkB,EAQrCf,aAAA,CAAAQ,UAAA,CAAmBQ,MARkB,EASrChB,aAAA,CAAAQ,UAAA,CAAmBS,QATkB,EAUrCjB,aAAA,CAAAQ,UAAA,CAAmBU,oBAVkB,EAWrClB,aAAA,CAAAQ,UAAA,CAAmBW,yBAXkB,EAYrCnB,aAAA,CAAAQ,UAAA,CAAmBY,OAZkB,EAarCpB,aAAA,CAAAQ,UAAA,CAAmBa,KAbkB,EAcrCrB,aAAA,CAAAQ,UAAA,CAAmBc,MAdkB,CAAhC,C,CAiBP;AACA;AACA;;;AACO,IAAMC,SAAS,GAAG,8BAAlB;;AAEP,IAAMC,iBAAiB,GAAGC,MAAM,CAACC,IAAP,CAAY1B,aAAA,CAAAQ,UAAZ,EAAgCmB,MAAhC,CACxB,UAAAC,IAAI;EAAA,OAAI,CAACrB,uBAAuB,CAACsB,QAAxB,CAAiCD,IAAjC,CAAL;AAAA,CADoB,CAA1B;AAIO,IAAME,6BAA6B,IAAAC,qBAAA,WAAAC,gBAAA,aAAAD,qBAAA,EACvC7B,gBAAA,CAAA+B,eAAA,WADuC,EACb;EACzBC,KAAK,EAAE,SAAAA,MAAAC,CAAC;IAAA,OAAI,OAAOA,CAAP,KAAa,SAAjB;EAAA,CADiB;EAEzBC,KAAK,EAAE,SAAAA,MAAAD,CAAC;IAAA,OAAIA,CAAC,KAAK,MAAN,IAAgBA,CAAC,KAAK,MAAtB,IAAgCA,CAAC,KAAK,MAAtC,IAAgDA,CAAC,KAAK,GAA1D;EAAA;AAFiB,CADa,OAAAH,gBAAA,aAAAD,qBAAA,EAKvC7B,gBAAA,CAAA+B,eAAA,CAAgBI,OALuB,EAKb;EACzBH,KAAK,EAAE,SAAAA,MAAAC,CAAC;IAAA,OAAIG,QAAQ,CAACH,CAAD,EAAI,EAAJ,CAAR,KAAoBA,CAAxB;EAAA,CADiB;EAEzBC,KAAK,EAAE,SAAAA,MAAAD,CAAC;IAAA,OAAIG,QAAQ,CAACH,CAAD,EAAI,EAAJ,CAAZ;EAAA;AAFiB,CALa,OAAAH,gBAAA,aAAAD,qBAAA,EASvC7B,gBAAA,CAAA+B,eAAA,CAAgBM,SATuB,EASX;EAC3BL,KAAK,EAAE,SAAAA,MAACC,CAAD,EAAIK,KAAJ;IAAA,OACL,CAAC,GAAD,EAAM,GAAN,EAAWX,QAAX,CAAoBW,KAAK,CAACC,MAA1B,IAAoC,OAAON,CAAP,KAAa,QAAjD,GAA4D,OAAOA,CAAP,KAAa,QADpE;EAAA,CADoB;EAG3BC,KAAK,EAAE,SAAAA,MAACD,CAAD,EAAIK,KAAJ;IAAA,OAAe,CAAC,GAAD,EAAM,GAAN,EAAWX,QAAX,CAAoBW,KAAK,CAACC,MAA1B,IAAoCC,MAAM,CAACP,CAAD,CAA1C,GAAgDA,CAA/D;EAAA;AAHoB,CATW,OAAAH,gBAAA,aAAAD,qBAAA,EAcvC7B,gBAAA,CAAA+B,eAAA,CAAgBU,IAduB,EAchB;EACtBT,KAAK,EAAE,SAAAA,MAAAC,CAAC;IAAA,OAAIS,UAAU,CAACT,CAAD,CAAV,KAAkBA,CAAtB;EAAA,CADc;EAEtB;EACAC,KAAK,EAAEQ;AAHe,CAdgB,GAAAb,qBAAA,CAAnC;AAqBP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACO,SAASc,cAATA,CAAwBC,OAAxB,EAAiCC,MAAjC,EAAyC;EAC9C,IAAIC,IAAJ;EACA,IAAIC,SAAJ;EAEA,IAAI,OAAOH,OAAP,KAAmB,QAAvB,EAAiC;IAC/B,IAAMI,WAAU,GAAG,IAAAxD,MAAA,CAAAyD,YAAA,EAAaL,OAAb,CAAnB;IAEA,IAAI,CAACM,KAAK,CAACC,OAAN,CAAcH,WAAd,CAAD,IAA8BA,WAAU,CAACI,MAAX,GAAoB,CAAtD,EAAyD;MACvD;MACA,MAAM,IAAIC,KAAJ,CAAU,uCAAV,CAAN;IACD;IACDN,SAAS,GAAGC,WAAU,CAAC,CAAD,CAAtB;IACAF,IAAI,GAAGE,WAAU,CAACM,KAAX,CAAiB,CAAjB,CAAP;EACD,CATD,MASO,IAAIJ,KAAK,CAACC,OAAN,CAAcP,OAAd,KAA0BA,OAAO,CAACQ,MAAtC,EAA8C;IACnDN,IAAI,GAAGF,OAAP;IACAG,SAAS,GAAGF,MAAZ;IAEA,IAAI,CAACK,KAAK,CAACC,OAAN,CAAcJ,SAAd,CAAL,EAA+B;MAC7B;MACA;MACAA,SAAS,GAAGH,OAAO,CAAC,CAAD,CAAnB;MACAE,IAAI,GAAGF,OAAO,CAACU,KAAR,CAAc,CAAd,CAAP;IACD;EACF;EAED,IAAI,CAACR,IAAD,IAAS,CAACC,SAAd,EAAyB;IACvB,MAAM,IAAIM,KAAJ,CAAU,wCAAV,CAAN;EACD,CA3B6C,CA6B9C;EACA;;EAEAE,oBAAoB,CAACT,IAAD,CAApB,CAhC8C,CAiC9C;EACA;;EACA,IAAMU,MAAM,GAAGC,uBAAuB,CAAC;IAACC,MAAM,EAAEX,SAAT;IAAoBD,IAAI,EAAJA;EAApB,CAAD,CAAtC;EACA,IAAMY,MAAM,GAAGC,iBAAiB,CAACH,MAAD,EAAST,SAAT,CAAhC;EACA,IAAMa,UAAU,GAAGC,iBAAiB,CAACf,IAAD,EAAOY,MAAP,CAApC;EAEA,OAAO;IAACA,MAAM,EAANA,MAAD;IAASZ,IAAI,EAAEc;EAAf,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;;AACO,SAASC,iBAATA,CAA2Bf,IAA3B,EAAiCY,MAAjC,EAAyC;EAC9C;EACA,IAAMI,eAAe,GAAGJ,MAAM,CAACK,SAAP,CAAiB,UAAAC,CAAC;IAAA,OAAIA,CAAC,CAACC,IAAF,KAAW,UAAf;EAAA,CAAlB,CAAxB;EACAP,MAAM,CAACQ,OAAP,CAAeC,uBAAuB,CAACC,IAAxB,CAA6B,IAA7B,EAAmCtB,IAAnC,EAAyCgB,eAAzC,CAAf;EAEA,OAAOhB,IAAP;AACD;AACD;AACA;AACA;AACA;AACA;;AACO,SAASW,uBAATA,CAAAY,IAAA,EAAmE;EAAA,IAAjCX,MAAiC,GAAAW,IAAA,CAAjCX,MAAiC;IAAzBZ,IAAyB,GAAAuB,IAAA,CAAzBvB,IAAyB;IAAAwB,gBAAA,GAAAD,IAAA,CAAnBE,WAAmB;IAAnBA,WAAmB,GAAAD,gBAAA,cAAL,EAAK,GAAAA,gBAAA;EACxE,IAAME,KAAK,GAAGC,IAAI,CAACC,GAAL,CAASH,WAAT,EAAsBzB,IAAI,CAACM,MAA3B,CAAd,CADwE,CAExE;;EACA,IAAMI,MAAM,GAAG,IAAA9D,QAAA,CAAAiF,KAAA,EAAM,CAAN,EAASH,KAAT,EAAgB,CAAhB,EAAmBI,GAAnB,CAAuB,UAAA3C,CAAC;IAAA,OAAK,EAAL;EAAA,CAAxB,CAAf,CAHwE,CAKxE;;EACAyB,MAAM,CAACQ,OAAP,CAAe,UAAC5B,KAAD,EAAQuC,QAAR,EAAqB;IAClC;IACA,IAAIC,CAAC,GAAG,CAAR,CAFkC,CAGlC;;IACA,IAAIC,CAAC,GAAG,CAAR;IAEA,OAAOA,CAAC,GAAGP,KAAX,EAAkB;MAChB,IAAIM,CAAC,IAAIhC,IAAI,CAACM,MAAd,EAAsB;QACpB;QACAI,MAAM,CAACuB,CAAD,CAAN,CAAUzC,KAAV,IAAmB,IAAnB;QACAyC,CAAC;MACF,CAJD,MAIO,IAAI,IAAA9E,UAAA,CAAA+E,kBAAA,EAAmBlC,IAAI,CAACgC,CAAD,CAAJ,CAAQD,QAAR,CAAnB,CAAJ,EAA2C;QAChD,IAAMI,KAAK,GAAGnC,IAAI,CAACgC,CAAD,CAAJ,CAAQD,QAAR,CAAd;QACArB,MAAM,CAACuB,CAAD,CAAN,CAAUzC,KAAV,IAAmB,OAAO2C,KAAP,KAAiB,QAAjB,GAA4BA,KAAK,CAACC,IAAN,EAA5B,GAA2CD,KAA9D;QACAF,CAAC;QACDD,CAAC;MACF,CALM,MAKA;QACLA,CAAC;MACF;IACF;EACF,CApBD;EAsBA,OAAOtB,MAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;AACA,SAASD,oBAATA,CAA8BT,IAA9B,EAAoC;EAClC,IAAMqC,EAAE,GAAG,IAAIC,MAAJ,CAAW/D,SAAX,EAAsB,GAAtB,CAAX;EACA,KAAK,IAAIyD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGhC,IAAI,CAACM,MAAzB,EAAiC0B,CAAC,EAAlC,EAAsC;IACpC,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGjC,IAAI,CAACgC,CAAD,CAAJ,CAAQ1B,MAA5B,EAAoC2B,CAAC,EAArC,EAAyC;MACvC;MACA;MACA;MACA;MACA,IAAI,OAAOjC,IAAI,CAACgC,CAAD,CAAJ,CAAQC,CAAR,CAAP,KAAsB,QAAtB,IAAkCjC,IAAI,CAACgC,CAAD,CAAJ,CAAQC,CAAR,EAAWM,KAAX,CAAiBF,EAAjB,CAAtC,EAA4D;QAC1DrC,IAAI,CAACgC,CAAD,CAAJ,CAAQC,CAAR,IAAa,IAAb;MACD;IACF;EACF;AACF;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASZ,uBAATA,CAAiCrB,IAAjC,EAAuCwC,WAAvC,EAAoDhD,KAApD,EAA2DwC,CAA3D,EAA8D;EACnE,IAAMS,MAAM,GAAG3D,6BAA6B,CAACU,KAAK,CAACZ,IAAP,CAA5C;EACA,IAAI6D,MAAJ,EAAY;IACV;IACA,IAAMC,KAAK,GAAG1C,IAAI,CAAC2C,IAAL,CAAU,UAAAC,CAAC;MAAA,OAAI,IAAAzF,UAAA,CAAA+E,kBAAA,EAAmBU,CAAC,CAACZ,CAAD,CAApB,CAAJ;IAAA,CAAX,CAAd;IACA,IAAI,CAACU,KAAD,IAAUD,MAAM,CAACvD,KAAP,CAAawD,KAAK,CAACV,CAAD,CAAlB,EAAuBxC,KAAvB,CAAd,EAA6C;MAC3C;IACD;IACDQ,IAAI,CAACoB,OAAL,CAAa,UAAAyB,GAAG,EAAI;MAClB;MACA,IAAIA,GAAG,CAACb,CAAD,CAAH,KAAW,IAAf,EAAqB;QACnBa,GAAG,CAACb,CAAD,CAAH,GAASS,MAAM,CAACrD,KAAP,CAAayD,GAAG,CAACb,CAAD,CAAhB,EAAqBxC,KAArB,CAAT;QACA,IAAIgD,WAAW,GAAG,CAAC,CAAf,IAAoBK,GAAG,CAACL,WAAD,CAAvB,IAAwCK,GAAG,CAACL,WAAD,CAAH,CAAiBM,UAA7D,EAAyE;UACvED,GAAG,CAACL,WAAD,CAAH,CAAiBM,UAAjB,CAA4BtD,KAAK,CAAC2B,IAAlC,IAA0C0B,GAAG,CAACb,CAAD,CAA7C;QACD;MACF;IACF,CARD;EASD;AACF;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASnB,iBAATA,CAA2BkC,IAA3B,EAAiCC,UAAjC,EAA6C;EAClD;EACA,IAAMC,QAAQ,GAAGjG,aAAA,CAAAkG,QAAA,CAASC,cAAT,CACfJ,IADe,EAEf,CACE;IAACK,KAAK,EAAE,uBAAR;IAAiCC,QAAQ,EAAE;EAA3C,CADF,EAEE;IAACD,KAAK,EAAE,WAAR;IAAqBC,QAAQ,EAAE;EAA/B,CAFF,CAFe,EAMf;IAACC,gBAAgB,EAAE9E;EAAnB,CANe,CAAjB;EAFkD,IAAA+E,qBAAA,GAW3BC,qBAAqB,CAACR,UAAD,CAXM;IAW3CS,YAX2C,GAAAF,qBAAA,CAW3CE,YAX2C;EAalD,IAAMC,MAAM,GAAGV,UAAU,CAAClB,GAAX,CAAe,UAACtC,KAAD,EAAQmE,KAAR,EAAkB;IAC9C,IAAMxC,IAAI,GAAGsC,YAAY,CAACE,KAAD,CAAzB;IAEA,IAAMC,SAAS,GAAGX,QAAQ,CAACN,IAAT,CAAc,UAAAkB,CAAC;MAAA,OAAIA,CAAC,CAACC,GAAF,KAAUtE,KAAd;IAAA,CAAf,CAAlB;IAH8C,IAAAuE,KAAA,GAIvBH,SAAS,IAAI,EAJU;MAIvChF,IAJuC,GAAAmF,KAAA,CAIvCnF,IAJuC;MAIjCa,MAJiC,GAAAsE,KAAA,CAIjCtE,MAJiC;IAM9C,OAAO;MACL0B,IAAI,EAAJA,IADK;MAEL6C,EAAE,EAAE7C,IAFC;MAGL8C,WAAW,EAAE9C,IAHR;MAIL1B,MAAM,EAANA,MAJK;MAKLsC,QAAQ,EAAE4B,KALL;MAML/E,IAAI,EAAEsF,uBAAuB,CAACtF,IAAD,CANxB;MAOLuF,YAAY,EAAEvF,IAPT;MAQLwF,aAAa,EAAE,SAAAA,cAAAC,EAAE;QAAA,OAAI,UAAAlF,CAAC,EAAI;UACxB,OAAOkF,EAAE,CAACC,OAAH,CAAWnF,CAAC,CAACwE,KAAb,EAAoBA,KAApB,CAAP;QACD,CAFgB;MAAA;IARZ,CAAP;EAYD,CAlBc,CAAf,CAbkD,CAiClD;;EACA,OAAOD,MAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASF,qBAATA,CAA+BR,UAA/B,EAA2C;EAChD,OAAOA,UAAU,CAACuB,MAAX,CACL,UAACC,IAAD,EAAOhF,KAAP,EAAcwC,CAAd,EAAoB;IAAA,IACXyC,QADW,GACCD,IADD,CACXC,QADW;IAElB,IAAIC,SAAS,GAAGlF,KAAhB,CAFkB,CAIlB;;IACA,IAAIiF,QAAQ,CAAC5F,QAAT,CAAkBW,KAAlB,CAAJ,EAA8B;MAC5B,IAAImF,OAAO,GAAG,CAAd;MACA,OAAOF,QAAQ,CAAC5F,QAAT,IAAA+F,MAAA,CAAqBpF,KAArB,OAAAoF,MAAA,CAA8BD,OAA9B,EAAP,EAAiD;QAC/CA,OAAO;MACR;MACDD,SAAS,MAAAE,MAAA,CAAMpF,KAAN,OAAAoF,MAAA,CAAeD,OAAf,CAAT;IACD;IAEDH,IAAI,CAACf,YAAL,CAAkBzB,CAAlB,IAAuB0C,SAAvB;IACAF,IAAI,CAACC,QAAL,CAAcI,IAAd,CAAmBH,SAAnB;IAEA,OAAOF,IAAP;EACD,CAlBI,EAmBL;IAACC,QAAQ,EAAE,EAAX;IAAehB,YAAY,EAAE;EAA7B,CAnBK,CAAP;AAqBD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;;AACO,SAASS,uBAATA,CAAiCY,KAAjC,EAAwC;EAAA,IAE3CrH,IAF2C,GAgBzCT,aAAA,CAAAQ,UAhByC,CAE3CC,IAF2C;IAG3CC,IAH2C,GAgBzCV,aAAA,CAAAQ,UAhByC,CAG3CE,IAH2C;IAI3CC,QAJ2C,GAgBzCX,aAAA,CAAAQ,UAhByC,CAI3CG,QAJ2C;IAK3CC,MAL2C,GAgBzCZ,aAAA,CAAAQ,UAhByC,CAK3CI,MAL2C;IAM3CC,GAN2C,GAgBzCb,aAAA,CAAAQ,UAhByC,CAM3CK,GAN2C;IAO3CC,KAP2C,GAgBzCd,aAAA,CAAAQ,UAhByC,CAO3CM,KAP2C;IAQ3CC,OAR2C,GAgBzCf,aAAA,CAAAQ,UAhByC,CAQ3CO,OAR2C;IAS3CC,MAT2C,GAgBzChB,aAAA,CAAAQ,UAhByC,CAS3CQ,MAT2C;IAU3CC,QAV2C,GAgBzCjB,aAAA,CAAAQ,UAhByC,CAU3CS,QAV2C;IAW3CC,oBAX2C,GAgBzClB,aAAA,CAAAQ,UAhByC,CAW3CU,oBAX2C;IAY3CC,yBAZ2C,GAgBzCnB,aAAA,CAAAQ,UAhByC,CAY3CW,yBAZ2C;IAa3CC,OAb2C,GAgBzCpB,aAAA,CAAAQ,UAhByC,CAa3CY,OAb2C;IAc3CC,KAd2C,GAgBzCrB,aAAA,CAAAQ,UAhByC,CAc3Ca,KAd2C;IAe3CC,MAf2C,GAgBzCtB,aAAA,CAAAQ,UAhByC,CAe3Cc,MAf2C,EAkB7C;EACA;;EACA,QAAQwG,KAAR;IACE,KAAKrH,IAAL;MACE,OAAOP,gBAAA,CAAA+B,eAAA,CAAgB8F,IAAvB;IACF,KAAKrH,IAAL;IACA,KAAKC,QAAL;MACE,OAAOT,gBAAA,CAAA+B,eAAA,CAAgBM,SAAvB;IACF,KAAKzB,KAAL;MACE,OAAOZ,gBAAA,CAAA+B,eAAA,CAAgBU,IAAvB;IACF,KAAK9B,GAAL;MACE,OAAOX,gBAAA,CAAA+B,eAAA,CAAgBI,OAAvB;IACF,KAAKtB,OAAL;MACE,OAAOb,gBAAA,CAAA+B,eAAA,WAAP;IACF,KAAKhB,QAAL;IACA,KAAKC,oBAAL;IACA,KAAKC,yBAAL;IACA,KAAKE,KAAL;IACA,KAAKC,MAAL;MACE;MACA,OAAOpB,gBAAA,CAAA+B,eAAA,CAAgB+F,OAAvB;IACF,KAAKpH,MAAL;IACA,KAAKI,MAAL;IACA,KAAKI,OAAL;MACE,OAAOlB,gBAAA,CAAA+B,eAAA,CAAgBgG,MAAvB;IACF;MACEpI,OAAA,CAAAqI,OAAA,CAAcC,IAAd,+BAAAP,MAAA,CAAiDE,KAAjD;MACA,OAAO5H,gBAAA,CAAA+B,eAAA,CAAgBgG,MAAvB;EAAA;AAEL;AACD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASG,gBAATA,CAA0BtF,OAA1B,EAAmC;EACxC,IAAI,CAACM,KAAK,CAACC,OAAN,CAAcP,OAAd,CAAD,IAA2B,CAACA,OAAO,CAACQ,MAAxC,EAAgD;IAC9C,OAAO,IAAP;EACD;EAED,IAAM5B,IAAI,GAAGD,MAAM,CAACC,IAAP,CAAYoB,OAAO,CAAC,CAAD,CAAnB,CAAb;EACA,IAAME,IAAI,GAAGF,OAAO,CAACgC,GAAR,CAAY,UAAA3C,CAAC;IAAA,OAAIT,IAAI,CAACoD,GAAL,CAAS,UAAAgC,GAAG;MAAA,OAAI3E,CAAC,CAAC2E,GAAD,CAAL;IAAA,CAAZ,CAAJ;EAAA,CAAb,CAAb,CANwC,CAQxC;;EACArD,oBAAoB,CAACT,IAAD,CAApB;EAEA,OAAOH,cAAc,CAACG,IAAD,EAAOtB,IAAP,CAArB;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAAS2G,cAATA,CAAwBvF,OAAxB,EAAiC;EACtC,IAAMwF,iBAAiB,GAAG,IAAArI,iBAAA,aAAU6C,OAAV,CAA1B;EAEA,IAAI,CAACwF,iBAAD,IAAsB,CAAClF,KAAK,CAACC,OAAN,CAAciF,iBAAiB,CAACC,QAAhC,CAA3B,EAAsE;IACpE,IAAMC,KAAK,GAAG,IAAIjF,KAAJ,2FAAAqE,MAAA,CAC8EvH,WAAA,CAAAoI,sBAD9E,OAAd;IAGA,MAAMD,KAAN,CAJoE,CAKpE;EACD,CATqC,CAWtC;;EACA,IAAME,WAAW,GAAG,EAApB;EACA,KAAK,IAAI1D,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGsD,iBAAiB,CAACC,QAAlB,CAA2BjF,MAA/C,EAAuD0B,CAAC,EAAxD,EAA4D;IAC1D,IAAMd,CAAC,GAAGoE,iBAAiB,CAACC,QAAlB,CAA2BvD,CAA3B,CAAV;IACA,IAAId,CAAC,CAACyE,QAAN,EAAgB;MACdD,WAAW,CAACb,IAAZ,CAAAe,aAAA;QACE;QACAC,QAAQ,EAAE3E;MAFZ,GAGMA,CAAC,CAAC4B,UAAF,IAAgB,EAHtB;IAKD;EACF,CAtBqC,CAuBtC;;EACA,IAAMlC,MAAM,GAAG8E,WAAW,CAACnB,MAAZ,CAAmB,UAACuB,IAAD,EAAOC,IAAP,EAAgB;IAChDtH,MAAM,CAACC,IAAP,CAAYqH,IAAZ,EAAkB3E,OAAlB,CAA0B,UAAA0C,GAAG,EAAI;MAC/B,IAAI,CAACgC,IAAI,CAACjH,QAAL,CAAciF,GAAd,CAAL,EAAyB;QACvBgC,IAAI,CAACjB,IAAL,CAAUf,GAAV;MACD;IACF,CAJD;IAKA,OAAOgC,IAAP;EACD,CAPc,EAOZ,EAPY,CAAf,CAxBsC,CAiCtC;;EACAJ,WAAW,CAACtE,OAAZ,CAAoB,UAAAjC,CAAC,EAAI;IACvByB,MAAM,CAACQ,OAAP,CAAe,UAAAF,CAAC,EAAI;MAClB,IAAI,EAAEA,CAAC,IAAI/B,CAAP,CAAJ,EAAe;QACbA,CAAC,CAAC+B,CAAD,CAAD,GAAO,IAAP;QACA/B,CAAC,CAAC0G,QAAF,CAAW/C,UAAX,CAAsB5B,CAAtB,IAA2B,IAA3B;MACD;IACF,CALD;EAMD,CAPD;EASA,OAAOkE,gBAAgB,CAACM,WAAD,CAAvB;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;AACO,SAASM,SAATA,CAAmBC,aAAnB,EAAkCrF,MAAlC,EAA0C;EAC/C,IAAMsF,OAAO,GAAGtF,MAAM,CAACkB,GAAP,CAAW,UAAAZ,CAAC;IAAA,OAAIA,CAAC,CAAC+C,WAAF,IAAiB/C,CAAC,CAACC,IAAvB;EAAA,CAAZ,CAAhB;EACA,IAAMgF,aAAa,GAAG,CAACD,OAAD,CAAtB,CAF+C,CAI/C;;EAJ+C,IAAAE,SAAA,GAAAC,0BAAA,CAK7BJ,aAAa,CAACjG,IAAd,CAAmB,IAAnB,CAL6B;IAAAsG,KAAA;EAAA;IAK/C,KAAAF,SAAA,CAAAG,CAAA,MAAAD,KAAA,GAAAF,SAAA,CAAAI,CAAA,IAAAC,IAAA,GAA4C;MAAA,IAAjC5D,GAAiC,GAAAyD,KAAA,CAAAnE,KAAA;MAC1CgE,aAAa,CAACtB,IAAd,CAAmBhC,GAAG,CAACf,GAAJ,CAAQ,UAAC3C,CAAD,EAAI6C,CAAJ;QAAA,OAAU,IAAA7E,UAAA,CAAAuJ,eAAA,EAAgBvH,CAAhB,EAAmByB,MAAM,CAACoB,CAAD,CAAN,CAAUpD,IAA7B,CAAV;MAAA,CAAR,CAAnB;IACD;EAP8C,SAAA+H,GAAA;IAAAP,SAAA,CAAAQ,CAAA,CAAAD,GAAA;EAAA;IAAAP,SAAA,CAAAlF,CAAA;EAAA;EAS/C,OAAO,IAAAxE,MAAA,CAAAmK,aAAA,EAAcV,aAAd,CAAP;AACD;AAED;AACA;AACA;AACA;;AACO,SAASW,iBAATA,CAA2B/D,IAA3B,EAAiC;EACtC,IAAI,CAAC,IAAAzF,MAAA,CAAAyJ,aAAA,EAAchE,IAAd,CAAL,EAA0B;IACxB,IAAAjG,OAAA,aAAO,iDAAP;IACA,OAAO,IAAP;EACD,CAHD,MAGO,IAAI,CAACsD,KAAK,CAACC,OAAN,CAAc0C,IAAI,CAACnC,MAAnB,CAAL,EAAiC;IACtC,IAAA9D,OAAA,aAAO,+DAAP;IACA,OAAO,IAAP;EACD,CAHM,MAGA,IAAI,CAACsD,KAAK,CAACC,OAAN,CAAc0C,IAAI,CAAC/C,IAAnB,CAAL,EAA+B;IACpC,IAAAlD,OAAA,aAAO,6DAAP;IACA,OAAO,IAAP;EACD;EAVqC,IAY/B8D,MAZ+B,GAYfmC,IAZe,CAY/BnC,MAZ+B;IAYvBZ,IAZuB,GAYf+C,IAZe,CAYvB/C,IAZuB,EActC;;EACA,IAAMgH,QAAQ,GAAGpG,MAAM,CAACqG,KAAP,CAAa,UAAC/F,CAAD,EAAIc,CAAJ,EAAU;IACtC,IAAI,CAAC,IAAA1E,MAAA,CAAAyJ,aAAA,EAAc7F,CAAd,CAAL,EAAuB;MACrB,IAAApE,OAAA,gEAAA8H,MAAA,KAAAsC,QAAA,aAAiEhG,CAAjE;MACAN,MAAM,CAACoB,CAAD,CAAN,GAAY,EAAZ;IACD;IAED,IAAI,CAACd,CAAC,CAACC,IAAP,EAAa;MACX,IAAArE,OAAA,sDAAA8H,MAAA,CAAgDuC,IAAI,CAACC,SAAL,CAAelG,CAAf,CAAhD,GADW,CAEX;;MACAN,MAAM,CAACoB,CAAD,CAAN,CAAUb,IAAV,aAAAyD,MAAA,CAA2B5C,CAA3B;IACD;IAED,IAAI,CAAC9E,gBAAA,CAAA+B,eAAA,CAAgBiC,CAAC,CAACtC,IAAlB,CAAL,EAA8B;MAC5B,IAAA9B,OAAA,mCAAA8H,MAAA,CAA6B1D,CAAC,CAACtC,IAA/B;MACA,OAAO,KAAP;IACD;IAED,IAAI,CAACgC,MAAM,CAACqG,KAAP,CAAa,UAAAzH,KAAK;MAAA,OAAIA,KAAK,CAAC2E,YAAV;IAAA,CAAlB,CAAL,EAAgD;MAC9C,IAAArH,OAAA,aAAO,4BAAP;MACA,OAAO,KAAP;IACD,CApBqC,CAsBtC;;IACA,IAAIoE,CAAC,CAACtC,IAAF,KAAW1B,gBAAA,CAAA+B,eAAA,CAAgBM,SAA/B,EAA0C;MACxC,IAAMmB,MAAM,GAAG2G,uBAAuB,CAACrH,IAAD,EAAOgC,CAAP,EAAU,EAAV,CAAvB,CAAqCF,GAArC,CAAyC,UAAAc,CAAC;QAAA,OAAK;UAAC0E,EAAE,EAAE1E,CAAC,CAACZ,CAAD;QAAN,CAAL;MAAA,CAA1C,CAAf;MACA,IAAMuF,YAAY,GAAGvK,aAAA,CAAAkG,QAAA,CAASC,cAAT,CAAwBzC,MAAxB,EAAgC,CAAhC,CAArB;MACA,OAAO6G,YAAY,IAAIA,YAAY,CAACC,QAAb,KAA0B,MAA1C,IAAoDD,YAAY,CAAC9H,MAAb,KAAwByB,CAAC,CAACzB,MAArF;IACD;IAED,OAAO,IAAP;EACD,CA9BgB,CAAjB;EAgCA,IAAIuH,QAAJ,EAAc;IACZ,OAAO;MAAChH,IAAI,EAAJA,IAAD;MAAOY,MAAM,EAANA;IAAP,CAAP;EACD,CAjDqC,CAmDtC;EACA;;EACA,IAAM6G,UAAU,GAAG9G,uBAAuB,CAAC;IACzCC,MAAM,EAAEA,MAAM,CAACkB,GAAP,CAAW,UAAAZ,CAAC;MAAA,OAAIA,CAAC,CAACC,IAAN;IAAA,CAAZ,CADiC;IAEzCnB,IAAI,EAAJA;EAFyC,CAAD,CAA1C;EAIA,IAAMgD,UAAU,GAAGpC,MAAM,CAACkB,GAAP,CAAW,UAAAZ,CAAC;IAAA,OAAIA,CAAC,CAACC,IAAN;EAAA,CAAZ,CAAnB;EACA,IAAMuG,IAAI,GAAG7G,iBAAiB,CAAC4G,UAAD,EAAazE,UAAb,CAA9B;EACA,IAAM2E,aAAa,GAAG/G,MAAM,CAACkB,GAAP,CAAW,UAACZ,CAAD,EAAIc,CAAJ;IAAA,OAAA4D,aAAA,CAAAA,aAAA,KAC5B1E,CAD4B;MAE/BtC,IAAI,EAAE8I,IAAI,CAAC1F,CAAD,CAAJ,CAAQpD,IAFiB;MAG/Ba,MAAM,EAAEiI,IAAI,CAAC1F,CAAD,CAAJ,CAAQvC,MAHe;MAI/B0E,YAAY,EAAEuD,IAAI,CAAC1F,CAAD,CAAJ,CAAQmC;IAJS;EAAA,CAAX,CAAtB;EAOA,OAAO;IAACvD,MAAM,EAAE+G,aAAT;IAAwB3H,IAAI,EAAJA;EAAxB,CAAP;AACD;AAED,SAASqH,uBAATA,CAAiCrH,IAAjC,EAAuC+B,QAAvC,EAAiDL,KAAjD,EAAwD;EACtD,IAAMhB,MAAM,GAAG,EAAf;EACA,IAAIsB,CAAC,GAAG,CAAR;EACA,OAAOtB,MAAM,CAACJ,MAAP,GAAgBoB,KAAhB,IAAyBM,CAAC,GAAGhC,IAAI,CAACM,MAAzC,EAAiD;IAC/C,IAAI,IAAAnD,UAAA,CAAA+E,kBAAA,EAAmBlC,IAAI,CAACgC,CAAD,CAAJ,CAAQD,QAAR,CAAnB,CAAJ,EAA2C;MACzCrB,MAAM,CAACmE,IAAP,CAAY7E,IAAI,CAACgC,CAAD,CAAhB;IACD;IACDA,CAAC;EACF;EACD,OAAOtB,MAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAASkH,mBAATA,CAA6B9H,OAA7B,EAAsC;EAC3C,OAAOA,OAAO,GAAG1C,QAAA,YAAeyK,IAAf,CAAoB/H,OAAO,CAACgI,QAA5B,EAAsChI,OAAO,CAACiI,MAA9C,CAAH,GAA2D,IAAzE;AACD;AAED;AACA;AACA;AACA;;AACO,SAASC,sBAATA,CAAgClI,OAAhC,EAAyC;EAC9C,IAAI,CAACA,OAAL,EAAc;IACZ,OAAO,IAAP;EACD;EAED,IAAMmI,OAAO,GAAG7K,QAAA,YAAe8K,cAAf,CAA8B,IAAA5K,MAAA,CAAA6K,OAAA,EAAQrI,OAAR,CAA9B,CAAhB;EACA,IAAI,CAACmI,OAAL,EAAc;IACZ,OAAO,IAAP;EACD;EACD,OAAO7H,KAAK,CAACC,OAAN,CAAcP,OAAd,IAAyBmI,OAAzB,GAAmCA,OAAO,CAAC,CAAD,CAAjD;AACD;AAEM,IAAMG,gBAAgB,IAAAC,iBAAA,WAAArJ,gBAAA,aAAAqJ,iBAAA,EAC1BnL,gBAAA,CAAAoL,eAAA,CAAgBzF,GADU,EACJuC,gBADI,OAAApG,gBAAA,aAAAqJ,iBAAA,EAE1BnL,gBAAA,CAAAoL,eAAA,CAAgBtD,OAFU,EAEAK,cAFA,OAAArG,gBAAA,aAAAqJ,iBAAA,EAG1BnL,gBAAA,CAAAoL,eAAA,CAAgBC,GAHU,EAGJ1I,cAHI,OAAAb,gBAAA,aAAAqJ,iBAAA,EAI1BnL,gBAAA,CAAAoL,eAAA,CAAgBE,QAJU,EAICR,sBAJD,GAAAK,iBAAA,CAAtB;;AAOA,IAAMI,UAAU,GAAG;EACxBpD,cAAc,EAAdA,cADwB;EAExBxF,cAAc,EAAdA,cAFwB;EAGxBuF,gBAAgB,EAAhBA,gBAHwB;EAIxBwC,mBAAmB,EAAnBA,mBAJwB;EAKxBI,sBAAsB,EAAtBA,sBALwB;EAMxB9D,uBAAuB,EAAvBA,uBANwB;EAOxBrD,iBAAiB,EAAjBA,iBAPwB;EAQxBQ,uBAAuB,EAAvBA,uBARwB;EASxB2E,SAAS,EAATA;AATwB,CAAnB"},"metadata":{},"sourceType":"script","externalDependencies":[]}