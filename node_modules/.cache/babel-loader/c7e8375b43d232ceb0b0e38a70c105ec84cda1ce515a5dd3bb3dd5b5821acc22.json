{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports[\"default\"] = void 0;\nvar _assertThisInitialized2 = _interopRequireDefault(require(\"@babel/runtime/helpers/assertThisInitialized\"));\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\nvar _lodash = _interopRequireDefault(require(\"lodash.pick\"));\nvar _window = require(\"global/window\");\nvar _versions = require(\"./versions\");\nvar _schema = _interopRequireDefault(require(\"./schema\"));\nvar _dataProcessor = require(\"../processors/data-processor\");\nvar _datasetSchema;\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        (0, _defineProperty2[\"default\"])(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n  return target;\n}\nfunction _createSuper(Derived) {\n  var hasNativeReflectConstruct = _isNativeReflectConstruct();\n  return function _createSuperInternal() {\n    var Super = (0, _getPrototypeOf2[\"default\"])(Derived),\n      result;\n    if (hasNativeReflectConstruct) {\n      var NewTarget = (0, _getPrototypeOf2[\"default\"])(this).constructor;\n      result = Reflect.construct(Super, arguments, NewTarget);\n    } else {\n      result = Super.apply(this, arguments);\n    }\n    return (0, _possibleConstructorReturn2[\"default\"])(this, result);\n  };\n}\nfunction _isNativeReflectConstruct() {\n  if (typeof Reflect === \"undefined\" || !Reflect.construct) return false;\n  if (Reflect.construct.sham) return false;\n  if (typeof Proxy === \"function\") return true;\n  try {\n    Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {}));\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\n// version v0\nvar fieldPropertiesV0 = {\n  name: null,\n  type: null\n};\nvar fieldPropertiesV1 = {\n  name: null,\n  type: null,\n  format: null,\n  analyzerType: null\n};\nvar FieldSchema = /*#__PURE__*/function (_Schema) {\n  (0, _inherits2[\"default\"])(FieldSchema, _Schema);\n  var _super = _createSuper(FieldSchema);\n  function FieldSchema() {\n    (0, _classCallCheck2[\"default\"])(this, FieldSchema);\n    return _super.apply(this, arguments);\n  }\n  (0, _createClass2[\"default\"])(FieldSchema, [{\n    key: \"save\",\n    value: function save(fields) {\n      var _this = this;\n      return (0, _defineProperty2[\"default\"])({}, this.key, fields.map(function (f) {\n        return _this.savePropertiesOrApplySchema(f)[_this.key];\n      }));\n    }\n  }, {\n    key: \"load\",\n    value: function load(fields) {\n      return (0, _defineProperty2[\"default\"])({}, this.key, fields);\n    }\n  }]);\n  return FieldSchema;\n}(_schema[\"default\"]);\nvar propertiesV0 = {\n  id: null,\n  label: null,\n  color: null,\n  allData: null,\n  fields: new FieldSchema({\n    key: 'fields',\n    version: _versions.VERSIONS.v0,\n    properties: fieldPropertiesV0\n  })\n};\nvar propertiesV1 = _objectSpread(_objectSpread({}, propertiesV0), {}, {\n  fields: new FieldSchema({\n    key: 'fields',\n    version: _versions.VERSIONS.v1,\n    properties: fieldPropertiesV1\n  })\n});\nvar DatasetSchema = /*#__PURE__*/function (_Schema2) {\n  (0, _inherits2[\"default\"])(DatasetSchema, _Schema2);\n  var _super2 = _createSuper(DatasetSchema);\n  function DatasetSchema() {\n    var _this2;\n    (0, _classCallCheck2[\"default\"])(this, DatasetSchema);\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n    _this2 = _super2.call.apply(_super2, [this].concat(args));\n    (0, _defineProperty2[\"default\"])((0, _assertThisInitialized2[\"default\"])(_this2), \"key\", 'dataset');\n    return _this2;\n  }\n  (0, _createClass2[\"default\"])(DatasetSchema, [{\n    key: \"save\",\n    value: function save(dataset) {\n      var datasetFlattened = dataset.dataContainer ? _objectSpread(_objectSpread({}, dataset), {}, {\n        allData: dataset.dataContainer.flattenData()\n      }) : dataset;\n      return this.savePropertiesOrApplySchema(datasetFlattened)[this.key];\n    }\n  }, {\n    key: \"load\",\n    value: function load(dataset) {\n      var fields = dataset.fields,\n        allData = dataset.allData;\n      var updatedFields = fields; // recalculate field type\n      // because we have updated type-analyzer\n      // we need to add format to each field\n\n      var needCalculateMeta = fields[0] && (!fields[0].hasOwnProperty('format') || !fields[0].hasOwnProperty('analyzerType'));\n      if (needCalculateMeta) {\n        var fieldOrder = fields.map(function (f) {\n          return f.name;\n        });\n        var sampleData = (0, _dataProcessor.getSampleForTypeAnalyze)({\n          fields: fieldOrder,\n          rows: allData\n        });\n        var meta = (0, _dataProcessor.getFieldsFromData)(sampleData, fieldOrder);\n        updatedFields = meta.map(function (f, i) {\n          return _objectSpread(_objectSpread({}, (0, _lodash[\"default\"])(meta[i], ['name', 'type', 'format'])), {}, {\n            analyzerType: meta[i].analyzerType\n          });\n        });\n        updatedFields.forEach(function (f, i) {\n          if (fields[i].type !== f.type) {\n            // if newly detected field type is different from saved type\n            // we log it but won't update it, cause we don't want to break people's map\n            _window.console.warn(\"detect \".concat(f.name, \" type is now \").concat(f.type, \" instead of \").concat(fields[i].type));\n          }\n        });\n      } // get format of all fields\n\n      return {\n        data: {\n          fields: updatedFields,\n          rows: dataset.allData\n        },\n        info: (0, _lodash[\"default\"])(dataset, ['id', 'label', 'color'])\n      };\n    }\n  }]);\n  return DatasetSchema;\n}(_schema[\"default\"]);\nvar datasetSchema = (_datasetSchema = {}, (0, _defineProperty2[\"default\"])(_datasetSchema, _versions.VERSIONS.v0, new DatasetSchema({\n  key: 'dataset',\n  version: _versions.VERSIONS.v0,\n  properties: propertiesV0\n})), (0, _defineProperty2[\"default\"])(_datasetSchema, _versions.VERSIONS.v1, new DatasetSchema({\n  key: 'dataset',\n  version: _versions.VERSIONS.v1,\n  properties: propertiesV1\n})), _datasetSchema);\nvar _default = datasetSchema;\nexports[\"default\"] = _default;","map":{"version":3,"names":["_lodash","_interopRequireDefault","require","_window","_versions","_schema","_dataProcessor","fieldPropertiesV0","name","type","fieldPropertiesV1","format","analyzerType","FieldSchema","save","fields","_this","_defineProperty2","key","map","f","savePropertiesOrApplySchema","load","propertiesV0","id","label","color","allData","version","VERSIONS","v0","properties","propertiesV1","_objectSpread","v1","DatasetSchema","dataset","datasetFlattened","dataContainer","flattenData","updatedFields","needCalculateMeta","hasOwnProperty","fieldOrder","sampleData","getSampleForTypeAnalyze","rows","meta","getFieldsFromData","i","forEach","console","warn","concat","data","info","datasetSchema","_datasetSchema"],"sources":["/Users/rohinphukan/Desktop/RefugeeWebsite/node_modules/kepler.gl/src/schemas/dataset-schema.js"],"sourcesContent":["// Copyright (c) 2021 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\nimport pick from 'lodash.pick';\nimport {console as globalConsole} from 'global/window';\n\nimport {VERSIONS} from './versions';\nimport Schema from './schema';\nimport {getFieldsFromData, getSampleForTypeAnalyze} from 'processors/data-processor';\n\n// version v0\nconst fieldPropertiesV0 = {\n  name: null,\n  type: null\n};\n\nconst fieldPropertiesV1 = {\n  name: null,\n  type: null,\n  format: null,\n  analyzerType: null\n};\n\nclass FieldSchema extends Schema {\n  save(fields) {\n    return {\n      [this.key]: fields.map(f => this.savePropertiesOrApplySchema(f)[this.key])\n    };\n  }\n  load(fields) {\n    return {[this.key]: fields};\n  }\n}\n\nconst propertiesV0 = {\n  id: null,\n  label: null,\n  color: null,\n  allData: null,\n  fields: new FieldSchema({\n    key: 'fields',\n    version: VERSIONS.v0,\n    properties: fieldPropertiesV0\n  })\n};\n\nconst propertiesV1 = {\n  ...propertiesV0,\n  fields: new FieldSchema({\n    key: 'fields',\n    version: VERSIONS.v1,\n    properties: fieldPropertiesV1\n  })\n};\n\nclass DatasetSchema extends Schema {\n  key = 'dataset';\n\n  save(dataset) {\n    const datasetFlattened = dataset.dataContainer\n      ? {\n          ...dataset,\n          allData: dataset.dataContainer.flattenData()\n        }\n      : dataset;\n\n    return this.savePropertiesOrApplySchema(datasetFlattened)[this.key];\n  }\n  load(dataset) {\n    const {fields, allData} = dataset;\n    let updatedFields = fields;\n\n    // recalculate field type\n    // because we have updated type-analyzer\n    // we need to add format to each field\n    const needCalculateMeta =\n      fields[0] &&\n      (!fields[0].hasOwnProperty('format') || !fields[0].hasOwnProperty('analyzerType'));\n\n    if (needCalculateMeta) {\n      const fieldOrder = fields.map(f => f.name);\n\n      const sampleData = getSampleForTypeAnalyze({\n        fields: fieldOrder,\n        rows: allData\n      });\n      const meta = getFieldsFromData(sampleData, fieldOrder);\n\n      updatedFields = meta.map((f, i) => ({\n        ...pick(meta[i], ['name', 'type', 'format']),\n        analyzerType: meta[i].analyzerType\n      }));\n\n      updatedFields.forEach((f, i) => {\n        if (fields[i].type !== f.type) {\n          // if newly detected field type is different from saved type\n          // we log it but won't update it, cause we don't want to break people's map\n          globalConsole.warn(`detect ${f.name} type is now ${f.type} instead of ${fields[i].type}`);\n        }\n      });\n    }\n\n    // get format of all fields\n    return {\n      data: {fields: updatedFields, rows: dataset.allData},\n      info: pick(dataset, ['id', 'label', 'color'])\n    };\n  }\n}\n\nconst datasetSchema = {\n  [VERSIONS.v0]: new DatasetSchema({\n    key: 'dataset',\n    version: VERSIONS.v0,\n    properties: propertiesV0\n  }),\n  [VERSIONS.v1]: new DatasetSchema({\n    key: 'dataset',\n    version: VERSIONS.v1,\n    properties: propertiesV1\n  })\n};\n\nexport default datasetSchema;\n"],"mappings":";;;;;;;;;;;;;;AAoBA,IAAAA,OAAA,GAAAC,sBAAA,CAAAC,OAAA;AACA,IAAAC,OAAA,GAAAD,OAAA;AAEA,IAAAE,SAAA,GAAAF,OAAA;AACA,IAAAG,OAAA,GAAAJ,sBAAA,CAAAC,OAAA;AACA,IAAAI,cAAA,GAAAJ,OAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEA;AACA,IAAMK,iBAAiB,GAAG;EACxBC,IAAI,EAAE,IADkB;EAExBC,IAAI,EAAE;AAFkB,CAA1B;AAKA,IAAMC,iBAAiB,GAAG;EACxBF,IAAI,EAAE,IADkB;EAExBC,IAAI,EAAE,IAFkB;EAGxBE,MAAM,EAAE,IAHgB;EAIxBC,YAAY,EAAE;AAJU,CAA1B;IAOMC,W;;;;;;;;;WACJ,SAAAC,KAAKC,MAAL,EAAa;MAAA,IAAAC,KAAA;MACX,WAAAC,gBAAA,iBACG,KAAKC,GADR,EACcH,MAAM,CAACI,GAAP,CAAW,UAAAC,CAAC;QAAA,OAAIJ,KAAI,CAACK,2BAAL,CAAiCD,CAAjC,EAAoCJ,KAAI,CAACE,GAAzC,CAAJ;MAAA,CAAZ,CADd;IAGD;;;WACD,SAAAI,KAAKP,MAAL,EAAa;MACX,WAAAE,gBAAA,iBAAS,KAAKC,GAAd,EAAoBH,MAApB;IACD;;;EARuBV,OAAA,W;AAW1B,IAAMkB,YAAY,GAAG;EACnBC,EAAE,EAAE,IADe;EAEnBC,KAAK,EAAE,IAFY;EAGnBC,KAAK,EAAE,IAHY;EAInBC,OAAO,EAAE,IAJU;EAKnBZ,MAAM,EAAE,IAAIF,WAAJ,CAAgB;IACtBK,GAAG,EAAE,QADiB;IAEtBU,OAAO,EAAExB,SAAA,CAAAyB,QAAA,CAASC,EAFI;IAGtBC,UAAU,EAAExB;EAHU,CAAhB;AALW,CAArB;AAYA,IAAMyB,YAAY,GAAAC,aAAA,CAAAA,aAAA,KACbV,YADa;EAEhBR,MAAM,EAAE,IAAIF,WAAJ,CAAgB;IACtBK,GAAG,EAAE,QADiB;IAEtBU,OAAO,EAAExB,SAAA,CAAAyB,QAAA,CAASK,EAFI;IAGtBH,UAAU,EAAErB;EAHU,CAAhB;AAFQ,EAAlB;IASMyB,a;;;;;;;;;;6FACE,S;;;;;WAEN,SAAArB,KAAKsB,OAAL,EAAc;MACZ,IAAMC,gBAAgB,GAAGD,OAAO,CAACE,aAAR,GAAAL,aAAA,CAAAA,aAAA,KAEhBG,OAFgB;QAGnBT,OAAO,EAAES,OAAO,CAACE,aAAR,CAAsBC,WAAtB;MAHU,KAKrBH,OALJ;MAOA,OAAO,KAAKf,2BAAL,CAAiCgB,gBAAjC,EAAmD,KAAKnB,GAAxD,CAAP;IACD;;;WACD,SAAAI,KAAKc,OAAL,EAAc;MAAA,IACLrB,MADK,GACcqB,OADd,CACLrB,MADK;QACGY,OADH,GACcS,OADd,CACGT,OADH;MAEZ,IAAIa,aAAa,GAAGzB,MAApB,CAFY,CAIZ;MACA;MACA;;MACA,IAAM0B,iBAAiB,GACrB1B,MAAM,CAAC,CAAD,CAAN,KACC,CAACA,MAAM,CAAC,CAAD,CAAN,CAAU2B,cAAV,CAAyB,QAAzB,CAAD,IAAuC,CAAC3B,MAAM,CAAC,CAAD,CAAN,CAAU2B,cAAV,CAAyB,cAAzB,CADzC,CADF;MAIA,IAAID,iBAAJ,EAAuB;QACrB,IAAME,UAAU,GAAG5B,MAAM,CAACI,GAAP,CAAW,UAAAC,CAAC;UAAA,OAAIA,CAAC,CAACZ,IAAN;QAAA,CAAZ,CAAnB;QAEA,IAAMoC,UAAU,GAAG,IAAAtC,cAAA,CAAAuC,uBAAA,EAAwB;UACzC9B,MAAM,EAAE4B,UADiC;UAEzCG,IAAI,EAAEnB;QAFmC,CAAxB,CAAnB;QAIA,IAAMoB,IAAI,GAAG,IAAAzC,cAAA,CAAA0C,iBAAA,EAAkBJ,UAAlB,EAA8BD,UAA9B,CAAb;QAEAH,aAAa,GAAGO,IAAI,CAAC5B,GAAL,CAAS,UAACC,CAAD,EAAI6B,CAAJ;UAAA,OAAAhB,aAAA,CAAAA,aAAA,KACpB,IAAAjC,OAAA,aAAK+C,IAAI,CAACE,CAAD,CAAT,EAAc,CAAC,MAAD,EAAS,MAAT,EAAiB,QAAjB,CAAd,CADoB;YAEvBrC,YAAY,EAAEmC,IAAI,CAACE,CAAD,CAAJ,CAAQrC;UAFC;QAAA,CAAT,CAAhB;QAKA4B,aAAa,CAACU,OAAd,CAAsB,UAAC9B,CAAD,EAAI6B,CAAJ,EAAU;UAC9B,IAAIlC,MAAM,CAACkC,CAAD,CAAN,CAAUxC,IAAV,KAAmBW,CAAC,CAACX,IAAzB,EAA+B;YAC7B;YACA;YACAN,OAAA,CAAAgD,OAAA,CAAcC,IAAd,WAAAC,MAAA,CAA6BjC,CAAC,CAACZ,IAA/B,mBAAA6C,MAAA,CAAmDjC,CAAC,CAACX,IAArD,kBAAA4C,MAAA,CAAwEtC,MAAM,CAACkC,CAAD,CAAN,CAAUxC,IAAlF;UACD;QACF,CAND;MAOD,CAhCW,CAkCZ;;MACA,OAAO;QACL6C,IAAI,EAAE;UAACvC,MAAM,EAAEyB,aAAT;UAAwBM,IAAI,EAAEV,OAAO,CAACT;QAAtC,CADD;QAEL4B,IAAI,EAAE,IAAAvD,OAAA,aAAKoC,OAAL,EAAc,CAAC,IAAD,EAAO,OAAP,EAAgB,OAAhB,CAAd;MAFD,CAAP;IAID;;;EApDyB/B,OAAA,W;AAuD5B,IAAMmD,aAAa,IAAAC,cAAA,WAAAxC,gBAAA,aAAAwC,cAAA,EAChBrD,SAAA,CAAAyB,QAAA,CAASC,EADO,EACF,IAAIK,aAAJ,CAAkB;EAC/BjB,GAAG,EAAE,SAD0B;EAE/BU,OAAO,EAAExB,SAAA,CAAAyB,QAAA,CAASC,EAFa;EAG/BC,UAAU,EAAER;AAHmB,CAAlB,CADE,OAAAN,gBAAA,aAAAwC,cAAA,EAMhBrD,SAAA,CAAAyB,QAAA,CAASK,EANO,EAMF,IAAIC,aAAJ,CAAkB;EAC/BjB,GAAG,EAAE,SAD0B;EAE/BU,OAAO,EAAExB,SAAA,CAAAyB,QAAA,CAASK,EAFa;EAG/BH,UAAU,EAAEC;AAHmB,CAAlB,CANE,GAAAyB,cAAA,CAAnB;eAaeD,a"},"metadata":{},"sourceType":"script","externalDependencies":[]}