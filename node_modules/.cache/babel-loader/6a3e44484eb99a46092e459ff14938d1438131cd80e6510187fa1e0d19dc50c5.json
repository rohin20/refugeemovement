{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.isGeoJson = isGeoJson;\nexports.isFeature = isFeature;\nexports.isFeatureCollection = isFeatureCollection;\nexports.isRowObject = isRowObject;\nexports.isKeplerGlMap = isKeplerGlMap;\nexports.makeProgressIterator = makeProgressIterator;\nexports.readBatch = readBatch;\nexports.readFileInBatches = readFileInBatches;\nexports.processFileData = processFileData;\nexports.filesToDataPayload = filesToDataPayload;\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _awaitAsyncGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/awaitAsyncGenerator\"));\nvar _wrapAsyncGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/wrapAsyncGenerator\"));\nvar _asyncIterator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncIterator\"));\nrequire(\"@loaders.gl/polyfills\");\nvar _core = require(\"@loaders.gl/core\");\nvar _json = require(\"@loaders.gl/json\");\nvar _csv = require(\"@loaders.gl/csv\");\nvar _dataProcessor = require(\"./data-processor\");\nvar _utils = require(\"../utils/utils\");\nvar _defaultSettings = require(\"../constants/default-settings\");\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        (0, _defineProperty2[\"default\"])(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n  return target;\n}\nvar BATCH_TYPE = {\n  METADATA: 'metadata',\n  PARTIAL_RESULT: 'partial-result',\n  FINAL_RESULT: 'final-result'\n};\nvar CSV_LOADER_OPTIONS = {\n  batchSize: 4000,\n  // Auto de tect number of rows per batch (network batch size)\n  rowFormat: 'object',\n  dynamicTyping: false // not working for now\n};\n\nvar JSON_LOADER_OPTIONS = {\n  // instruct loaders.gl on what json paths to stream\n  jsonpaths: ['$',\n  // JSON Row array\n  '$.features',\n  // GeoJSON\n  '$.datasets' // KeplerGL JSON\n  ]\n};\n\nfunction isGeoJson(json) {\n  // json can be feature collection\n  // or single feature\n  return (0, _utils.isPlainObject)(json) && (isFeature(json) || isFeatureCollection(json));\n}\nfunction isFeature(json) {\n  return json.type === 'Feature' && json.geometry;\n}\nfunction isFeatureCollection(json) {\n  return json.type === 'FeatureCollection' && json.features;\n}\nfunction isRowObject(json) {\n  return Array.isArray(json) && (0, _utils.isPlainObject)(json[0]);\n}\nfunction isKeplerGlMap(json) {\n  return Boolean((0, _utils.isPlainObject)(json) && json.datasets && json.config && json.info && json.info.app === 'kepler.gl');\n}\nfunction makeProgressIterator(_x, _x2) {\n  return _makeProgressIterator.apply(this, arguments);\n} // eslint-disable-next-line complexity\n\nfunction _makeProgressIterator() {\n  _makeProgressIterator = (0, _wrapAsyncGenerator2[\"default\"])( /*#__PURE__*/_regenerator[\"default\"].mark(function _callee(asyncIterator, info) {\n    var rowCount, _iteratorNormalCompletion, _didIteratorError, _iteratorError, _iterator, _step, _value, batch, rowCountInBatch, percent, progress;\n    return _regenerator[\"default\"].wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            rowCount = 0;\n            _iteratorNormalCompletion = true;\n            _didIteratorError = false;\n            _context.prev = 3;\n            _iterator = (0, _asyncIterator2[\"default\"])(asyncIterator);\n          case 5:\n            _context.next = 7;\n            return (0, _awaitAsyncGenerator2[\"default\"])(_iterator.next());\n          case 7:\n            _step = _context.sent;\n            _iteratorNormalCompletion = _step.done;\n            _context.next = 11;\n            return (0, _awaitAsyncGenerator2[\"default\"])(_step.value);\n          case 11:\n            _value = _context.sent;\n            if (_iteratorNormalCompletion) {\n              _context.next = 23;\n              break;\n            }\n            batch = _value;\n            rowCountInBatch = batch.data && batch.data.length || 0;\n            rowCount += rowCountInBatch;\n            percent = Number.isFinite(batch.bytesUsed) ? batch.bytesUsed / info.size : null; // Update progress object\n\n            progress = _objectSpread({\n              rowCount: rowCount,\n              rowCountInBatch: rowCountInBatch\n            }, Number.isFinite(percent) ? {\n              percent: percent\n            } : {});\n            _context.next = 20;\n            return _objectSpread(_objectSpread({}, batch), {}, {\n              progress: progress\n            });\n          case 20:\n            _iteratorNormalCompletion = true;\n            _context.next = 5;\n            break;\n          case 23:\n            _context.next = 29;\n            break;\n          case 25:\n            _context.prev = 25;\n            _context.t0 = _context[\"catch\"](3);\n            _didIteratorError = true;\n            _iteratorError = _context.t0;\n          case 29:\n            _context.prev = 29;\n            _context.prev = 30;\n            if (!(!_iteratorNormalCompletion && _iterator[\"return\"] != null)) {\n              _context.next = 34;\n              break;\n            }\n            _context.next = 34;\n            return (0, _awaitAsyncGenerator2[\"default\"])(_iterator[\"return\"]());\n          case 34:\n            _context.prev = 34;\n            if (!_didIteratorError) {\n              _context.next = 37;\n              break;\n            }\n            throw _iteratorError;\n          case 37:\n            return _context.finish(34);\n          case 38:\n            return _context.finish(29);\n          case 39:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, null, [[3, 25, 29, 39], [30,, 34, 38]]);\n  }));\n  return _makeProgressIterator.apply(this, arguments);\n}\nfunction readBatch(_x3, _x4) {\n  return _readBatch.apply(this, arguments);\n}\nfunction _readBatch() {\n  _readBatch = (0, _wrapAsyncGenerator2[\"default\"])( /*#__PURE__*/_regenerator[\"default\"].mark(function _callee2(asyncIterator, fileName) {\n    var result, batches, _iteratorNormalCompletion2, _didIteratorError2, _iteratorError2, _iterator2, _step2, _value2, batch, streamingPath, i;\n    return _regenerator[\"default\"].wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            result = null;\n            batches = [];\n            _iteratorNormalCompletion2 = true;\n            _didIteratorError2 = false;\n            _context2.prev = 4;\n            _iterator2 = (0, _asyncIterator2[\"default\"])(asyncIterator);\n          case 6:\n            _context2.next = 8;\n            return (0, _awaitAsyncGenerator2[\"default\"])(_iterator2.next());\n          case 8:\n            _step2 = _context2.sent;\n            _iteratorNormalCompletion2 = _step2.done;\n            _context2.next = 12;\n            return (0, _awaitAsyncGenerator2[\"default\"])(_step2.value);\n          case 12:\n            _value2 = _context2.sent;\n            if (_iteratorNormalCompletion2) {\n              _context2.next = 21;\n              break;\n            }\n            batch = _value2;\n\n            // Last batch will have this special type and will provide all the root\n            // properties of the parsed document.\n            // Only json parse will have `FINAL_RESULT`\n            if (batch.batchType === BATCH_TYPE.FINAL_RESULT) {\n              if (batch.container) {\n                result = _objectSpread({}, batch.container);\n              } // Set the streamed data correctly is Batch json path is set\n              // and the path streamed is not the top level object (jsonpath = '$')\n\n              if (batch.jsonpath && batch.jsonpath.length > 1) {\n                streamingPath = new _json._JSONPath(batch.jsonpath);\n                streamingPath.setFieldAtPath(result, batches);\n              } else if (batch.jsonpath && batch.jsonpath.length === 1) {\n                // The streamed object is a ROW JSON-batch (jsonpath = '$')\n                // row objects\n                result = batches;\n              }\n            } else {\n              for (i = 0; i < batch.data.length; i++) {\n                batches.push(batch.data[i]);\n              }\n            }\n            _context2.next = 18;\n            return _objectSpread(_objectSpread(_objectSpread({}, batch), batch.schema ? {\n              headers: Object.keys(batch.schema)\n            } : {}), {}, {\n              fileName: fileName,\n              // if dataset is CSV, data is set to the raw batches\n              data: result ? result : batches\n            });\n          case 18:\n            _iteratorNormalCompletion2 = true;\n            _context2.next = 6;\n            break;\n          case 21:\n            _context2.next = 27;\n            break;\n          case 23:\n            _context2.prev = 23;\n            _context2.t0 = _context2[\"catch\"](4);\n            _didIteratorError2 = true;\n            _iteratorError2 = _context2.t0;\n          case 27:\n            _context2.prev = 27;\n            _context2.prev = 28;\n            if (!(!_iteratorNormalCompletion2 && _iterator2[\"return\"] != null)) {\n              _context2.next = 32;\n              break;\n            }\n            _context2.next = 32;\n            return (0, _awaitAsyncGenerator2[\"default\"])(_iterator2[\"return\"]());\n          case 32:\n            _context2.prev = 32;\n            if (!_didIteratorError2) {\n              _context2.next = 35;\n              break;\n            }\n            throw _iteratorError2;\n          case 35:\n            return _context2.finish(32);\n          case 36:\n            return _context2.finish(27);\n          case 37:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2, null, [[4, 23, 27, 37], [28,, 32, 36]]);\n  }));\n  return _readBatch.apply(this, arguments);\n}\nfunction readFileInBatches(_x5) {\n  return _readFileInBatches.apply(this, arguments);\n}\nfunction _readFileInBatches() {\n  _readFileInBatches = (0, _asyncToGenerator2[\"default\"])( /*#__PURE__*/_regenerator[\"default\"].mark(function _callee3(_ref) {\n    var file, _ref$fileCache, fileCache, _ref$loaders, loaders, _ref$loadOptions, loadOptions, batchIterator, progressIterator;\n    return _regenerator[\"default\"].wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            file = _ref.file, _ref$fileCache = _ref.fileCache, fileCache = _ref$fileCache === void 0 ? [] : _ref$fileCache, _ref$loaders = _ref.loaders, loaders = _ref$loaders === void 0 ? [] : _ref$loaders, _ref$loadOptions = _ref.loadOptions, loadOptions = _ref$loadOptions === void 0 ? {} : _ref$loadOptions;\n            loaders = [_json.JSONLoader, _csv.CSVLoader].concat((0, _toConsumableArray2[\"default\"])(loaders));\n            loadOptions = _objectSpread({\n              csv: CSV_LOADER_OPTIONS,\n              json: JSON_LOADER_OPTIONS,\n              metadata: true\n            }, loadOptions);\n            _context3.next = 5;\n            return (0, _core.parseInBatches)(file, loaders, loadOptions);\n          case 5:\n            batchIterator = _context3.sent;\n            progressIterator = makeProgressIterator(batchIterator, {\n              size: file.size\n            });\n            return _context3.abrupt(\"return\", readBatch(progressIterator, file.name));\n          case 8:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n  return _readFileInBatches.apply(this, arguments);\n}\nfunction processFileData(_ref2) {\n  var content = _ref2.content,\n    fileCache = _ref2.fileCache;\n  return new Promise(function (resolve, reject) {\n    var data = content.data;\n    var format;\n    var processor;\n    if (isKeplerGlMap(data)) {\n      format = _defaultSettings.DATASET_FORMATS.keplergl;\n      processor = _dataProcessor.processKeplerglJSON;\n    } else if (isRowObject(data)) {\n      format = _defaultSettings.DATASET_FORMATS.row;\n      processor = _dataProcessor.processRowObject;\n    } else if (isGeoJson(data)) {\n      format = _defaultSettings.DATASET_FORMATS.geojson;\n      processor = _dataProcessor.processGeojson;\n    }\n    if (format && processor) {\n      var result = processor(data);\n      resolve([].concat((0, _toConsumableArray2[\"default\"])(fileCache), [{\n        data: result,\n        info: {\n          label: content.fileName,\n          format: format\n        }\n      }]));\n    }\n    reject('Unknow File Format');\n  });\n}\nfunction filesToDataPayload(fileCache) {\n  // seperate out files which could be a single datasets. or a keplergl map json\n  var collection = fileCache.reduce(function (accu, file) {\n    var data = file.data,\n      _file$info = file.info,\n      info = _file$info === void 0 ? {} : _file$info;\n    var format = info.format;\n    if (format === _defaultSettings.DATASET_FORMATS.keplergl) {\n      // if file contains a single kepler map dataset & config\n      accu.keplerMaps.push(_objectSpread(_objectSpread({}, data), {}, {\n        options: {\n          centerMap: !(data.config && data.config.mapState)\n        }\n      }));\n    } else if (_defaultSettings.DATASET_FORMATS[format]) {\n      // if file contains only data\n      var newDataset = {\n        data: data,\n        info: _objectSpread({\n          id: info.id || (0, _utils.generateHashId)(4)\n        }, info)\n      };\n      accu.datasets.push(newDataset);\n    }\n    return accu;\n  }, {\n    datasets: [],\n    keplerMaps: []\n  }); // add kepler map first with config\n  // add datasets later in one add data call\n\n  return collection.keplerMaps.concat({\n    datasets: collection.datasets\n  });\n}","map":{"version":3,"names":["require","_core","_json","_csv","_dataProcessor","_utils","_defaultSettings","BATCH_TYPE","METADATA","PARTIAL_RESULT","FINAL_RESULT","CSV_LOADER_OPTIONS","batchSize","rowFormat","dynamicTyping","JSON_LOADER_OPTIONS","jsonpaths","isGeoJson","json","isPlainObject","isFeature","isFeatureCollection","type","geometry","features","isRowObject","Array","isArray","isKeplerGlMap","Boolean","datasets","config","info","app","makeProgressIterator","_callee","asyncIterator","rowCount","_iteratorNormalCompletion","_didIteratorError","_iteratorError","_iterator","_step","_value","batch","rowCountInBatch","percent","progress","_regenerator","wrap","_callee$","_context","prev","next","_asyncIterator2","_awaitAsyncGenerator2","sent","done","value","data","length","Number","isFinite","bytesUsed","size","_objectSpread","t0","finish","stop","readBatch","_callee2","fileName","result","batches","_iteratorNormalCompletion2","_didIteratorError2","_iteratorError2","_iterator2","_step2","_value2","streamingPath","i","_callee2$","_context2","batchType","container","jsonpath","_JSONPath","setFieldAtPath","push","schema","headers","Object","keys","readFileInBatches","_callee3","_ref","file","_ref$fileCache","fileCache","_ref$loaders","loaders","_ref$loadOptions","loadOptions","batchIterator","progressIterator","_callee3$","_context3","JSONLoader","CSVLoader","concat","_toConsumableArray2","csv","metadata","parseInBatches","abrupt","name","processFileData","_ref2","content","Promise","resolve","reject","format","processor","DATASET_FORMATS","keplergl","processKeplerglJSON","row","processRowObject","geojson","processGeojson","label","filesToDataPayload","collection","reduce","accu","_file$info","keplerMaps","options","centerMap","mapState","newDataset","id","generateHashId"],"sources":["/Users/rohinphukan/Desktop/RefugeeWebsite/node_modules/kepler.gl/src/processors/file-handler.js"],"sourcesContent":["// Copyright (c) 2021 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\nimport '@loaders.gl/polyfills';\nimport {parseInBatches} from '@loaders.gl/core';\nimport {JSONLoader, _JSONPath} from '@loaders.gl/json';\nimport {CSVLoader} from '@loaders.gl/csv';\nimport {processGeojson, processKeplerglJSON, processRowObject} from './data-processor';\nimport {isPlainObject, generateHashId} from 'utils/utils';\nimport {DATASET_FORMATS} from 'constants/default-settings';\n\nconst BATCH_TYPE = {\n  METADATA: 'metadata',\n  PARTIAL_RESULT: 'partial-result',\n  FINAL_RESULT: 'final-result'\n};\n\nconst CSV_LOADER_OPTIONS = {\n  batchSize: 4000, // Auto de tect number of rows per batch (network batch size)\n  rowFormat: 'object',\n  dynamicTyping: false // not working for now\n};\n\nconst JSON_LOADER_OPTIONS = {\n  // instruct loaders.gl on what json paths to stream\n  jsonpaths: [\n    '$', // JSON Row array\n    '$.features', // GeoJSON\n    '$.datasets' // KeplerGL JSON\n  ]\n};\n\nexport function isGeoJson(json) {\n  // json can be feature collection\n  // or single feature\n  return isPlainObject(json) && (isFeature(json) || isFeatureCollection(json));\n}\n\nexport function isFeature(json) {\n  return json.type === 'Feature' && json.geometry;\n}\n\nexport function isFeatureCollection(json) {\n  return json.type === 'FeatureCollection' && json.features;\n}\n\nexport function isRowObject(json) {\n  return Array.isArray(json) && isPlainObject(json[0]);\n}\n\nexport function isKeplerGlMap(json) {\n  return Boolean(\n    isPlainObject(json) &&\n      json.datasets &&\n      json.config &&\n      json.info &&\n      json.info.app === 'kepler.gl'\n  );\n}\n\nexport async function* makeProgressIterator(asyncIterator, info) {\n  let rowCount = 0;\n\n  for await (const batch of asyncIterator) {\n    const rowCountInBatch = (batch.data && batch.data.length) || 0;\n    rowCount += rowCountInBatch;\n    const percent = Number.isFinite(batch.bytesUsed) ? batch.bytesUsed / info.size : null;\n\n    // Update progress object\n    const progress = {\n      rowCount,\n      rowCountInBatch,\n      // @ts-ignore\n      ...(Number.isFinite(percent) ? {percent} : {})\n    };\n\n    yield {...batch, progress};\n  }\n}\n\n// eslint-disable-next-line complexity\nexport async function* readBatch(asyncIterator, fileName) {\n  let result = null;\n  const batches = [];\n\n  for await (const batch of asyncIterator) {\n    // Last batch will have this special type and will provide all the root\n    // properties of the parsed document.\n    // Only json parse will have `FINAL_RESULT`\n    if (batch.batchType === BATCH_TYPE.FINAL_RESULT) {\n      if (batch.container) {\n        result = {...batch.container};\n      }\n      // Set the streamed data correctly is Batch json path is set\n      // and the path streamed is not the top level object (jsonpath = '$')\n      if (batch.jsonpath && batch.jsonpath.length > 1) {\n        const streamingPath = new _JSONPath(batch.jsonpath);\n        streamingPath.setFieldAtPath(result, batches);\n      } else if (batch.jsonpath && batch.jsonpath.length === 1) {\n        // The streamed object is a ROW JSON-batch (jsonpath = '$')\n        // row objects\n        result = batches;\n      }\n    } else {\n      for (let i = 0; i < batch.data.length; i++) {\n        batches.push(batch.data[i]);\n      }\n    }\n\n    yield {\n      ...batch,\n      ...(batch.schema ? {headers: Object.keys(batch.schema)} : {}),\n      fileName,\n      // if dataset is CSV, data is set to the raw batches\n      data: result ? result : batches\n    };\n  }\n}\n\nexport async function readFileInBatches({file, fileCache = [], loaders = [], loadOptions = {}}) {\n  loaders = [JSONLoader, CSVLoader, ...loaders];\n  loadOptions = {\n    csv: CSV_LOADER_OPTIONS,\n    json: JSON_LOADER_OPTIONS,\n    metadata: true,\n    ...loadOptions\n  };\n\n  const batchIterator = await parseInBatches(file, loaders, loadOptions);\n  const progressIterator = makeProgressIterator(batchIterator, {size: file.size});\n\n  return readBatch(progressIterator, file.name);\n}\n\nexport function processFileData({content, fileCache}) {\n  return new Promise((resolve, reject) => {\n    const {data} = content;\n\n    let format;\n    let processor;\n    if (isKeplerGlMap(data)) {\n      format = DATASET_FORMATS.keplergl;\n      processor = processKeplerglJSON;\n    } else if (isRowObject(data)) {\n      format = DATASET_FORMATS.row;\n      processor = processRowObject;\n    } else if (isGeoJson(data)) {\n      format = DATASET_FORMATS.geojson;\n      processor = processGeojson;\n    }\n\n    if (format && processor) {\n      const result = processor(data);\n\n      resolve([\n        ...fileCache,\n        {\n          data: result,\n          info: {\n            label: content.fileName,\n            format\n          }\n        }\n      ]);\n    }\n\n    reject('Unknow File Format');\n  });\n}\n\nexport function filesToDataPayload(fileCache) {\n  // seperate out files which could be a single datasets. or a keplergl map json\n  const collection = fileCache.reduce(\n    (accu, file) => {\n      const {data, info = {}} = file;\n      const {format} = info;\n      if (format === DATASET_FORMATS.keplergl) {\n        // if file contains a single kepler map dataset & config\n        accu.keplerMaps.push({\n          ...data,\n          options: {\n            centerMap: !(data.config && data.config.mapState)\n          }\n        });\n      } else if (DATASET_FORMATS[format]) {\n        // if file contains only data\n        const newDataset = {\n          data,\n          info: {\n            id: info.id || generateHashId(4),\n            ...info\n          }\n        };\n        accu.datasets.push(newDataset);\n      }\n      return accu;\n    },\n    {datasets: [], keplerMaps: []}\n  );\n\n  // add kepler map first with config\n  // add datasets later in one add data call\n  return collection.keplerMaps.concat({datasets: collection.datasets});\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;AAoBAA,OAAA;AACA,IAAAC,KAAA,GAAAD,OAAA;AACA,IAAAE,KAAA,GAAAF,OAAA;AACA,IAAAG,IAAA,GAAAH,OAAA;AACA,IAAAI,cAAA,GAAAJ,OAAA;AACA,IAAAK,MAAA,GAAAL,OAAA;AACA,IAAAM,gBAAA,GAAAN,OAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEA,IAAMO,UAAU,GAAG;EACjBC,QAAQ,EAAE,UADO;EAEjBC,cAAc,EAAE,gBAFC;EAGjBC,YAAY,EAAE;AAHG,CAAnB;AAMA,IAAMC,kBAAkB,GAAG;EACzBC,SAAS,EAAE,IADc;EACR;EACjBC,SAAS,EAAE,QAFc;EAGzBC,aAAa,EAAE,KAHU,CAGJ;AAHI,CAA3B;;AAMA,IAAMC,mBAAmB,GAAG;EAC1B;EACAC,SAAS,EAAE,CACT,GADS;EACJ;EACL,YAFS;EAEK;EACd,YAHS,CAGI;EAAA;AALW,CAA5B;;AASO,SAASC,SAATA,CAAmBC,IAAnB,EAAyB;EAC9B;EACA;EACA,OAAO,IAAAb,MAAA,CAAAc,aAAA,EAAcD,IAAd,MAAwBE,SAAS,CAACF,IAAD,CAAT,IAAmBG,mBAAmB,CAACH,IAAD,CAA9D,CAAP;AACD;AAEM,SAASE,SAATA,CAAmBF,IAAnB,EAAyB;EAC9B,OAAOA,IAAI,CAACI,IAAL,KAAc,SAAd,IAA2BJ,IAAI,CAACK,QAAvC;AACD;AAEM,SAASF,mBAATA,CAA6BH,IAA7B,EAAmC;EACxC,OAAOA,IAAI,CAACI,IAAL,KAAc,mBAAd,IAAqCJ,IAAI,CAACM,QAAjD;AACD;AAEM,SAASC,WAATA,CAAqBP,IAArB,EAA2B;EAChC,OAAOQ,KAAK,CAACC,OAAN,CAAcT,IAAd,KAAuB,IAAAb,MAAA,CAAAc,aAAA,EAAcD,IAAI,CAAC,CAAD,CAAlB,CAA9B;AACD;AAEM,SAASU,aAATA,CAAuBV,IAAvB,EAA6B;EAClC,OAAOW,OAAO,CACZ,IAAAxB,MAAA,CAAAc,aAAA,EAAcD,IAAd,KACEA,IAAI,CAACY,QADP,IAEEZ,IAAI,CAACa,MAFP,IAGEb,IAAI,CAACc,IAHP,IAIEd,IAAI,CAACc,IAAL,CAAUC,GAAV,KAAkB,WALR,CAAd;AAOD;SAEsBC,oB;;EAoBvB;;;0GApBO,SAAAC,QAAqCC,aAArC,EAAoDJ,IAApD;IAAA,IAAAK,QAAA,EAAAC,yBAAA,EAAAC,iBAAA,EAAAC,cAAA,EAAAC,SAAA,EAAAC,KAAA,EAAAC,MAAA,EAAAC,KAAA,EAAAC,eAAA,EAAAC,OAAA,EAAAC,QAAA;IAAA,OAAAC,YAAA,YAAAC,IAAA,UAAAC,SAAAC,QAAA;MAAA;QAAA,QAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;UAAA;YACDhB,QADC,GACU,CADV;YAAAC,yBAAA;YAAAC,iBAAA;YAAAY,QAAA,CAAAC,IAAA;YAAAX,SAAA,OAAAa,eAAA,aAGqBlB,aAHrB;UAAA;YAAAe,QAAA,CAAAE,IAAA;YAAA,WAAAE,qBAAA,aAAAd,SAAA,CAAAY,IAAA;UAAA;YAAAX,KAAA,GAAAS,QAAA,CAAAK,IAAA;YAAAlB,yBAAA,GAAAI,KAAA,CAAAe,IAAA;YAAAN,QAAA,CAAAE,IAAA;YAAA,WAAAE,qBAAA,aAAAb,KAAA,CAAAgB,KAAA;UAAA;YAAAf,MAAA,GAAAQ,QAAA,CAAAK,IAAA;YAAA,IAAAlB,yBAAA;cAAAa,QAAA,CAAAE,IAAA;cAAA;YAAA;YAGYT,KAHZ,GAAAD,MAAA;YAIGE,eAJH,GAIsBD,KAAK,CAACe,IAAN,IAAcf,KAAK,CAACe,IAAN,CAAWC,MAA1B,IAAqC,CAJ1D;YAKHvB,QAAQ,IAAIQ,eAAZ;YACMC,OANH,GAMae,MAAM,CAACC,QAAP,CAAgBlB,KAAK,CAACmB,SAAtB,IAAmCnB,KAAK,CAACmB,SAAN,GAAkB/B,IAAI,CAACgC,IAA1D,GAAiE,IAN9E,EAQH;;YACMjB,QATH,GAAAkB,aAAA;cAUD5B,QAAQ,EAARA,QAVC;cAWDQ,eAAe,EAAfA;YAXC,GAaGgB,MAAM,CAACC,QAAP,CAAgBhB,OAAhB,IAA2B;cAACA,OAAO,EAAPA;YAAD,CAA3B,GAAuC,EAb1C;YAAAK,QAAA,CAAAE,IAAA;YAgBH,OAAAY,aAAA,CAAAA,aAAA,KAAUrB,KAAV;cAAiBG,QAAQ,EAARA;YAAjB;UAhBG;YAAAT,yBAAA;YAAAa,QAAA,CAAAE,IAAA;YAAA;UAAA;YAAAF,QAAA,CAAAE,IAAA;YAAA;UAAA;YAAAF,QAAA,CAAAC,IAAA;YAAAD,QAAA,CAAAe,EAAA,GAAAf,QAAA;YAAAZ,iBAAA;YAAAC,cAAA,GAAAW,QAAA,CAAAe,EAAA;UAAA;YAAAf,QAAA,CAAAC,IAAA;YAAAD,QAAA,CAAAC,IAAA;YAAA,OAAAd,yBAAA,IAAAG,SAAA;cAAAU,QAAA,CAAAE,IAAA;cAAA;YAAA;YAAAF,QAAA,CAAAE,IAAA;YAAA,WAAAE,qBAAA,aAAAd,SAAA;UAAA;YAAAU,QAAA,CAAAC,IAAA;YAAA,KAAAb,iBAAA;cAAAY,QAAA,CAAAE,IAAA;cAAA;YAAA;YAAA,MAAAb,cAAA;UAAA;YAAA,OAAAW,QAAA,CAAAgB,MAAA;UAAA;YAAA,OAAAhB,QAAA,CAAAgB,MAAA;UAAA;UAAA;YAAA,OAAAhB,QAAA,CAAAiB,IAAA;QAAA;MAAA;IAAA,GAAAjC,OAAA;EAAA,C;;;SAqBgBkC,S;;;;+FAAhB,SAAAC,SAA0BlC,aAA1B,EAAyCmC,QAAzC;IAAA,IAAAC,MAAA,EAAAC,OAAA,EAAAC,0BAAA,EAAAC,kBAAA,EAAAC,eAAA,EAAAC,UAAA,EAAAC,MAAA,EAAAC,OAAA,EAAAnC,KAAA,EAAAoC,aAAA,EAAAC,CAAA;IAAA,OAAAjC,YAAA,YAAAC,IAAA,UAAAiC,UAAAC,SAAA;MAAA;QAAA,QAAAA,SAAA,CAAA/B,IAAA,GAAA+B,SAAA,CAAA9B,IAAA;UAAA;YACDmB,MADC,GACQ,IADR;YAECC,OAFD,GAEW,EAFX;YAAAC,0BAAA;YAAAC,kBAAA;YAAAQ,SAAA,CAAA/B,IAAA;YAAAyB,UAAA,OAAAvB,eAAA,aAIqBlB,aAJrB;UAAA;YAAA+C,SAAA,CAAA9B,IAAA;YAAA,WAAAE,qBAAA,aAAAsB,UAAA,CAAAxB,IAAA;UAAA;YAAAyB,MAAA,GAAAK,SAAA,CAAA3B,IAAA;YAAAkB,0BAAA,GAAAI,MAAA,CAAArB,IAAA;YAAA0B,SAAA,CAAA9B,IAAA;YAAA,WAAAE,qBAAA,aAAAuB,MAAA,CAAApB,KAAA;UAAA;YAAAqB,OAAA,GAAAI,SAAA,CAAA3B,IAAA;YAAA,IAAAkB,0BAAA;cAAAS,SAAA,CAAA9B,IAAA;cAAA;YAAA;YAIYT,KAJZ,GAAAmC,OAAA;;YAKH;YACA;YACA;YACA,IAAInC,KAAK,CAACwC,SAAN,KAAoB7E,UAAU,CAACG,YAAnC,EAAiD;cAC/C,IAAIkC,KAAK,CAACyC,SAAV,EAAqB;gBACnBb,MAAM,GAAAP,aAAA,KAAOrB,KAAK,CAACyC,SAAb,CAAN;cACD,CAH8C,CAI/C;cACA;;cACA,IAAIzC,KAAK,CAAC0C,QAAN,IAAkB1C,KAAK,CAAC0C,QAAN,CAAe1B,MAAf,GAAwB,CAA9C,EAAiD;gBACzCoB,aADyC,GACzB,IAAI9E,KAAA,CAAAqF,SAAJ,CAAc3C,KAAK,CAAC0C,QAApB,CADyB;gBAE/CN,aAAa,CAACQ,cAAd,CAA6BhB,MAA7B,EAAqCC,OAArC;cACD,CAHD,MAGO,IAAI7B,KAAK,CAAC0C,QAAN,IAAkB1C,KAAK,CAAC0C,QAAN,CAAe1B,MAAf,KAA0B,CAAhD,EAAmD;gBACxD;gBACA;gBACAY,MAAM,GAAGC,OAAT;cACD;YACF,CAdD,MAcO;cACL,KAASQ,CAAT,GAAa,CAAb,EAAgBA,CAAC,GAAGrC,KAAK,CAACe,IAAN,CAAWC,MAA/B,EAAuCqB,CAAC,EAAxC,EAA4C;gBAC1CR,OAAO,CAACgB,IAAR,CAAa7C,KAAK,CAACe,IAAN,CAAWsB,CAAX,CAAb;cACD;YACF;YA1BEE,SAAA,CAAA9B,IAAA;YA4BH,OAAAY,aAAA,CAAAA,aAAA,CAAAA,aAAA,KACKrB,KADL,GAEMA,KAAK,CAAC8C,MAAN,GAAe;cAACC,OAAO,EAAEC,MAAM,CAACC,IAAP,CAAYjD,KAAK,CAAC8C,MAAlB;YAAV,CAAf,GAAsD,EAF5D;cAGEnB,QAAQ,EAARA,QAHF;cAIE;cACAZ,IAAI,EAAEa,MAAM,GAAGA,MAAH,GAAYC;YAL1B;UA5BG;YAAAC,0BAAA;YAAAS,SAAA,CAAA9B,IAAA;YAAA;UAAA;YAAA8B,SAAA,CAAA9B,IAAA;YAAA;UAAA;YAAA8B,SAAA,CAAA/B,IAAA;YAAA+B,SAAA,CAAAjB,EAAA,GAAAiB,SAAA;YAAAR,kBAAA;YAAAC,eAAA,GAAAO,SAAA,CAAAjB,EAAA;UAAA;YAAAiB,SAAA,CAAA/B,IAAA;YAAA+B,SAAA,CAAA/B,IAAA;YAAA,OAAAsB,0BAAA,IAAAG,UAAA;cAAAM,SAAA,CAAA9B,IAAA;cAAA;YAAA;YAAA8B,SAAA,CAAA9B,IAAA;YAAA,WAAAE,qBAAA,aAAAsB,UAAA;UAAA;YAAAM,SAAA,CAAA/B,IAAA;YAAA,KAAAuB,kBAAA;cAAAQ,SAAA,CAAA9B,IAAA;cAAA;YAAA;YAAA,MAAAuB,eAAA;UAAA;YAAA,OAAAO,SAAA,CAAAhB,MAAA;UAAA;YAAA,OAAAgB,SAAA,CAAAhB,MAAA;UAAA;UAAA;YAAA,OAAAgB,SAAA,CAAAf,IAAA;QAAA;MAAA;IAAA,GAAAE,QAAA;EAAA,C;;;SAsCewB,iB;;;;qGAAf,SAAAC,SAAAC,IAAA;IAAA,IAAAC,IAAA,EAAAC,cAAA,EAAAC,SAAA,EAAAC,YAAA,EAAAC,OAAA,EAAAC,gBAAA,EAAAC,WAAA,EAAAC,aAAA,EAAAC,gBAAA;IAAA,OAAAzD,YAAA,YAAAC,IAAA,UAAAyD,UAAAC,SAAA;MAAA;QAAA,QAAAA,SAAA,CAAAvD,IAAA,GAAAuD,SAAA,CAAAtD,IAAA;UAAA;YAAkC4C,IAAlC,GAAAD,IAAA,CAAkCC,IAAlC,EAAAC,cAAA,GAAAF,IAAA,CAAwCG,SAAxC,EAAwCA,SAAxC,GAAAD,cAAA,cAAoD,EAApD,GAAAA,cAAA,EAAAE,YAAA,GAAAJ,IAAA,CAAwDK,OAAxD,EAAwDA,OAAxD,GAAAD,YAAA,cAAkE,EAAlE,GAAAA,YAAA,EAAAE,gBAAA,GAAAN,IAAA,CAAsEO,WAAtE,EAAsEA,WAAtE,GAAAD,gBAAA,cAAoF,EAApF,GAAAA,gBAAA;YACLD,OAAO,IAAInG,KAAA,CAAA0G,UAAJ,EAAgBzG,IAAA,CAAA0G,SAAhB,EAAAC,MAAA,KAAAC,mBAAA,aAA8BV,OAA9B,EAAP;YACAE,WAAW,GAAAtC,aAAA;cACT+C,GAAG,EAAErG,kBADI;cAETO,IAAI,EAAEH,mBAFG;cAGTkG,QAAQ,EAAE;YAHD,GAINV,WAJM,CAAX;YAFKI,SAAA,CAAAtD,IAAA;YAAA,OASuB,IAAApD,KAAA,CAAAiH,cAAA,EAAejB,IAAf,EAAqBI,OAArB,EAA8BE,WAA9B,CATvB;UAAA;YASCC,aATD,GAAAG,SAAA,CAAAnD,IAAA;YAUCiD,gBAVD,GAUoBvE,oBAAoB,CAACsE,aAAD,EAAgB;cAACxC,IAAI,EAAEiC,IAAI,CAACjC;YAAZ,CAAhB,CAVxC;YAAA,OAAA2C,SAAA,CAAAQ,MAAA,WAYE9C,SAAS,CAACoC,gBAAD,EAAmBR,IAAI,CAACmB,IAAxB,CAZX;UAAA;UAAA;YAAA,OAAAT,SAAA,CAAAvC,IAAA;QAAA;MAAA;IAAA,GAAA2B,QAAA;EAAA,C;;;AAeA,SAASsB,eAATA,CAAAC,KAAA,EAA+C;EAAA,IAArBC,OAAqB,GAAAD,KAAA,CAArBC,OAAqB;IAAZpB,SAAY,GAAAmB,KAAA,CAAZnB,SAAY;EACpD,OAAO,IAAIqB,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;IAAA,IAC/B/D,IAD+B,GACvB4D,OADuB,CAC/B5D,IAD+B;IAGtC,IAAIgE,MAAJ;IACA,IAAIC,SAAJ;IACA,IAAIhG,aAAa,CAAC+B,IAAD,CAAjB,EAAyB;MACvBgE,MAAM,GAAGrH,gBAAA,CAAAuH,eAAA,CAAgBC,QAAzB;MACAF,SAAS,GAAGxH,cAAA,CAAA2H,mBAAZ;IACD,CAHD,MAGO,IAAItG,WAAW,CAACkC,IAAD,CAAf,EAAuB;MAC5BgE,MAAM,GAAGrH,gBAAA,CAAAuH,eAAA,CAAgBG,GAAzB;MACAJ,SAAS,GAAGxH,cAAA,CAAA6H,gBAAZ;IACD,CAHM,MAGA,IAAIhH,SAAS,CAAC0C,IAAD,CAAb,EAAqB;MAC1BgE,MAAM,GAAGrH,gBAAA,CAAAuH,eAAA,CAAgBK,OAAzB;MACAN,SAAS,GAAGxH,cAAA,CAAA+H,cAAZ;IACD;IAED,IAAIR,MAAM,IAAIC,SAAd,EAAyB;MACvB,IAAMpD,MAAM,GAAGoD,SAAS,CAACjE,IAAD,CAAxB;MAEA8D,OAAO,IAAAX,MAAA,KAAAC,mBAAA,aACFZ,SADE,IAEL;QACExC,IAAI,EAAEa,MADR;QAEExC,IAAI,EAAE;UACJoG,KAAK,EAAEb,OAAO,CAAChD,QADX;UAEJoD,MAAM,EAANA;QAFI;MAFR,CAFK,GAAP;IAUD;IAEDD,MAAM,CAAC,oBAAD,CAAN;EACD,CAhCM,CAAP;AAiCD;AAEM,SAASW,kBAATA,CAA4BlC,SAA5B,EAAuC;EAC5C;EACA,IAAMmC,UAAU,GAAGnC,SAAS,CAACoC,MAAV,CACjB,UAACC,IAAD,EAAOvC,IAAP,EAAgB;IAAA,IACPtC,IADO,GACYsC,IADZ,CACPtC,IADO;MAAA8E,UAAA,GACYxC,IADZ,CACDjE,IADC;MACDA,IADC,GAAAyG,UAAA,cACM,EADN,GAAAA,UAAA;IAAA,IAEPd,MAFO,GAEG3F,IAFH,CAEP2F,MAFO;IAGd,IAAIA,MAAM,KAAKrH,gBAAA,CAAAuH,eAAA,CAAgBC,QAA/B,EAAyC;MACvC;MACAU,IAAI,CAACE,UAAL,CAAgBjD,IAAhB,CAAAxB,aAAA,CAAAA,aAAA,KACKN,IADL;QAEEgF,OAAO,EAAE;UACPC,SAAS,EAAE,EAAEjF,IAAI,CAAC5B,MAAL,IAAe4B,IAAI,CAAC5B,MAAL,CAAY8G,QAA7B;QADJ;MAFX;IAMD,CARD,MAQO,IAAIvI,gBAAA,CAAAuH,eAAA,CAAgBF,MAAhB,CAAJ,EAA6B;MAClC;MACA,IAAMmB,UAAU,GAAG;QACjBnF,IAAI,EAAJA,IADiB;QAEjB3B,IAAI,EAAAiC,aAAA;UACF8E,EAAE,EAAE/G,IAAI,CAAC+G,EAAL,IAAW,IAAA1I,MAAA,CAAA2I,cAAA,EAAe,CAAf;QADb,GAEChH,IAFD;MAFa,CAAnB;MAOAwG,IAAI,CAAC1G,QAAL,CAAc2D,IAAd,CAAmBqD,UAAnB;IACD;IACD,OAAON,IAAP;EACD,CAxBgB,EAyBjB;IAAC1G,QAAQ,EAAE,EAAX;IAAe4G,UAAU,EAAE;EAA3B,CAzBiB,CAAnB,CAF4C,CA8B5C;EACA;;EACA,OAAOJ,UAAU,CAACI,UAAX,CAAsB5B,MAAtB,CAA6B;IAAChF,QAAQ,EAAEwG,UAAU,CAACxG;EAAtB,CAA7B,CAAP;AACD"},"metadata":{},"sourceType":"script","externalDependencies":[]}