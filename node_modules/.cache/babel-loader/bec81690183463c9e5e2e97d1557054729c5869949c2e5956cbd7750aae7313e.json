{"ast":null,"code":"// Copyright (c) 2022 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.findDefaultColorField = findDefaultColorField;\nexports.validateInputData = validateInputData;\nexports.getSampleForTypeAnalyze = getSampleForTypeAnalyze;\nexports.getFieldsFromData = getFieldsFromData;\nexports.renameDuplicateFields = renameDuplicateFields;\nexports.analyzerTypeToFieldType = analyzerTypeToFieldType;\nexports.ACCEPTED_ANALYZER_TYPES = exports.datasetColorMaker = void 0;\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\nvar _typeof2 = _interopRequireDefault(require(\"@babel/runtime/helpers/typeof\"));\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\nvar _window = require(\"global/window\");\nvar _constants = require(\"@kepler.gl/constants\");\nvar _typeAnalyzer = require(\"type-analyzer\");\nvar _assert = _interopRequireDefault(require(\"assert\"));\nvar _dataUtils = require(\"./data-utils\");\nvar _d3Array = require(\"d3-array\");\nvar _colorUtils = require(\"./color-utils\");\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        (0, _defineProperty2[\"default\"])(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n  return target;\n}\nvar _marked = /*#__PURE__*/_regenerator[\"default\"].mark(generateColor);\n\n// apply a color for each dataset\n// to use as label colors\nvar datasetColors = ['#8F2FBF', '#005CFF', '#C06C84', '#F8B195', '#547A82', '#3EACA8', '#A2D4AB'].map(_colorUtils.hexToRgb);\n/**\n * Random color generator\n */\n\nfunction generateColor() {\n  var index;\n  return _regenerator[\"default\"].wrap(function generateColor$(_context) {\n    while (1) {\n      switch (_context.prev = _context.next) {\n        case 0:\n          index = 0;\n        case 1:\n          if (!(index < datasetColors.length + 1)) {\n            _context.next = 7;\n            break;\n          }\n          if (index === datasetColors.length) {\n            index = 0;\n          }\n          _context.next = 5;\n          return datasetColors[index++];\n        case 5:\n          _context.next = 1;\n          break;\n        case 7:\n        case \"end\":\n          return _context.stop();\n      }\n    }\n  }, _marked);\n}\nvar datasetColorMaker = generateColor();\n/**\n * Field name prefixes and suffixes which should not be considered\n * as metrics. Fields will still be included if a 'metric word'\n * is found on the field name, however.\n */\n\nexports.datasetColorMaker = datasetColorMaker;\nvar EXCLUDED_DEFAULT_FIELDS = [\n// Serial numbers and identification numbers\n'_id', 'id', 'index', 'uuid', 'guid', 'uid', 'gid', 'serial',\n// Geographic IDs are unlikely to be interesting to color\n'zip', 'code', 'post', 'region', 'fips', 'cbgs', 'h3', 's2',\n// Geographic coords (but not z/elevation/altitude\n// since that might be a metric)\n'lat', 'lon', 'lng', 'latitude', 'longitude', '_x', '_y'];\n/**\n * Prefixes and suffixes that indicate a field is a metric.\n *\n * Note that these are in order of preference, first being\n * most preferred.\n */\n\nvar METRIC_DEFAULT_FIELDS = ['metric', 'value', 'sum', 'count', 'unique', 'mean', 'mode', 'median', 'max', 'min', 'deviation', 'variance', 'p99', 'p95', 'p75', 'p50', 'p25', 'p05',\n// Abbreviations are less preferred\n'cnt', 'val'];\n/**\n * Choose a field to use as the default color field of a layer.\n *\n * The heuristic is:\n *\n * First, exclude fields that are on the exclusion list and don't\n * have names that suggest they contain metrics. Also exclude\n * field names that are blank.\n *\n * Next, look for a field that is of real type and contains one\n * of the preferred names (in order of the preferred names).\n *\n * Next, look for a field that is of integer type and contains\n * one of the preferred names (in order of the preferred names).\n *\n * Next, look for the first field that is of real type (in order\n * of field index).\n *\n * Next, look for the first field that is of integer type (in\n * order of field index).\n *\n * It's possible no field will be chosen (i.e. because all fields\n * are strings.)\n *\n * @param dataset\n */\n\nfunction findDefaultColorField(_ref) {\n  var fields = _ref.fields,\n    _ref$fieldPairs = _ref.fieldPairs,\n    fieldPairs = _ref$fieldPairs === void 0 ? [] : _ref$fieldPairs;\n  var fieldsWithoutExcluded = fields.filter(function (field) {\n    if (field.type !== _constants.ALL_FIELD_TYPES.real && field.type !== _constants.ALL_FIELD_TYPES.integer) {\n      // Only select numeric fields.\n      return false;\n    }\n    if (fieldPairs.find(function (pair) {\n      return pair.pair.lat.value === field.name || pair.pair.lng.value === field.name;\n    })) {\n      // Do not permit lat, lon fields\n      return false;\n    }\n    var normalizedFieldName = field.name.toLowerCase();\n    if (normalizedFieldName === '') {\n      // Special case excluded name when the name is blank.\n      return false;\n    }\n    var hasExcluded = EXCLUDED_DEFAULT_FIELDS.find(function (f) {\n      return normalizedFieldName.startsWith(f) || normalizedFieldName.endsWith(f);\n    });\n    var hasInclusion = METRIC_DEFAULT_FIELDS.find(function (f) {\n      return normalizedFieldName.startsWith(f) || normalizedFieldName.endsWith(f);\n    });\n    return !hasExcluded || hasInclusion;\n  });\n  var sortedFields = fieldsWithoutExcluded.sort(function (left, right) {\n    var normalizedLeft = left.name.toLowerCase();\n    var normalizedRight = right.name.toLowerCase();\n    var leftHasInclusion = METRIC_DEFAULT_FIELDS.findIndex(function (f) {\n      return normalizedLeft.startsWith(f) || normalizedLeft.endsWith(f);\n    });\n    var rightHasInclusion = METRIC_DEFAULT_FIELDS.findIndex(function (f) {\n      return normalizedRight.startsWith(f) || normalizedRight.endsWith(f);\n    });\n    if (leftHasInclusion !== rightHasInclusion) {\n      if (leftHasInclusion === -1) {\n        // Elements that do not have the inclusion list should go after those that do.\n        return 1;\n      } else if (rightHasInclusion === -1) {\n        // Elements that do have the inclusion list should go before those that don't.\n        return -1;\n      } // Compare based on order in the inclusion list\n\n      return leftHasInclusion - rightHasInclusion;\n    } // Compare based on type\n\n    if (left.type !== right.type) {\n      if (left.type === _constants.ALL_FIELD_TYPES.real) {\n        return -1;\n      } // left is an integer and right is not\n      // and reals come before integers\n\n      return 1;\n    } // Finally, order based on the order in the datasets columns\n    // @ts-expect-error\n\n    return left.index - right.index;\n  });\n  if (sortedFields.length) {\n    // There was a best match\n    return sortedFields[0];\n  } // No matches\n\n  return null;\n}\nvar ACCEPTED_ANALYZER_TYPES = [_typeAnalyzer.DATA_TYPES.DATE, _typeAnalyzer.DATA_TYPES.TIME, _typeAnalyzer.DATA_TYPES.DATETIME, _typeAnalyzer.DATA_TYPES.NUMBER, _typeAnalyzer.DATA_TYPES.INT, _typeAnalyzer.DATA_TYPES.FLOAT, _typeAnalyzer.DATA_TYPES.BOOLEAN, _typeAnalyzer.DATA_TYPES.STRING, _typeAnalyzer.DATA_TYPES.GEOMETRY, _typeAnalyzer.DATA_TYPES.GEOMETRY_FROM_STRING, _typeAnalyzer.DATA_TYPES.PAIR_GEOMETRY_FROM_STRING, _typeAnalyzer.DATA_TYPES.ZIPCODE, _typeAnalyzer.DATA_TYPES.ARRAY, _typeAnalyzer.DATA_TYPES.OBJECT];\nexports.ACCEPTED_ANALYZER_TYPES = ACCEPTED_ANALYZER_TYPES;\nvar IGNORE_DATA_TYPES = Object.keys(_typeAnalyzer.DATA_TYPES).filter(function (type) {\n  return !ACCEPTED_ANALYZER_TYPES.includes(type);\n});\n/**\n * Validate input data, adding missing field types, rename duplicate columns\n */\n\nfunction validateInputData(data) {\n  if (!(0, _dataUtils.isPlainObject)(data)) {\n    (0, _assert[\"default\"])('addDataToMap Error: dataset.data cannot be null');\n    return null;\n  } else if (!Array.isArray(data.fields)) {\n    (0, _assert[\"default\"])('addDataToMap Error: expect dataset.data.fields to be an array');\n    return null;\n  } else if (!Array.isArray(data.rows)) {\n    (0, _assert[\"default\"])('addDataToMap Error: expect dataset.data.rows to be an array');\n    return null;\n  }\n  var fields = data.fields,\n    rows = data.rows; // check if all fields has name, format and type\n\n  var allValid = fields.every(function (f, i) {\n    if (!(0, _dataUtils.isPlainObject)(f)) {\n      (0, _assert[\"default\"])(\"fields needs to be an array of object, but find \".concat((0, _typeof2[\"default\"])(f)));\n      fields[i] = {};\n    }\n    if (!f.name) {\n      (0, _assert[\"default\"])(\"field.name is required but missing in \".concat(JSON.stringify(f))); // assign a name\n\n      fields[i].name = \"column_\".concat(i);\n    }\n    if (!_constants.ALL_FIELD_TYPES[f.type]) {\n      (0, _assert[\"default\"])(\"unknown field type \".concat(f.type));\n      return false;\n    }\n    if (!fields.every(function (field) {\n      return field.analyzerType;\n    })) {\n      (0, _assert[\"default\"])('field missing analyzerType');\n      return false;\n    } // check time format is correct based on first 10 not empty element\n\n    if (f.type === _constants.ALL_FIELD_TYPES.timestamp) {\n      var sample = findNonEmptyRowsAtField(rows, i, 10).map(function (r) {\n        return {\n          ts: r[i]\n        };\n      });\n      var analyzedType = _typeAnalyzer.Analyzer.computeColMeta(sample)[0];\n      return analyzedType && analyzedType.category === 'TIME' && analyzedType.format === f.format;\n    }\n    return true;\n  });\n  if (allValid) {\n    return {\n      rows: rows,\n      fields: fields\n    };\n  } // if any field has missing type, recalculate it for everyone\n  // because we simply lost faith in humanity\n\n  var sampleData = getSampleForTypeAnalyze({\n    fields: fields.map(function (f) {\n      return f.name;\n    }),\n    rows: rows\n  });\n  var fieldOrder = fields.map(function (f) {\n    return f.name;\n  });\n  var meta = getFieldsFromData(sampleData, fieldOrder);\n  var updatedFields = fields.map(function (f, i) {\n    return _objectSpread(_objectSpread({}, f), {}, {\n      type: meta[i].type,\n      format: meta[i].format,\n      analyzerType: meta[i].analyzerType\n    });\n  });\n  return {\n    fields: updatedFields,\n    rows: rows\n  };\n}\nfunction findNonEmptyRowsAtField(rows, fieldIdx, total) {\n  var sample = [];\n  var i = 0;\n  while (sample.length < total && i < rows.length) {\n    var _rows$i;\n    if ((0, _dataUtils.notNullorUndefined)((_rows$i = rows[i]) === null || _rows$i === void 0 ? void 0 : _rows$i[fieldIdx])) {\n      sample.push(rows[i]);\n    }\n    i++;\n  }\n  return sample;\n}\n/**\n * Getting sample data for analyzing field type.\n */\n\nfunction getSampleForTypeAnalyze(_ref2) {\n  var fields = _ref2.fields,\n    rows = _ref2.rows,\n    _ref2$sampleCount = _ref2.sampleCount,\n    sampleCount = _ref2$sampleCount === void 0 ? 50 : _ref2$sampleCount;\n  var total = Math.min(sampleCount, rows.length); // const fieldOrder = fields.map(f => f.name);\n\n  var sample = (0, _d3Array.range)(0, total, 1).map(function (d) {\n    return {};\n  }); // collect sample data for each field\n\n  fields.forEach(function (field, fieldIdx) {\n    // data counter\n    var i = 0; // sample counter\n\n    var j = 0;\n    while (j < total) {\n      if (i >= rows.length) {\n        // if depleted data pool\n        sample[j][field] = null;\n        j++;\n      } else if ((0, _dataUtils.notNullorUndefined)(rows[i][fieldIdx])) {\n        var value = rows[i][fieldIdx];\n        sample[j][field] = typeof value === 'string' ? value.trim() : value;\n        j++;\n        i++;\n      } else {\n        i++;\n      }\n    }\n  });\n  return sample;\n}\n/**\n * Analyze field types from data in `string` format, e.g. uploaded csv.\n * Assign `type`, `fieldIdx` and `format` (timestamp only) to each field\n *\n * @param data array of row object\n * @param fieldOrder array of field names as string\n * @returns formatted fields\n * @public\n * @example\n *\n * import {getFieldsFromData} from 'kepler.gl/processors';\n * const data = [{\n *   time: '2016-09-17 00:09:55',\n *   value: '4',\n *   surge: '1.2',\n *   isTrip: 'true',\n *   zeroOnes: '0'\n * }, {\n *   time: '2016-09-17 00:30:08',\n *   value: '3',\n *   surge: null,\n *   isTrip: 'false',\n *   zeroOnes: '1'\n * }, {\n *   time: null,\n *   value: '2',\n *   surge: '1.3',\n *   isTrip: null,\n *   zeroOnes: '1'\n * }];\n *\n * const fieldOrder = ['time', 'value', 'surge', 'isTrip', 'zeroOnes'];\n * const fields = getFieldsFromData(data, fieldOrder);\n * // fields = [\n * // {name: 'time', format: 'YYYY-M-D H:m:s', fieldIdx: 1, type: 'timestamp'},\n * // {name: 'value', format: '', fieldIdx: 4, type: 'integer'},\n * // {name: 'surge', format: '', fieldIdx: 5, type: 'real'},\n * // {name: 'isTrip', format: '', fieldIdx: 6, type: 'boolean'},\n * // {name: 'zeroOnes', format: '', fieldIdx: 7, type: 'integer'}];\n *\n */\n\nfunction getFieldsFromData(data, fieldOrder) {\n  // add a check for epoch timestamp\n  var metadata = _typeAnalyzer.Analyzer.computeColMeta(data, [{\n    regex: /.*geojson|all_points/g,\n    dataType: 'GEOMETRY'\n  }, {\n    regex: /.*census/g,\n    dataType: 'STRING'\n  }], {\n    ignoredDataTypes: IGNORE_DATA_TYPES\n  });\n  var _renameDuplicateField = renameDuplicateFields(fieldOrder),\n    fieldByIndex = _renameDuplicateField.fieldByIndex;\n  var result = fieldOrder.map(function (field, index) {\n    var name = fieldByIndex[index];\n    var fieldMeta = metadata.find(function (m) {\n      return m.key === field;\n    });\n    var _ref3 = fieldMeta || {},\n      type = _ref3.type,\n      format = _ref3.format;\n    return {\n      name: name,\n      id: name,\n      displayName: name,\n      format: format,\n      fieldIdx: index,\n      type: analyzerTypeToFieldType(type),\n      analyzerType: type,\n      valueAccessor: function valueAccessor(dc) {\n        return function (d) {\n          return dc.valueAt(d.index, index);\n        };\n      }\n    };\n  });\n  return result;\n}\n/**\n * pass in an array of field names, rename duplicated one\n * and return a map from old field index to new name\n *\n * @param fieldOrder\n * @returns new field name by index\n */\n\nfunction renameDuplicateFields(fieldOrder) {\n  return fieldOrder.reduce(function (accu, field, i) {\n    var allNames = accu.allNames;\n    var fieldName = field; // add a counter to duplicated names\n\n    if (allNames.includes(field)) {\n      var counter = 0;\n      while (allNames.includes(\"\".concat(field, \"-\").concat(counter))) {\n        counter++;\n      }\n      fieldName = \"\".concat(field, \"-\").concat(counter);\n    }\n    accu.fieldByIndex[i] = fieldName;\n    accu.allNames.push(fieldName);\n    return accu;\n  }, {\n    allNames: [],\n    fieldByIndex: []\n  });\n}\n/**\n * Convert type-analyzer output to kepler.gl field types\n *\n * @param aType\n * @returns corresponding type in `ALL_FIELD_TYPES`\n */\n\n/* eslint-disable complexity */\n\nfunction analyzerTypeToFieldType(aType) {\n  var DATE = _typeAnalyzer.DATA_TYPES.DATE,\n    TIME = _typeAnalyzer.DATA_TYPES.TIME,\n    DATETIME = _typeAnalyzer.DATA_TYPES.DATETIME,\n    NUMBER = _typeAnalyzer.DATA_TYPES.NUMBER,\n    INT = _typeAnalyzer.DATA_TYPES.INT,\n    FLOAT = _typeAnalyzer.DATA_TYPES.FLOAT,\n    BOOLEAN = _typeAnalyzer.DATA_TYPES.BOOLEAN,\n    STRING = _typeAnalyzer.DATA_TYPES.STRING,\n    GEOMETRY = _typeAnalyzer.DATA_TYPES.GEOMETRY,\n    GEOMETRY_FROM_STRING = _typeAnalyzer.DATA_TYPES.GEOMETRY_FROM_STRING,\n    PAIR_GEOMETRY_FROM_STRING = _typeAnalyzer.DATA_TYPES.PAIR_GEOMETRY_FROM_STRING,\n    ZIPCODE = _typeAnalyzer.DATA_TYPES.ZIPCODE,\n    ARRAY = _typeAnalyzer.DATA_TYPES.ARRAY,\n    OBJECT = _typeAnalyzer.DATA_TYPES.OBJECT; // TODO: un recognized types\n  // CURRENCY PERCENT NONE\n\n  switch (aType) {\n    case DATE:\n      return _constants.ALL_FIELD_TYPES.date;\n    case TIME:\n    case DATETIME:\n      return _constants.ALL_FIELD_TYPES.timestamp;\n    case FLOAT:\n      return _constants.ALL_FIELD_TYPES.real;\n    case INT:\n      return _constants.ALL_FIELD_TYPES.integer;\n    case BOOLEAN:\n      return _constants.ALL_FIELD_TYPES[\"boolean\"];\n    case GEOMETRY:\n    case GEOMETRY_FROM_STRING:\n    case PAIR_GEOMETRY_FROM_STRING:\n    case ARRAY:\n    case OBJECT:\n      // TODO: create a new data type for objects and arrays\n      return _constants.ALL_FIELD_TYPES.geojson;\n    case NUMBER:\n    case STRING:\n    case ZIPCODE:\n      return _constants.ALL_FIELD_TYPES.string;\n    default:\n      _window.console.warn(\"Unsupported analyzer type: \".concat(aType));\n      return _constants.ALL_FIELD_TYPES.string;\n  }\n}","map":{"version":3,"names":["value","exports","findDefaultColorField","getSampleForTypeAnalyze","renameDuplicateFields","ACCEPTED_ANALYZER_TYPES","datasetColorMaker","_window","require","_constants","_typeAnalyzer","_dataUtils","_d3Array","_colorUtils","_objectSpread","target","i","arguments","length","source","ownKeys","Object","forEach","key","_defineProperty2","getOwnPropertyDescriptors","defineProperties","defineProperty","getOwnPropertyDescriptor","_marked","_regenerator","mark","generateColor","datasetColors","map","hexToRgb","index","wrap","generateColor$","_context","next","stop","EXCLUDED_DEFAULT_FIELDS","METRIC_DEFAULT_FIELDS","_ref","fields","_ref$fieldPairs","fieldPairs","fieldsWithoutExcluded","filter","field","type","ALL_FIELD_TYPES","real","integer","find","pair","lat","name","lng","normalizedFieldName","toLowerCase","hasExcluded","f","startsWith","endsWith","hasInclusion","sortedFields","sort","left","right","normalizedLeft","rightHasInclusion","findIndex","normalizedRight","leftHasInclusion","IGNORE_DATA_TYPES","keys","DATA_TYPES","isPlainObject","data","_assert","Array","isArray","rows","allValid","every","concat","_typeof2","JSON","stringify","analyzerType","timestamp","sample","findNonEmptyRowsAtField","r","analyzedType","Analyzer","computeColMeta","category","format","sampleData","updatedFields","meta","total","_rows$i","push","_ref2","_ref2$sampleCount","sampleCount","Math","min","range","d","fieldIdx","j","notNullorUndefined","trim","metadata","regex","dataType","ignoredDataTypes","_renameDuplicateField","fieldOrder","fieldByIndex","result","fieldMeta","m","_ref3","id","displayName","analyzerTypeToFieldType","valueAccessor","allNames","dc","reduce","accu","fieldName","includes","counter","DATE","TIME","DATETIME","INT","FLOAT","STRING","GEOMETRY","PAIR_GEOMETRY_FROM_STRING","ZIPCODE","OBJECT","aType","date","BOOLEAN"],"sources":["/Users/rohinphukan/Desktop/RefugeeWebsite/node_modules/@kepler.gl/utils/src/dataset-utils.ts"],"sourcesContent":["// Copyright (c) 2022 Uber Technologies, Inc.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\nimport {console as globalConsole} from 'global/window';\nimport {ALL_FIELD_TYPES} from '@kepler.gl/constants';\nimport {Analyzer, DATA_TYPES as AnalyzerDATA_TYPES} from 'type-analyzer';\nimport assert from 'assert';\n\nimport {ProcessorResult, RGBColor, RowData, Field, FieldPair} from '@kepler.gl/types';\n\nimport {notNullorUndefined, isPlainObject} from './data-utils';\nimport {range} from 'd3-array';\nimport {hexToRgb} from './color-utils';\n\n// apply a color for each dataset\n// to use as label colors\nconst datasetColors = [\n  '#8F2FBF',\n  '#005CFF',\n  '#C06C84',\n  '#F8B195',\n  '#547A82',\n  '#3EACA8',\n  '#A2D4AB'\n].map(hexToRgb);\n\n/**\n * Random color generator\n */\nfunction* generateColor(): Generator<RGBColor> {\n  let index = 0;\n  while (index < datasetColors.length + 1) {\n    if (index === datasetColors.length) {\n      index = 0;\n    }\n    yield datasetColors[index++];\n  }\n}\n\nexport const datasetColorMaker = generateColor();\n\n/**\n * Field name prefixes and suffixes which should not be considered\n * as metrics. Fields will still be included if a 'metric word'\n * is found on the field name, however.\n */\nconst EXCLUDED_DEFAULT_FIELDS = [\n  // Serial numbers and identification numbers\n  '_id',\n  'id',\n  'index',\n  'uuid',\n  'guid',\n  'uid',\n  'gid',\n  'serial',\n  // Geographic IDs are unlikely to be interesting to color\n  'zip',\n  'code',\n  'post',\n  'region',\n  'fips',\n  'cbgs',\n  'h3',\n  's2',\n  // Geographic coords (but not z/elevation/altitude\n  // since that might be a metric)\n  'lat',\n  'lon',\n  'lng',\n  'latitude',\n  'longitude',\n  '_x',\n  '_y'\n];\n\n/**\n * Prefixes and suffixes that indicate a field is a metric.\n *\n * Note that these are in order of preference, first being\n * most preferred.\n */\nconst METRIC_DEFAULT_FIELDS = [\n  'metric',\n  'value',\n  'sum',\n  'count',\n  'unique',\n  'mean',\n  'mode',\n  'median',\n  'max',\n  'min',\n  'deviation',\n  'variance',\n  'p99',\n  'p95',\n  'p75',\n  'p50',\n  'p25',\n  'p05',\n  // Abbreviations are less preferred\n  'cnt',\n  'val'\n];\n\n/**\n * Choose a field to use as the default color field of a layer.\n *\n * The heuristic is:\n *\n * First, exclude fields that are on the exclusion list and don't\n * have names that suggest they contain metrics. Also exclude\n * field names that are blank.\n *\n * Next, look for a field that is of real type and contains one\n * of the preferred names (in order of the preferred names).\n *\n * Next, look for a field that is of integer type and contains\n * one of the preferred names (in order of the preferred names).\n *\n * Next, look for the first field that is of real type (in order\n * of field index).\n *\n * Next, look for the first field that is of integer type (in\n * order of field index).\n *\n * It's possible no field will be chosen (i.e. because all fields\n * are strings.)\n *\n * @param dataset\n */\nexport function findDefaultColorField({\n  fields,\n  fieldPairs = []\n}: {\n  fields: Field[];\n  fieldPairs: FieldPair[];\n}): null | Field {\n  const fieldsWithoutExcluded = fields.filter(field => {\n    if (field.type !== ALL_FIELD_TYPES.real && field.type !== ALL_FIELD_TYPES.integer) {\n      // Only select numeric fields.\n      return false;\n    }\n    if (\n      fieldPairs.find(\n        pair => pair.pair.lat.value === field.name || pair.pair.lng.value === field.name\n      )\n    ) {\n      // Do not permit lat, lon fields\n      return false;\n    }\n\n    const normalizedFieldName = field.name.toLowerCase();\n    if (normalizedFieldName === '') {\n      // Special case excluded name when the name is blank.\n      return false;\n    }\n    const hasExcluded = EXCLUDED_DEFAULT_FIELDS.find(\n      f => normalizedFieldName.startsWith(f) || normalizedFieldName.endsWith(f)\n    );\n    const hasInclusion = METRIC_DEFAULT_FIELDS.find(\n      f => normalizedFieldName.startsWith(f) || normalizedFieldName.endsWith(f)\n    );\n    return !hasExcluded || hasInclusion;\n  });\n\n  const sortedFields = fieldsWithoutExcluded.sort((left, right) => {\n    const normalizedLeft = left.name.toLowerCase();\n    const normalizedRight = right.name.toLowerCase();\n    const leftHasInclusion = METRIC_DEFAULT_FIELDS.findIndex(\n      f => normalizedLeft.startsWith(f) || normalizedLeft.endsWith(f)\n    );\n    const rightHasInclusion = METRIC_DEFAULT_FIELDS.findIndex(\n      f => normalizedRight.startsWith(f) || normalizedRight.endsWith(f)\n    );\n    if (leftHasInclusion !== rightHasInclusion) {\n      if (leftHasInclusion === -1) {\n        // Elements that do not have the inclusion list should go after those that do.\n        return 1;\n      } else if (rightHasInclusion === -1) {\n        // Elements that do have the inclusion list should go before those that don't.\n        return -1;\n      }\n      // Compare based on order in the inclusion list\n      return leftHasInclusion - rightHasInclusion;\n    }\n\n    // Compare based on type\n    if (left.type !== right.type) {\n      if (left.type === ALL_FIELD_TYPES.real) {\n        return -1;\n      }\n      // left is an integer and right is not\n      // and reals come before integers\n      return 1;\n    }\n\n    // Finally, order based on the order in the datasets columns\n    // @ts-expect-error\n    return left.index - right.index;\n  });\n\n  if (sortedFields.length) {\n    // There was a best match\n    return sortedFields[0];\n  }\n  // No matches\n  return null;\n}\n\nexport const ACCEPTED_ANALYZER_TYPES = [\n  AnalyzerDATA_TYPES.DATE,\n  AnalyzerDATA_TYPES.TIME,\n  AnalyzerDATA_TYPES.DATETIME,\n  AnalyzerDATA_TYPES.NUMBER,\n  AnalyzerDATA_TYPES.INT,\n  AnalyzerDATA_TYPES.FLOAT,\n  AnalyzerDATA_TYPES.BOOLEAN,\n  AnalyzerDATA_TYPES.STRING,\n  AnalyzerDATA_TYPES.GEOMETRY,\n  AnalyzerDATA_TYPES.GEOMETRY_FROM_STRING,\n  AnalyzerDATA_TYPES.PAIR_GEOMETRY_FROM_STRING,\n  AnalyzerDATA_TYPES.ZIPCODE,\n  AnalyzerDATA_TYPES.ARRAY,\n  AnalyzerDATA_TYPES.OBJECT\n];\n\nconst IGNORE_DATA_TYPES = Object.keys(AnalyzerDATA_TYPES).filter(\n  type => !ACCEPTED_ANALYZER_TYPES.includes(type)\n);\n\n/**\n * Validate input data, adding missing field types, rename duplicate columns\n */\nexport function validateInputData(data: Record<string, unknown>): ProcessorResult {\n  if (!isPlainObject(data)) {\n    assert('addDataToMap Error: dataset.data cannot be null');\n    return null;\n  } else if (!Array.isArray(data.fields)) {\n    assert('addDataToMap Error: expect dataset.data.fields to be an array');\n    return null;\n  } else if (!Array.isArray(data.rows)) {\n    assert('addDataToMap Error: expect dataset.data.rows to be an array');\n    return null;\n  }\n\n  const {fields, rows} = data;\n\n  // check if all fields has name, format and type\n  const allValid = fields.every((f, i) => {\n    if (!isPlainObject(f)) {\n      assert(`fields needs to be an array of object, but find ${typeof f}`);\n      fields[i] = {};\n    }\n\n    if (!f.name) {\n      assert(`field.name is required but missing in ${JSON.stringify(f)}`);\n      // assign a name\n      fields[i].name = `column_${i}`;\n    }\n\n    if (!ALL_FIELD_TYPES[f.type]) {\n      assert(`unknown field type ${f.type}`);\n      return false;\n    }\n\n    if (!fields.every(field => field.analyzerType)) {\n      assert('field missing analyzerType');\n      return false;\n    }\n\n    // check time format is correct based on first 10 not empty element\n    if (f.type === ALL_FIELD_TYPES.timestamp) {\n      const sample = findNonEmptyRowsAtField(rows, i, 10).map(r => ({ts: r[i]}));\n      const analyzedType = Analyzer.computeColMeta(sample)[0];\n      return analyzedType && analyzedType.category === 'TIME' && analyzedType.format === f.format;\n    }\n\n    return true;\n  });\n\n  if (allValid) {\n    return {rows, fields};\n  }\n\n  // if any field has missing type, recalculate it for everyone\n  // because we simply lost faith in humanity\n  const sampleData = getSampleForTypeAnalyze({\n    fields: fields.map(f => f.name),\n    rows\n  });\n  const fieldOrder = fields.map(f => f.name);\n  const meta = getFieldsFromData(sampleData, fieldOrder);\n  const updatedFields = fields.map((f, i) => ({\n    ...f,\n    type: meta[i].type,\n    format: meta[i].format,\n    analyzerType: meta[i].analyzerType\n  }));\n\n  return {fields: updatedFields, rows};\n}\n\nfunction findNonEmptyRowsAtField(rows: unknown[][], fieldIdx: number, total: number): any[] {\n  const sample: any[] = [];\n  let i = 0;\n  while (sample.length < total && i < rows.length) {\n    if (notNullorUndefined(rows[i]?.[fieldIdx])) {\n      sample.push(rows[i]);\n    }\n    i++;\n  }\n  return sample;\n}\n/**\n * Getting sample data for analyzing field type.\n */\nexport function getSampleForTypeAnalyze({\n  fields,\n  rows,\n  sampleCount = 50\n}: {\n  fields: string[];\n  rows: unknown[][];\n  sampleCount?: number;\n}): RowData {\n  const total = Math.min(sampleCount, rows.length);\n  // const fieldOrder = fields.map(f => f.name);\n  const sample = range(0, total, 1).map(d => ({}));\n\n  // collect sample data for each field\n  fields.forEach((field, fieldIdx) => {\n    // data counter\n    let i = 0;\n    // sample counter\n    let j = 0;\n\n    while (j < total) {\n      if (i >= rows.length) {\n        // if depleted data pool\n        sample[j][field] = null;\n        j++;\n      } else if (notNullorUndefined(rows[i][fieldIdx])) {\n        const value = rows[i][fieldIdx];\n        sample[j][field] = typeof value === 'string' ? value.trim() : value;\n        j++;\n        i++;\n      } else {\n        i++;\n      }\n    }\n  });\n\n  return sample;\n}\n\n/**\n * Analyze field types from data in `string` format, e.g. uploaded csv.\n * Assign `type`, `fieldIdx` and `format` (timestamp only) to each field\n *\n * @param data array of row object\n * @param fieldOrder array of field names as string\n * @returns formatted fields\n * @public\n * @example\n *\n * import {getFieldsFromData} from 'kepler.gl/processors';\n * const data = [{\n *   time: '2016-09-17 00:09:55',\n *   value: '4',\n *   surge: '1.2',\n *   isTrip: 'true',\n *   zeroOnes: '0'\n * }, {\n *   time: '2016-09-17 00:30:08',\n *   value: '3',\n *   surge: null,\n *   isTrip: 'false',\n *   zeroOnes: '1'\n * }, {\n *   time: null,\n *   value: '2',\n *   surge: '1.3',\n *   isTrip: null,\n *   zeroOnes: '1'\n * }];\n *\n * const fieldOrder = ['time', 'value', 'surge', 'isTrip', 'zeroOnes'];\n * const fields = getFieldsFromData(data, fieldOrder);\n * // fields = [\n * // {name: 'time', format: 'YYYY-M-D H:m:s', fieldIdx: 1, type: 'timestamp'},\n * // {name: 'value', format: '', fieldIdx: 4, type: 'integer'},\n * // {name: 'surge', format: '', fieldIdx: 5, type: 'real'},\n * // {name: 'isTrip', format: '', fieldIdx: 6, type: 'boolean'},\n * // {name: 'zeroOnes', format: '', fieldIdx: 7, type: 'integer'}];\n *\n */\nexport function getFieldsFromData(data: RowData, fieldOrder: string[]): Field[] {\n  // add a check for epoch timestamp\n  const metadata = Analyzer.computeColMeta(\n    data,\n    [\n      {regex: /.*geojson|all_points/g, dataType: 'GEOMETRY'},\n      {regex: /.*census/g, dataType: 'STRING'}\n    ],\n    {ignoredDataTypes: IGNORE_DATA_TYPES}\n  );\n\n  const {fieldByIndex} = renameDuplicateFields(fieldOrder);\n\n  const result = fieldOrder.map((field, index) => {\n    const name = fieldByIndex[index];\n\n    const fieldMeta = metadata.find(m => m.key === field);\n    const {type, format} = fieldMeta || {};\n\n    return {\n      name,\n      id: name,\n      displayName: name,\n      format,\n      fieldIdx: index,\n      type: analyzerTypeToFieldType(type),\n      analyzerType: type,\n      valueAccessor: dc => d => {\n        return dc.valueAt(d.index, index);\n      }\n    };\n  });\n\n  return result;\n}\n\n/**\n * pass in an array of field names, rename duplicated one\n * and return a map from old field index to new name\n *\n * @param fieldOrder\n * @returns new field name by index\n */\nexport function renameDuplicateFields(\n  fieldOrder: string[]\n): {allNames: string[]; fieldByIndex: string[]} {\n  return fieldOrder.reduce<{allNames: string[]; fieldByIndex: string[]}>(\n    (accu, field, i) => {\n      const {allNames} = accu;\n      let fieldName = field;\n\n      // add a counter to duplicated names\n      if (allNames.includes(field)) {\n        let counter = 0;\n        while (allNames.includes(`${field}-${counter}`)) {\n          counter++;\n        }\n        fieldName = `${field}-${counter}`;\n      }\n\n      accu.fieldByIndex[i] = fieldName;\n      accu.allNames.push(fieldName);\n\n      return accu;\n    },\n    {allNames: [], fieldByIndex: []}\n  );\n}\n\n/**\n * Convert type-analyzer output to kepler.gl field types\n *\n * @param aType\n * @returns corresponding type in `ALL_FIELD_TYPES`\n */\n/* eslint-disable complexity */\nexport function analyzerTypeToFieldType(aType: string): string {\n  const {\n    DATE,\n    TIME,\n    DATETIME,\n    NUMBER,\n    INT,\n    FLOAT,\n    BOOLEAN,\n    STRING,\n    GEOMETRY,\n    GEOMETRY_FROM_STRING,\n    PAIR_GEOMETRY_FROM_STRING,\n    ZIPCODE,\n    ARRAY,\n    OBJECT\n  } = AnalyzerDATA_TYPES;\n\n  // TODO: un recognized types\n  // CURRENCY PERCENT NONE\n  switch (aType) {\n    case DATE:\n      return ALL_FIELD_TYPES.date;\n    case TIME:\n    case DATETIME:\n      return ALL_FIELD_TYPES.timestamp;\n    case FLOAT:\n      return ALL_FIELD_TYPES.real;\n    case INT:\n      return ALL_FIELD_TYPES.integer;\n    case BOOLEAN:\n      return ALL_FIELD_TYPES.boolean;\n    case GEOMETRY:\n    case GEOMETRY_FROM_STRING:\n    case PAIR_GEOMETRY_FROM_STRING:\n    case ARRAY:\n    case OBJECT:\n      // TODO: create a new data type for objects and arrays\n      return ALL_FIELD_TYPES.geojson;\n    case NUMBER:\n    case STRING:\n    case ZIPCODE:\n      return ALL_FIELD_TYPES.string;\n    default:\n      globalConsole.warn(`Unsupported analyzer type: ${aType}`);\n      return ALL_FIELD_TYPES.string;\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;EAsBAA,KAAA;;AACAC,OAAA,CAAAC,qBAAA,GAAAA,qBAAA;;AAIAD,OAAA,CAAAE,uBAAA,GAAAA,uBAAA;;AACAF,OAAA,CAAAG,qBAAA,GAAAA,qBAAA;;AACAH,OAAA,CAAAI,uBAAA,GAAAJ,OAAA,CAAAK,iBAAA;;;;AAEA,IAAAC,OAAA,GAAAC,OAAA;AAEA,IAAMC,UAAA,GAAaD,OACjB,uBAEA;AAQF,IAAAE,aAAA,GAAAF,OAAA;;AAEA,IAAAG,UAAA,GAAAH,OAAA;AAAA,IAAAI,QAAA,GAAAJ,OAAA;AAAA,IAAAK,WAAA,GAAAL,OAAA;;;;;;;;;;;;AAAA,SAAAM,aAEcA,CAAAC,MAAG;EAAA,KAAc,IAAAC,CAAA,GAAd,CAAuB,EAFxCA,CAAA,GAAAC,SAAA,CAAAC,MAAA,EAAAF,CAAA;IAAA,IAAAG,MAAA,GAAAF,SAAA,CAAAD,CAAA,YAAAC,SAAA,CAAAD,CAAA;IAAA,IAAAA,CAAA;MAAAI,OAAA,CAAAC,MAAA,CAAAF,MAAA,SAAAG,OAAA,WAAAC,GAAA;QAAA,IAAAC,gBAAA,aAAAT,MAAA,EAAAQ,GAAA,EAAAJ,MAAA,CAAAI,GAAA;MAAA;IAAA,WAAAF,MAAA,CAAAI,yBAAA;MAAAJ,MAAA,CAAAK,gBAAA,CAAAX,MAAA,EAAAM,MAAA,CAAAI,yBAAA,CAAAN,MAAA;IAAA;MAAAC,OAAA,CAAAC,MAAA,CAAAF,MAAA,GAAAG,OAAA,WAAAC,GAAA;QAAAF,MAAA,CAAAM,cAAA,CAAAZ,MAAA,EAAAQ,GAAA,EAAAF,MAAA,CAAAO,wBAAA,CAAAT,MAAA,EAAAI,GAAA;MAAA;IAAA;EAAA;EAAA,OAAAR,MAAA;AAAA;AAAA,IAAAc,OAAA,gBAAAC,YAAA,YAAAC,IAAA,CAAAC,aAAA;;;AAGI;AACE,IAAAC,aAAK,GAAG,CAAR,6EAAAC,GAAA,CAAArB,WAAA,CAAAsB,QAAA;AACD;;AALL;;;EAAA,IAAAC,KAAA;EAAA,OAAAN,YAAA,YAAAO,IAAA,UAAAC,eAAAC,QAAA;IAAA;;QAAA;UAAAH,KAAA;QAAA;UAAA,MAAAA,KAAA,GAAAH,aAAA,CAAAf,MAAA;YAAAqB,QAAA,CAAAC,IAAA;YAAA;;UAYA,IAAAJ,KAAA,KAAAH,aAAA,CAAAf,MAAA;YACAkB,KAAA;UACA;UAEAG,QAAA,CAAAC,IAAA;;QACM;UAGJD,QACA,CAAAC,IACA;UAOA;QAUA,KAtB8B,CAuB9B;QAOF;UACA,OAAAD,QAAA,CAAAE,IAAA;MAAA;IAEA;EACA,GAAAZ,OAAA;AACA;AACA,IAAMvB,iBAAA,GAAA0B,aAAwB,EAE5B;AAkBA;AAIF;AACA;AACA;AACA;;AAEA/B,OAAA,CAAAK,iBAAA,GAAAA,iBAAA;AACA,IAAAoC,uBAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,IAAAC,qBAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO;AAMU;AAAA;AAAA;AACf;AACE;AACE;AACA;AACD;;AACD;AAEQ;AAAA;AAGN;AACA;AACD;;AAED;;;AAEE,SAAAzC,sBAAA0C,IAAA;EACA,IAAAC,MAAA,GAAOD,IAAP,CAAAC,MAAA;IACDC,eAAA,GAAAF,IAAA,CAAAG,UAAA;;EACD,IAAAC,qBAAoB,GAAAH,MAAA,CAAAI,MAAA,WAClBC,KAAA;IAAC,IAAAA,KAAI,CAAAC,IAAA,KAAA1C,UAAoB,CAAA2C,eAApB,CAAqCC,IAAA,IAAAH,KAAA,CAAAC,IAAA,KAAoB1C,UAA7D,CAAA2C,eAAA,CAAAE,OAAA;MADH;MAGA,OAAM;IACH;IAEH,IAAAP,UAAQ,CAAAQ,IAAD,WAAgBC,IAAA,EAAvB;MAzBF,OAAAA,IAAA,CAAAA,IAAA,CAAAC,GAAA,CAAAzD,KAAA,KAAAkD,KAAA,CAAAQ,IAAA,IAAAF,IAAA,CAAAA,IAAA,CAAAG,GAAA,CAAA3D,KAAA,KAAAkD,KAAA,CAAAQ,IAAA;IA4BA,EAAM;MACJ;MACA,OAAM;IACN;IACG,IADHE,mBAAA,GAAAV,KAAA,CAAAQ,IAAA,CAAAG,WAAA;IAIG,IAAAD,mBAAI,KAAgB;MADvB;;IAGA;IAEI,IAAAE,WAAA,GAAApB,uBAAA,CAAAa,IAAA,WAAAQ,CAAA;MACA,OAAAH,mBAAA,CAAAI,UAAA,CAAAD,CAAA,KAAAH,mBAAA,CAAAK,QAAA,CAAAF,CAAA;IACD;IACC,IAAAG,YAAA,GAAAvB,qBAAA,CAAAY,IAAA,WAAAQ,CAAA;MACA,OAAAH,mBAAA,CAAAI,UAAA,CAAAD,CAAA,KAAAH,mBAAA,CAAAK,QAAA,CAAAF,CAAA;IACD;;;EAED,IAAAI,YAAO,GAAAnB,qBAAmB,CAAAoB,IAAA,WAA1BC,IAAA,EAAAC,KAAA;IACD,IAEDC,cAAA,GAAAF,IAAA,CAAAX,IAAA,CAAAG,WAAA;;;MACA,OAASU,cAAc,CAACP,UAAM,CAAAD,CAAA,KAAAQ,cAAA,CAAAN,QAAA,CAAAF,CAAA;IAC5B;IACE,IAAAS,iBAAA,GAAA7B,qBAAA,CAAA8B,SAAA,WAAAV,CAAA;MACD,OACDW,eAAA,CAAAV,UAAA,CAAAD,CAAA,KAAAW,eAAA,CAAAT,QAAA,CAAAF,CAAA;IACA;;MACA,IAAAY,gBAAA;QAGF;QACA;;;QACA,OAAW,CAAC;MAjCd;;MAqCE,OAAAA,gBAAA,GAAAH,iBAAA;IACA;;;MAGF,IAAOH,IAAP,CAAAlB,IAAA,KAAA1C,UAAA,CAAA2C,eAAA,CAAAC,IAAA;QACD;;MAEY;;MAkBP,OAAK;IADX;IAIA;;;EAGO;EAEH,IAAAc,YAAA,CAAAjD,MAAA;IACA;IAFF,OAGOiD,YAAW;EAChB;;EAGA;AACA;;AAT8ElE,OAYzE,CAAAI,uBAZyE,GAAAA,uBAAA;AAAA,IAAAuE,iBAYjE,GAEfvD,MAAA,CAAAwD,IAAA,CAAAnE,aAAA,CAAAoE,UAAA,EAAA7B,MAAA,WAAAE,IAAA;;AACA;AACE;AACE;AACA;;;EAGF,MAAI,CAAC,EAAExC,UAAM,CAAAoE,aAAA,EAAAC,IAAA;IACX,IAAAC,OAAA,+DAAgD;;EAEhD,WAAO,CAADC,KAAI,CAAVC,OAAA,CAAAH,IAAA,CAAAnC,MAAA,CAA2B,EAA3B;IACD,IAAAoC,OAAA;;EAED,OAAK,KAAAC,KAAA,CAAAC,OAAA,CAAAH,IAAA,CAAAI,IAAiB,CAAC;IACrB,IAAAH,OAAA;IACA,WAAO;EACR;EAED,IAAApC,MAAK,GAAMmC,IAAC,CAAAnC,MAAM;IAAKuC,IAAA,GAAIJ,IAAA,CAAKI,IAAC;;EAC/B,IAAAC,QAAA,GAAAxC,MAAA,CAAAyC,KAAA,CAAO,UAAAvB,CAAA,EAAA/C,CAAA;IACP,SAAOL,UAAP,CAAAoE,aAAA,EAAAhB,CAAA;MAGF,IAAAkB,OAAA,gEAAAM,MAAA,KAAAC,QAAA,aAAAzB,CAAA;;;IAEE,KAAAA,CAAM,CAAAL,IAAA,EAAM;MAA6C,IAAAuB,OAAK,sDAAAM,MAAA,CAAAE,IAAA,CAAAC,SAAA,CAAA3B,CAAA;;MAAAlB,MAAL,CAAA7B,CAAA,EAAA0C,IAAA,aAAA6B,MAAA,CAAAvE,CAAA;IAAA;IACzD,KAAAP,UAAM,CAAA2C,eAAe,CAAAW,CAAA,CAAAZ,IAAA;;MACrB,OAAO;IACR;IAED,KAAAN,MAAA,CAAAyC,KAAA,WAAApC,KAAA;MA7BF,OAAAA,KAAA,CAAAyC,YAAA;;MAgCI,IAAAV,OAAU;MACZ,OAAO;IAAC;;IAGV,IAAAlB,CAAA,CAAAZ,IAAA,KAAA1C,UAAA,CAAA2C,eAAA,CAAAwC,SAAA;MACA,IAAAC,MAAA,GAAAC,uBAAA,CAAAV,IAAA,EAAApE,CAAA,MAAAkB,GAAA,WAAA6D,CAAA;;;QACM;MACJ;MADyC,IAAAC,YAAA,GAAAtF,aAAA,CAAAuF,QAAA,CAAAC,cAAA,CAAAL,MAAA;MAA3C,OAAAG,YAAA,IAAAA,YAAA,CAAAG,QAAA,eAAAH,YAAA,CAAAI,MAAA,KAAArC,CAAA,CAAAqC,MAAA;IAIA;IAAA;EACA;EACiC,IAAAf,QAAA;IAE/B,OAAI;MACJD,IAAA,EAAMA,IAAE;MACRvC,MAAA,EAAAA;IAJ+B;EAAA,CAAX,CAAtB;EAOA;;EAAO,IAAPwD,UAAA,GAAAlG,uBAAA;IACD0C,MAAA,EAAAA,MAAA,CAAAX,GAAA,WAAA6B,CAAA;;IAED;IACEqB,IAAM,EAAAA;EACN;;IACA,OAAOrB,CAAA,CAAAL,IAAO;EAAmC;;EAC/C,IAAA4C,aAAI,GAAAzD,MAAA,CAAAX,GAAA,WAAA6B,CAAA,EAAA/C,CAAA;IACF,OAAAF,aAAgB,CAAhBA,aAAA,KAAAiD,CAAA;MACDZ,IAAA,EAAAoD,IAAA,CAAAvF,CAAA,EAAAmC,IAAA;;MACAwC,YAAA,EAAAY,IAAA,CAAAvF,CAAA,EAAA2E;IACF;;EACD,OAAO;IACR9C,MAAA,EAAAyD,aAAA;IACDlB,IAAA,EAAAA;EACA;AACA;;EACO,IAAAS,MAAS;EAQJ,IAPV7E,CAAA;EAOU,OAAA6E,MAAA,CAAA3E,MAAA,GAAAsF,KAAA,IALVxF,CAAA,GAAAoE,IAAA,CAKUlE,MAAA;IAAA,IALVuF,OAAA;;MAQMZ,MAAM,CAAAa,IAAG,CAAAtB,IAAA,CAAApE,CAAA;IAAwB;;EAGvC;EAEE,OAAK6E,MACL;;AACA;;AAEA;;AAGI,SAAA1F,uBAAA0F,CAAAc,KAAA;EACA,IAAA9D,MAAC,GAAA8D,KAAA,CAAA9D,MAAA;IACFuC,IAJD,GAIOuB,KAAI,CAAAvB,IAAA;IACTwB,iBAAc,GAAID,KAAI,CAAAE,WAAtB;IACAA,WAAA,GAAUD,iBAAgB,KAAP,KAAiB,MAAjB,GAA4BA,iBAAe;EAC9D,IAAAJ,KAAC,GAAAM,IAAA,CAAAC,GAAA,CAAAF,WAAA,EAAAzB,IAAA,CAAAlE,MAAA;;EAEF,IAAA2E,MALM,GAKA,IAAAjF,QAAA,CAAAoG,KAAA,KAAAR,KAAA,KAAAtE,GAAA,WAAA+E,CAAA;IACL,OAAC;EACF;;EAEJpE,MApBD,CAAAvB,OAAA,WAAA4B,KAAA,EAAAgE,QAAA;IAsBA;IACD,IAAAlG,CAAA;;IAGD,IAAAmG,CAAA;IAEA,OAAAA,CAAA,GAAAX,KAAA;MACA,IAAAxF,CAAA,IAAAoE,IAAA,CAAAlE,MAAA;QACA;QACA2E,MAAA,CAAAsB,CAAA,EAAAjE,KAAA;QACAiE,CAAA;MACA,eAAAxG,UAAA,CAAAyG,kBAAA,EAAAhC,IAAA,CAAApE,CAAA,EAAAkG,QAAA;QACA,IAAAlH,KAAA,GAAAoF,IAAA,CAAApE,CAAA,EAAAkG,QAAA;QACArB,MAAA,CAAAsB,CAAA,EAAAjE,KAAA,WAAAlD,KAAA,gBAAAA,KAAA,CAAAqH,IAAA,KAAArH,KAAA;QACAmH,CAAA;QACAnG,CAAA;MACA;QACAA,CAAA;MACA;IACA;EACA;EACA,OAAA6E,MAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACO;AACL;AACA;AAGK;AAAgC;AAAjC;AACC;AAAoB;AAArB;AAED;AAAD;;AAR4E;AAAA;;AAa9E;AACE;AAEA;;;EAH8C;EAAA,IAAAyB,QAAA,GAAA5G,aAAA,CAAAuF,QAAA,CAAAC,cAAA,CAAAlB,IAAA;IAAAuC,KAIjC,yBAJiC;;EAM9C;IACEA,KAAA,EAAI,WADC;IAELC,QAAI,EAFC;EAGL;IACAC,gBAJK,EAAA7C;EAKL;EAEA,IAAA8C,qBAPK,GAAAtH,qBAAA,CAAAuH,UAAA;IAQLC,YAAA,GAAeF,qBAAA,CAAAE,YAAE;EACf,IAAAC,MAAA,GAAAF,UAAU,CAAAzF,GAAS,CAAC,UAAOgB,KAA3B,EAAAd,KAAA;IACD,IAAAsB,IAFgB,GAAAkE,YAAA,CAAAxF,KAAA;IAAA,IAAA0F,SAAA,GAAAR,QAAA,CAAA/D,IAAA,WAAAwE,CAAA;MARnB,OAAAA,CAAA,CAAAxG,GAAA,KAAA2B,KAAA;IANF;IAqBD,IAAA8E,KAAA,GAAAF,SAAA;MAED3E,IAAA,GAAA6E,KAAA,CAAA7E,IAAA;MACAiD,MAAA,GAAA4B,KAAA,CAAA5B,MAAA;IAEA;MACA1C,IAAA,EAAAA,IAAA;MACAuE,EAAA,EAAAvE,IAAA;MACAwE,WAAA,EAAAxE,IAAA;;;MACOP,IAAS,EAAAgF,uBACd,CAAAhF,IAAA,CADK;MAGLwC,YAAO,EAAWxC,IAAA;MACIiF,aACC,WAAZA,aADWC,CAAAC,EAAA;QAEd,iBAAJrB,CAFkB,EAIlB;;QACI;MACF;;EACA;EACE,OAAAY,MAAO;AACR;;AACD;AACD;;AAED;AACA;AAEA;;AAEa,SAAAzH,qBAAcwH,CAAAD,UAAA;EAA7B,OAnBFA,UAAA,CAAAY,MAAA,WAAAC,IAAA,EAAAtF,KAAA,EAAAlC,CAAA;IAqBD,IAAAqH,QAAA,GAAAG,IAAA,CAAAH,QAAA;IAED,IAAAI,SAAA,GAAAvF,KAAA;;IAEA,IAAAmF,QAAA,CAAAK,QAAA,CAAAxF,KAAA;MACA,IAAAyF,OAAA;MAEA,OAAAN,QAAA,CAAAK,QAAA,IAAAnD,MAAA,CAAArC,KAAA,OAAAqC,MAAA,CAAAoD,OAAA;;MACA;;IACO;IAAwDH,IAG3D,CAAAZ,YAaE,CAAA5G,CAAA,IAAAyH,SAAA;IAhByDD,IAI3D,CAAAH,QAYE,CAAA3B,IAAA,CAAA+B,SAAA;IAhByD,OAK3DD,IAWE;EAhByD;IAAAH,QAAA,EAgBzD;IAhByDT,YAgBzD;EAhByD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAmB7D;;AACA;;;EAGE,IAAAgB,IAAK,GAALlI,aAAA,CAAAoE,UAAA,CAAA8D,IAAA;IACAC,IAAK,GAAAnI,aAAL,CAAAoE,UAAA,CAAA+D,IAAA;IACEC,QAAO,GAAApI,aAAA,CAAAoE,UAAgB,CAAAgE,QAAvB;;IACFC,GAAK,GAAArI,aAAL,CAAAoE,UAAA,CAAAiE,GAAA;IACEC,KAAA,GAAOtI,aAAA,CAAAoE,UAAA,CAAAkE,KAAP;;IACFC,MAAA,GAAAvI,aAAA,CAAAoE,UAAA,CAAAmE,MAAA;IACEC,QAAO,GAAAxI,aAAA,CAAAoE,UAAgB,CAAAoE,QAAvB;;IACFC,yBAAA,GAAAzI,aAAA,CAAAoE,UAAA,CAAAqE,yBAAA;IACEC,OAAO,GAAA1I,aAAA,CAAAoE,UAAA,CAAAsE,OAAA;;IACTC,MAAK,GAAA3I,aAAL,CAAAoE,UAAA,CAAAuE,MAAA;EACA;;EAEA,QAAKC,KAAL;IACA,KAAKV,IAAA;MACH,OAAAnI,UAAA,CAAA2C,eAAA,CAAAmG,IAAA;;IAEF,KAAKT,QAAL;MACA,OAAKrI,UAAL,CAAA2C,eAAA,CAAAwC,SAAA;IAEE,KAAAoD,KAAO;;IAEP,KAAAD,GAAA;;IAxBJ,KAAAS,OAAA;MA2BD,OAAA/I,UAAA,CAAA2C,eAAA"},"metadata":{},"sourceType":"script","externalDependencies":[]}